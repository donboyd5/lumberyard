---
title: "Cambridge Lumberyard analysis"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook: 
    df_print: paged
    fig_height: 6
    fig_width: 8
    toc: yes
    number_sections: yes
    code_folding: hide
editor_options:
  chunk_output_type: console
---

# SETUP SECTION

```{r setup, eval=TRUE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}

# note that eval=TRUE unless set to FALSE
# to have a chunk's output show in the html file, set include=TRUE in the chunk's options

knitr::opts_chunk$set(eval=TRUE, include=FALSE, echo=FALSE, message=FALSE, rows.print=20)
options(width = 150)
```

```{r libraries}
library(tidyverse)
tprint <- 50  # default tibble print
options(tibble.print_max = tprint, tibble.print_min = tprint) # show up to tprint rows

# tools
library(vroom)
library(readxl)
library(lubridate)
library(RColorBrewer)
library(RcppRoll)
library(fredr)
library(btools)
library(tidycensus)
library(fs)
library(archive)
library(arrow)

# graphics
library(scales)
library(ggbeeswarm)
library(patchwork)
library(gridExtra)
library(ggrepel)
library(ggbreak)

# tables
library(knitr)
library(kableExtra)
library(DT)
library(gt)

# maps
library(maps)
# https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html
library(usmap)
library(ggmap)
register_google(key = gmaps_apikey)
library(ggspatial)
library(sf)
library(tigris)
options(tigris_use_cache = TRUE)
# library(remotes)
# remotes::install_github("ropensci/osmdata")
library(osmdata) # package for working with streets
# library(showtext) # for custom fonts
library(rvest)

```

```{r locations}
# dsacs <- r"(E:\data\CA_sacs/)"
# dsacs_all <- paste0(dsacs, "data/allyears/")
# 
# dj90 <- r"(E:\data\CA_j90/)"
# dj90_all <- paste0(dj90, "data/allyears/")
# dcenpop <- r"(E:\data\census_annpop\)"
dcenpop <- r"(E:\data\census_annpop)"
dpl <- r"(E:\data\census_redistricting)"

dacssf <- r"(E:\data\acs\sf\)"
dny2009 <- r"(E:\data\acs\sf\2009_5year\ny\)"
dny2014 <- r"(E:\data\acs\sf\2014_5year\ny\)"
dny2019 <- r"(E:\data\acs\sf\2019_5year\ny\)"



```


```{r functions_utility}
source(here::here("r", "functions_utility.r"))

get_rowlab <- function(sgeotype){
  factor(sgeotype,
         levels=c("state", "county", "place", "cosub"),
         labels=c("Statewide",
                  "Selected counties",
                  "Selected villages",
                  "Selected towns"))
}


```


```{r constants}
#.. geoids of interest ----
cambridge_town <- "3611511836"
cambridge_village <- "3611825"
cambridge_schools <- "3606210"
greenwich_town <- "3611530686"
greenwich_village <- "3630675"
greenwich_schools <- "3612900"
washington_county <- "36115"
newyork_state <- "36"

#.. api keys ----
source("~/R_projects/api_keys.r", verbose=TRUE)
fredr_set_key(fred_apikey)
# gmaps_apikey <- "AIzaSyDFWxscpciI2HDziBJ3CIhqxKWEqbaD6VM"
## Not run: 
# census_api_key(census_apikey, install = TRUE, overwrite=TRUE)
# First time, reload your environment so you can use the key without restarting R.
# readRenviron("~/.Renviron")
# Sys.getenv("CENSUS_API_KEY")  # check

#.. graph theme items ----
legend_none <- theme(legend.position = "None")
legend_notitle <- theme(legend.title = element_blank())
caption_left <- theme(plot.caption = element_text(hjust = 0))

#.. source notes ----
source_acs <- "American Community Survey 5-year summary file"
source_cornell <- "Cornell Program on Applied Demographics (PAD)"
source_decennialpop <- "U.S. Census Bureau Decennial Census"
source_cenpop <- "U.S. Census Bureau City and Town Population Estimates"
# (https://www.census.gov/data/tables/time-series/demo/popest/2010s-total-cities-and-towns.html)
source_hud <- "HUD Comprehensive Housing Affordability Strategy data, based on 2014-2018 ACS"
source_padcoproj <- "Cornell Program on Applied Demographics, County Projections 2018 (https://pad.human.cornell.edu/counties/projections.cfm)"

# https://pad.human.cornell.edu/schools/projections.cfm
# https://www.nyeducationdata.org/
# https://www.ers.usda.gov/data-products/atlas-of-rural-and-small-town-america/download-the-data/

```

```{r geos_dataframe}
geos <- read_delim(
"geotype;geoid;geoname

state; 36; New York

county; 36001; Albany County, New York
county; 36091; Saratoga County, New York
county; 36113; Warren County, New York
county; 36115; Washington County, New York

cosub; 36115; Washington County, New York

place; 3602550; Argyle village, New York
place; 3611825; Cambridge village, New York
place; 3630675; Greenwich village, New York
place; 3664771; Salem village, New York
place; 3665750; Schuylerville village, New York

school; 3603210; Argyle Central School District, New York
school; 3606210; Cambridge Central School District, New York
school; 3612900; Greenwich Central School District, New York
school; 3625470; Salem Central School District, New York
school; 3625770; Saratoga Springs City School District, New York
school; 3626160; Schuylerville Central School District, New York

zcta; 12816; 12816
zcta; 12834; 12834

", col_types=cols(.default = col_character()), trim_ws=TRUE
)
geos
```


# GOALS

The goal is to understand the current local housing situation and help inform decisions about what kind of housing might be appropriate to consider within the Lumber Yard.

I think the big questions are: • What does the census and other publicly available records tell us about the population and housing within Village of Cambridge (and perhaps the CCS school district catchment area of White Creek, Cambridge and Jackson and how they compare to prior censuses to see what the trends are?.\
• What is the current status of housing in Village of Cambridge?\
• What is needed or might be the right mix of housing options in the Village of Cambridge, generally to ensure a vibrant, dynamic, diverse, multi-generational caring rural community?\
• Are there case studies/lessons learned from other ' housing developments' that attract younger people (25-35 year olds) and entrepreneurs and remote workers to rural communities?

# DATA PREPARATION SECTION

```{r acs_notes}
# https://www.census.gov/programs-surveys/acs/data/summary-file.2019.html

```

```{r tidycensus_notes}
# https://walker-data.com/tidycensus/articles/basic-usage.html 
# load_variables() takes two required arguments: year of Census or endyear of ACS sample, and dataset name
# For decennial Census, possible dataset choices include "pl" for the redistricting files (currently the only choice for 2020), "sf1" or "sf2" (2000 and 2010) and "sf3" or "sf4" (2000 only)
#  For ACS, use either "acs1" or "acs5" for the ACS detailed tables, and append /profile for the Data Profile and /subject for the Subject Tables.

# 5-year ACS for all geographies down to the block group level starting with 2005-2009

#.. get_acs and geography ----
# https://walker-data.com/tidycensus/articles/basic-usage.html#working-with-acs-data-1
# geography="county subdivision", state="NY", county="Washington", # gets all in county
# geography="place", state="NY", # DON'T USE COUNTY, gets all in state
# geography="school district (unified)", state="NY", # DON'T USE COUNTY, gets all
# geography="zcta", state="NY", zcta=c(12816, 12834) # DON'T USE COUNTY, gets all

# keep_geo_vars=TRUE doesn't seem to matter for what I'm doing

```

```{r tidycensus_nonacs}
# median age by state in 2010
age10 <- get_decennial(geography = "state", 
                       variables = "P013001", 
                       year = 2010)

get_estimates(
  geography="county",
  product = "characteristics",
  # variables = NULL,
  breakdown = "AGEGROUP",
  state="NY",
  county="Washington",
  time_series = TRUE)

tpop <- get_estimates(
  geography="county subdivision",
  product = "characteristics",
  # variables = NULL,
  breakdown = "AGEGROUP",
  state="NY",
  county="Washington",
  time_series = TRUE)

```


```{r tidycensus_functions}

get_acstab <- function(acstab, years, dict=uvacs, geos=geos){
  
  get_geo <- function(geotype, year, acstab){
    print(geotype)
    if(geotype=="state"){
      df <- get_acs(geography="state",
                    state=states,
                    table=acstab,
                    year=year)
      } else if(geotype=="county") {
        df <- get_acs(geography="county",
                      state=states,
                      county=counties,
                      table=acstab,
                      year=year)
       } else if(geotype=="cosub"){
          df <- get_acs(geography="county subdivision",
                        state=cosubs_state,
                        county=cosubs_county,
                        table=acstab,
                   year=year)
        } else if(geotype=="place"){
          df <- get_acs(geography="place",
                   state=states,
                   table=acstab,
                   year=year)
        } else if(geotype=="school"){
          df <- get_acs(geography="school district (unified)",
                   state=states,
                   table=acstab,
                   year=year)
        } else if (geotype=="zcta" & year > 2009) {
          df <- get_acs(geography="zcta",
                        state="NY",
                        zcta=zctas,
                        table=acstab,
                        year=year)
          
        } else {
          df <- tibble(GEOID=NA_character_,
                       NAME=NA_character_,
                       variable=NA_character_,
                       estimate=NA_real_,
                       moe=NA_real_)
        }
        
        df <- df %>%
          setNames(str_to_lower(names(.))) %>%
          mutate(geotype=!!geotype,
                 year=!!year)  %>%
          select(geotype, year, geoid, geoname=name, variable, estimate, moe)
        
        df <- df %>%
          # drop non-cosub govts that are not specified in the geos file (revisit)
          left_join(geos %>% 
              select(geoid, geotype, geos_geoname=geoname) %>%
              mutate(ingeo=TRUE),
            by=c("geoid", "geotype")) %>%
          filter((geotype=="cosub") | ingeo) %>%
          select(-ingeo)
        return(df)
        }
  
  get_year <- function(year, acstab, geos){
    # the main program -- direct action for a single year
    print(year)
    if(acstab %in% tabs_avail$tableid[tabs_avail$year==year]) {
      map_dfr(geotypes, get_geo, year, acstab)
    } else {
      tibble(geo=NULL,
                  geoid=NULL,
                  name=NULL,
                  variable=NULL,
                  estimate=NULL,
                  moe=NULL)
    }
  }
  
  # these variables are available throughout the function
  geotypes <- unique(geos$geotype)
  states <- geos %>% filter(geotype=="state") %>% .$geoid
  counties <- geos %>% 
    filter(geotype=="county") %>% 
    mutate(counties=str_sub(geoid, 3, 5)) %>%
    .$counties
  places <- geos %>% filter(geotype=="place") %>% .$geoid
  cosubs <- geos %>% filter(geotype=="cosub") %>% .$geoid
  cosubs_state <- str_sub(cosubs, 1, 2)
  cosubs_county <- ifelse(nchar(cosubs)==5, str_sub(cosubs, 3, 5), NULL)
  zctas <- geos %>% filter(geotype=="zcta") %>% .$geoid
  
  tabs_avail <- count(dict, tableid, year=endyear)
  df <- map_dfr(years, get_year, acstab, geos)
  df
}

# tmp <- get_acstab(acstab="B25071", years=c(2009, 2014, 2019), dict=uvacs, geos=geos)

```

```{r ONETIME_tidycensus_uvacs}
# build a full variable list and clean it up so that it has uniform titles
vacs2009 <- load_variables(2009, "acs5", cache = TRUE)
vacs2014 <- load_variables(2014, "acs5", cache = TRUE)
vacs2018 <- load_variables(2018, "acs5", cache = TRUE)
vacs2019 <- load_variables(2019, "acs5", cache = TRUE)
vacs <- 
  bind_rows(vacs2009 %>% mutate(endyear=2009),
            vacs2014 %>% mutate(endyear=2014),
            vacs2018 %>% mutate(endyear=2018),
            vacs2019 %>% mutate(endyear=2019))

# create uniform labels based on latest year and count # years
uvacs <- vacs %>%
  separate(name, c("tableid", "vnum"), remove=FALSE) %>%
  group_by(name) %>%
  arrange(endyear) %>%
  mutate(nyears=n(), ulabel=label[endyear==max(endyear)], maxyear=max(endyear)) %>%
  ungroup %>%
  # there are never more than 8 parts to the uniform lable
  separate(ulabel, into=paste0("ulab", 1:8), sep="!!", remove=FALSE)

saveRDS(uvacs, here::here("data", "uvacs.rds"))

```


```{r tidycensus_table_selection}
# https://data.census.gov/cedsci/table
# ACS_2019_SF_5YR_Appendices.xlsx sheet Appendics A
# ACS2019_Table_Shells.xlsx

uvacs <- readRDS(here::here("data", "uvacs.rds"))

# possible concepts of interest
# AGE BY DISABILITY STATUS BY HEALTH INSURANCE COVERAGE STATUS
# AGE BY IMPUTATION OF INDEPENDENT LIVING DIFFICULTY FOR THE CIVILIAN NONINSTITUTIONALIZED POPULATION 15 YEARS AND OVER
# AGE BY NUMBER OF DISABILITIES
# AGE BY PRESENCE OF A COMPUTER AND TYPES OF INTERNET SUBSCRIPTION IN HOUSEHOLD
# AGE BY VETERAN STATUS BY EMPLOYMENT STATUS FOR THE CIVILIAN POPULATION 18 TO 64 YEARS
# AGE OF HOUSEHOLDER BY GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS

tabs <- count(uvacs, tableid, concept)

s <- "educational attain"
s <- "geographical mobility"
s <- "percent of"
s <- "rent"
s <- "age"
(look <- tabs %>% 
  # filter(str_sub(tableid, 1, 1)=="B") %>%
  filter(str_detect(concept, coll(s, ignore_case = TRUE))) %>% select(tableid, concept))


# if needed:
df <- get_acs(geography="county",
            state="NY",
            # county=c("115"),
            table="B25071",
            year=2019)

```

```{r tidycensus_save_individual_tables}

# Universe if NOT Population 25 years and over in the United States (from table shell) is listed below
# B01001 SEX BY AGE
# total population
# B01002   MEDIAN AGE BY SEX
# Universe: Total population
# B07001    GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY AGE FOR CURRENT RESIDENCE IN THE UNITED STATES
# Universe:  Population 1 year and over in the United States
# B07009 GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR CURRENT RESIDENCE IN THE UNITED STATES
# B07409   GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR RESIDENCE 1 YEAR AGO IN THE UNITED STATES
# B15003   EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER
# B25071  MEDIAN GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS (DOLLARS)
# Universe:  Renter-occupied housing units paying cash rent

save_table <- function(tab){
  # print(tab)
  df <- get_acstab(acstab=tab, years=c(2009, 2014, 2019), dict=uvacs, geos=geos)
  df <- df %>% mutate(tableid=tab)
  fn <- paste0("tab_", tab, ".rds")
  saveRDS(df, here::here("data", fn))
  df
}

# get tables one at a time depending on exploration above
df <- save_table("B01001")
df <- save_table("B01002")
df <- save_table("B07001")
df <- save_table("B07009")
# df <- readRDS(here::here("data", "tab_B07009.rds"))
df <- save_table("B07409")
df <- save_table("B15003")
df <- save_table("B25071")


```


```{r tidycensus_combine_save}

# tmp <- get_acstab(acstab="B25071", years=c(2009, 2014, 2019), dict=uvacs, geos=geos)
# combine tables ----
combine_tabs <- function(tabnames){
  get_tab <- function(tabname){
    fname <- paste0("tab_", tabname, ".rds")
    df <- readRDS(here::here("data", fname))
    df
  }
  # get all the tabs
  df <- map_dfr(tabnames, get_tab)
  # clean them up
  df <- df %>%
    filter(!is.na(variable)) %>%
    select(-geos_geoname)%>%
    left_join(uvacs %>% 
                filter(endyear==maxyear) %>%
                select(variable=name, vnum, concept, starts_with("ulab")),
              by="variable") %>%
    mutate(concept=str_to_sentence(concept),
           across(ulab1:ulab8, ~ str_remove(.x, ":")),
           sname=str_extract(geoname, "^[^,]+"),
           sname=case_when(geoid=="36" ~ "New York State",
                           str_detect(sname, "ZCTA") ~ str_replace(sname, "ZCTA5", "Zip"),
                           TRUE ~ sname),
           sname=ifelse(sname %in% c("Salem village", "Salem CDP"),
                        "Salem village/CDP",
                        sname)) %>%
    select(geotype, geoid, sname, variable, tableid, vnum, year, estimate, moe,
           concept, ulab1:ulab8, ulabel, geoname) %>%
    arrange(geotype, geoid, variable, year)
}

# tabnames <- c("B01002", "B07001", "B07009", "B07409", "B15003", "B25071")
(tabfiles <- list.files(here::here("data"), pattern="tab_"))
tabnames <- tabfiles %>% str_remove("tab_") %>% str_remove(".rds")
acsdata <- combine_tabs(tabnames)
glimpse(acsdata)
count(acsdata, tableid)
count(acsdata, sname)
saveRDS(acsdata, here::here("data", "acsdata.rds"))

```


```{r ONETIME_CensusCityTown_pop}
# https://community.rstudio.com/t/get-file-name-from-url/25505/4
# https://fs.r-lib.org/reference/index.html
# library(fs)
# uplace %>%
#   path_file() %>% 
#   path_ext_remove()

# https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/sub-est2019.pdf

# 2020 and 2021 state-level births, deaths, migration
# https://www2.census.gov/programs-surveys/popest/datasets/2020-2021/state/totals/NST-EST2021-alldata.csv

# 2020 and 2021 state-level ests and changes
# https://www2.census.gov/programs-surveys/popest/datasets/2020-2021/state/totals/NST-EST2021-popchg2020_2021.csv

#..2010-2020 data csv format ----
# 2010-2020 place-level ests
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/SUB-EST2020_ALL.csv
# 2010-2020 county-level ests
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv
# 2010-2020 county-level ests plus births deaths migration
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020-alldata.csv
# 2010-2020 county-level housing estimates
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/housing/HU-EST2020_ALL.csv
# US, states, and regions
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020.csv
# ... popests and changes
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020-popchg2010-2020.csv
# ... popests and births, deaths, migration
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020-alldata.csv

#.. vintage 2021 data info ---- December 21, 2021 states data, and national and
#state components of change
#https://www.census.gov/newsroom/press-releases/2021/2021-population-estimates.html
#https://www.census.gov/programs-surveys/popest/data/tables.html 2020 county
#data from redistricting files
#https://www.census.gov/library/visualizations/interactive/2020-population-and-housing-state-data.html
#https://www.census.gov/programs-surveys/decennial-census/about/rdo/summary-files.html#P1
# The 2020 Census Redistricting Data (P.L. 94-171) Summary File data are
# available for all 50 states, the District of Columbia, and the Commonwealth of
# Puerto Rico through data.census.gov and FTP download (in the Legacy Format).
# But they also appear to have county data (djb)
#  Washington County, NY
# 
# Total population (2020): 61,302 
# ----
# Population Data
# Total population (2020): 61,302
# Total population (2010): 63,216
# Numeric change (2010–2020): -1,914
# Percent change (2010–2020): -3.0
# from techdoc:
# This product contains summary statistics on population and housing subjects. Population
# counts for the total population and for the population 18 years and over are presented by race
# and by Hispanic or Latino origin, and for the total group quarters population by major group
# quarters type. The product includes one housing table showing occupancy status (occupied,
# vacant). The official titles of the six tables are:
# P1. Race
# P2. Hispanic or Latino, and Not Hispanic or Latino by Race
# P3. Race for the Population 18 Years and Over
# P4. Hispanic or Latino, and Not Hispanic or Latino by Race for the Population 18 Years and
# Over
# P5. Group Quarters Population by Major Group Quarters Type
# H1. Occupancy Status




ubase <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/"
ubase <- "# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/"

f <- function(url) download.file(url, file.path(dcenpop, path_file(url)), mode="wb")

#.. all (?) as csv ----
uallcsv <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/cities/totals/sub-est2019_all.csv"
f(uallcsv)

#.. population ----
# comp means components of change
ucounty <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/counties/totals/co-est2019-annres.xlsx"
f(ucounty)
ucocomp <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/counties/totals/co-est2019-comp.xlsx"
f(ucocomp)

# places, cities
uplace <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/cities/totals/SUB-IP-EST2019-ANNRES.xlsx"
f(uplace)

umcdny <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/mcds/totals/SUB-MCD-EST2019-ANNRES-36.xlsx"
f(umcdny)

ucbsa <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/cbsa-met-est2019-annres.xlsx"
f(ucbsa)
ucbsacomp <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/cbsa-met-est2019-comp.xlsx"
f(ucbsacomp)

ucsa <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/csa-est2019-annres.xlsx"
f(ucsa)
ucsacomp <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/csa-est2019-comp.xlsx"
f(ucsacomp)

#.. housing ----
usthousing <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/housing/totals/NST-EST2019-ANNHU.xlsx"
f(usthousing)

ucohousing <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/housing/totals/CO-EST2019-ANNHU.xlsx"
f(ucohousing)

```


```{r popann_2020}

# just estimates, not components of change:
# US, states, and regions
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020.csv
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/SUB-EST2020_ALL.csv

# 2010-2020 county-level ests plus births deaths migration
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020-alldata.csv
# 2010-2020 county-level housing estimates
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/housing/HU-EST2020_ALL.csv

dcenpop <- r"(E:\data\census_annpop)"
ustate <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020.csv"
ucounty <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv"
usubco <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/SUB-EST2020_ALL.csv"

# dcenpop <- r"(E:\data\census_annpop\)"
# nst-est2020.csv co-est2020.csv SUB-EST2020_ALL.csv HU-EST2020_ALL.csv
popfiles <- c("nst-est2020.csv", "co-est2020.csv", "SUB-EST2020_ALL.csv") 

f <- function(url) download.file(url, file.path(dcenpop, path_file(url)), mode="wb")
f(ustate)
f(ucounty)
f(usubco)

# combine files and clean
f2 <- function(url, dcenpop){
  df <- vroom(file.path(dcenpop, path_file(url)), col_types=cols(.default="c"))
  df %>%
    mutate(src=path_file(url))
}
df <- map_dfr(list(ustate, ucounty, usubco), f2, dcenpop)
names(df)

# use !! to unquote one variable or !!! to unquote a vector of variables inside
# of arrange(). When you pass those columns, if they are bare, quote them using
# quo() for one variable or quos() for a vector
idvars <- quos(c(sumlev, region, division, state, 
         county, place, cousub, concit, primgeo_flag, funcstat,
         stname, ctyname, name))

df2 <- df %>%
  setNames(str_to_lower(names(.))) %>%
  select(src, !!!idvars, everything()) %>%
  # we want all pop variables to start with "pop" and end with the year
  rename(popcensus2010=census2010pop,
         popestimatesbase2010=estimatesbase2010,
         popcensusestimate2020=popestimate042020) %>%
  mutate(across(starts_with("pop"), as.numeric))

count(df2, sumlev, src)
names(df2)
count(df2 %>% filter(is.na(name)), sumlev)

# get rid of duplicate sumlev 040
tmp <- df2 %>% 
  filter(sumlev=="040") %>% 
  mutate(name2=ifelse(is.na(stname), name, stname)) %>%
  select(src, !!!idvars, name2, popcensus2010, popcensusestimate2020) %>%
  arrange(name2, src)
# nst-est2020.csv has PR, others don't; all pop numbers appear the same

# get county names to put on file
counties <- df2 %>%
  filter(sumlev=="050", !is.na(ctyname)) %>%
  select(state, county, ctyname) %>%
  distinct()

df3 <- df2 %>%
  filter(!(sumlev=="040" & src != "nst-est2020.csv")) %>%
  # fill in names
  mutate(stname=ifelse(sumlev=="040", name, stname),
         name=ifelse(sumlev=="050", ctyname, name)) %>%
  select(-ctyname) %>%
  left_join(counties, by=c("state", "county")) %>% # bring in ctyname
  relocate(ctyname, .after=stname) %>%
  # filter(state=="36")
  # create geoid for NY records
  mutate(sgeotype=case_when(state=="36" & sumlev=="040" ~ "state",
                            state=="36" & sumlev=="050" ~ "county",
                            state=="36" & sumlev=="061" ~ "cosub", # cities and towns
                            state=="36" & sumlev=="157" ~ "place", # villages
                            TRUE ~ NA_character_),
         geoid=case_when(sgeotype=="state" ~   paste0("04000US", state),
                         sgeotype=="county" ~  paste0("05000US", state, county),
                         sgeotype=="cosub" ~   paste0("06000US", state, county, cousub),
                         sgeotype=="place" ~   paste0("16000US", state, place)))
names(df3)

# create long file
df4 <- df3 %>%
  select(geoid, sumlev, sgeotype, state, stname, geoname=name,
         county, place, cousub, concit, starts_with("pop")) %>%
  pivot_longer(starts_with("pop")) %>%
  mutate(esttype=case_when(str_detect(name, "popcensus") ~ "census",
                           str_detect(name, "popestimatesbase") ~ "estsbase",
                           str_detect(name, "popestimate") &
                             !str_detect(name, "popestimatesbase") ~ "est"),
         year=str_sub(name, -4, -1) %>% as.integer())

ny <- df4 %>%
  filter(state=="36")
tmp <- ny %>% filter(str_detect(geoname, "Dexter"))

saveRDS(df4, file.path(dcenpop, "popann2020.rds"))


```


```{r housing_decennial}
z2010 <- here::here("data", "DECENNIALPL2010.H1_2022-01-19T092207.zip")
z2020 <- here::here("data", "DECENNIALPL2020.H1_2022-01-19T094129.zip")

df2010 <- read_csv(archive_read(z2010, "DECENNIALPL2010.H1_data_with_overlays_2022-01-19T092201.csv"),
         col_types = cols(.default="c"), skip=1)

df2020 <- read_csv(archive_read(z2020, "DECENNIALPL2020.H1_data_with_overlays_2022-01-19T094122.csv"),
         col_types = cols(.default="c"), skip=1)

dfcen1 <- bind_rows(df2010 %>%
                     setNames(c("id", "total", "occupied", "vacant", "usgeoname")) %>% 
                     mutate(year=2010),
                   df2020 %>% 
                     setNames(c("id", "usgeoname", "total", "occupied", "vacant")) %>%
                     mutate(year=2020)) %>%
  mutate(year=as.integer(year),
         across(c(total, occupied, vacant), as.numeric),
         usgeoname=str_replace(usgeoname, "Salem village", "Salem CDP")) %>%
  mutate(sgeotype=case_when(id=="0400000US36" ~ "state",
                            id %in% c("0500000US36091", "0500000US36113", "0500000US36115") ~
                              "county",
                            str_detect_any(usgeoname, c("village", "CDP")) ~ "place",
                            str_detect(usgeoname, "town") ~ "cosub")) %>%
  select(id, usgeoname, sgeotype, year, total, occupied, vacant)
saveRDS(dfcen1,  here::here("data", "cenhousing.rds"))


```


```{r housing_ann}
url <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/housing/HU-EST2020_ALL.csv"


f <- function(url) download.file(url, file.path(dcenpop, path_file(url)), mode="wb")
f(url)

# combine files and clean
f2 <- function(url, dcenpop){
  df <- vroom(file.path(dcenpop, path_file(url)), col_types=cols(.default="c"))
  df %>%
    mutate(src=path_file(url))
}
df <- f2(url, dcenpop)
names(df)

df %>% filter(STATE=="36") # counties

# use !! to unquote one variable or !!! to unquote a vector of variables inside
# of arrange(). When you pass those columns, if they are bare, quote them using
# quo() for one variable or quos() for a vector
idvars <- quos(c(sumlev, region, division, state, 
         county, place, cousub, concit, primgeo_flag, funcstat,
         stname, ctyname, name))

df2 <- df %>%
  setNames(str_to_lower(names(.))) %>%
  select(src, !!!idvars, everything()) %>%
  # we want all pop variables to start with "pop" and end with the year
  rename(popcensus2010=census2010pop,
         popestimatesbase2010=estimatesbase2010,
         popcensusestimate2020=popestimate042020) %>%
  mutate(across(starts_with("pop"), as.numeric))

```



```{r OLD_read_popann_and_xwalk}

#.. read data ----
# https://www.statsamerica.org/geography-tools.aspx
dcenpop <- r"(E:\data\census_annpop\)"
uallcsv <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/cities/totals/sub-est2019_all.csv"
path_file(uallcsv)
dfall1 <- read_csv(file.path(dcenpop, path_file(uallcsv)))
glimpse(dfall1)
names(dfall1)

# why is CENSUS2010POP character?
bad <- dfall1 %>%
  mutate(rn=row_number()) %>%
  filter(is.na(as.numeric(CENSUS2010POP))) %>%
  select(SUMLEV:POPESTIMATE2010, rn)
bad
nrow(bad) # 430 rows

count(dfall1, FUNCSTAT)
# https://www.census.gov/library/reference/code-lists/functional-status-codes.html
#   FUNCSTAT     n
#   <chr>    <int>
# 1 A        69600  active govt
# 2 B           24
# 3 C           62
# 4 F        11195  fictitious entity to fill Census hierarchy, includes many types of areas
# 5 G            1
# 6 I          108  inactive govt with special purpose powers
# 7 N           70
# 8 S          374  statistical entity

# clean up and make an rds file ----
dfall2 <- dfall1 %>%
  setNames(str_to_lower(names(.))) %>%
  # we want all pop variables to start with "pop" and end with the year
  rename(popcensus2010=census2010pop,
         popestimatesbase2010=estimatesbase2010) %>%
  mutate(popcensus2010=as.numeric(popcensus2010))

# https://www.census.gov/programs-surveys/geography/technical-documentation/naming-convention/cartographic-boundary-file/carto-boundary-summary-level.html
# https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html
# https://www.census.gov/geographies/reference-files/2010/geo/state-local-geo-guides-2010/new-york.html
# https://mcdc.missouri.edu/geography/sumlevs/more-about-sumlevels.html
# https://www2.census.gov/geo/docs/reference/

# use the codes in the codes folder, not in the codes/files folder
# https://www2.census.gov/geo/docs/reference/codes/national_county.txt
# State,State ANSI,County ANSI,County Name,ANSI Cl
# AL,01,001,Autauga County,H1

# https://www2.census.gov/geo/docs/reference/codes/COUSUBlist.txt
# STATE,STATEFP,COUNTYFP,COUNTYNAME,COUSUBFP,COUSUBNAME,FUNCSTAT
# AL,01,001,Autauga County,90171,Autaugaville CCD,S

# https://www2.census.gov/geo/docs/reference/codes/PLACElist.txt  note the | delimiter
# STATE|STATEFP|PLACEFP|PLACENAME|TYPE|FUNCSTAT|COUNTY
# AL|01|00100|Abanda CDP|Census Designated Place|S|Chambers County

# https://www2.census.gov/geo/docs/reference/codes/SDlist.txt
# STATE,STATEFP,LEA,SDNAME,TYPE
# AL,01,00001,Fort Rucker School District,Unified

# delimited files, names?, and delimiter
# https://www2.census.gov/geo/docs/reference/codes/files/
# [TXT]	national_county.txt	09-May-2014 08:12	92K	 no, ,
# https://www2.census.gov/geo/docs/reference/codes/national_county.txt yes, ,
# [TXT]	national_cousub.txt	09-May-2014 08:12	1.8M	 yes, ,
# [TXT]	national_places.txt	09-May-2014 08:12	2.7M	    yes, |
# [TXT]	national_schdist.txt	09-May-2014 08:12	739K	 yes, ,

#   sumlev     n
#   <chr>  <int>
# 1 040       51  state
# 2 050     3142  county
# 3 061    21063  towns -- are 060 in geoid
# 4 071    13839  city -- 070 in geoid
# 5 157    23714  place (village) WITHIN COUNTY
# 6 162    19502  place (village) county is 000, just like geoid
# 7 170        8
# 8 172      115
# does not have sumlev 970 schooldistrict 

# selected ACS codes
# 04000US36,"New York"
# 04001US36,"New York -- Urban"
# 04043US36,"New York -- Rural"
# 05000US36001,"Albany County, New York"
# 05000US36115,"Washington County, New York"
# 06000US3600101000,"Albany city, Albany County, New York",,,
# 06000US3600106211,"Berne town, Albany County, New York",,,
# 06000US3611511836,"Cambridge town, Washington County, New York"
# 16000US3611825,"Cambridge village, New York"
# 16000US3664771,"Salem CDP, New York"
# 97000US3606210,"Cambridge Central School District, New York" NOT IN POPEST DATA

# construct acs geoid -- investigate
part <- "Albany city"
part <- "Berne town"
part <- "Cambridge"
part <- "Salem"  # CDP or village does not seem to be in popest data
dfall2 %>%
  filter(str_detect(name, part), state=="36") %>%
  select(sumlev:popcensus2010)
count(dfall2, sumlev)


# selected popest data
# sumlev state county place cousub concit primgeo_flag funcstat name
# 050    36    001    00000 00000  00000             0 A        Albany County
# 061    36    001    00000 06211  00000             1 A        Berne town
# 061    36    115    00000 11836  00000             0 A        Cambridge town

# summary paste rules for NY based on sgeotype
# state: 04000US36
# county: 05000US36,county
# cosub(town/city 061-->060): 06000US36,county,cousub 
# place(village 162-->160): 16000US36,place


dfall3 <- dfall2 %>%
  mutate(sgeotype=case_when(state=="36" & sumlev=="040" ~ "state",
                            state=="36" & sumlev=="050" ~ "county",
                            state=="36" & sumlev=="061" ~ "cosub",
                            state=="36" & sumlev=="162" ~ "place",
                            TRUE ~ NA_character_),
         geoid=case_when(sgeotype=="state" ~   paste0("04000US", state),
                         sgeotype=="county" ~  paste0("05000US", state, county),
                         sgeotype=="cosub" ~   paste0("06000US", state, county, cousub),
                         sgeotype=="place" ~   paste0("16000US", state, place)))
dfall3 %>% filter(state=="36")
dfall3 %>% filter(state=="36", sgeotype=="state")
tmp <- dfall3 %>% filter(state=="36", sgeotype=="county")
tmp <- dfall3 %>% filter(state=="36", sgeotype=="cosub", county=="115")
tmp <- dfall3 %>% filter(state=="36", sgeotype=="place")

# The “GEO.ID” field contains 14-digit codes that identify the summary level of
# data, the geographic component of the data and FIPS codes that uniquely
# identify the data. For example, the 14-digit “GEO.ID” for Harris County, TX is
# “0500000US48201” where “050” represents the summary level of the data, “0000”
# represents the 2-digit geographic variant and the 2-digit geographic
# component, “US” represents the United States, “48” represents the state of
# Texas and “201” represents Harris County.

# do final cleaning and save
dfall4 <- dfall3 %>%
  select(geoid, sumlev, sgeotype, state, stname, geoname=name,
         county, place, cousub, concit, starts_with("pop")) %>%
  pivot_longer(starts_with("pop")) %>%
  mutate(esttype=case_when(str_detect(name, "popcensus") ~ "census",
                           str_detect(name, "popestimatesbase") ~ "estsbase",
                           str_detect(name, "popestimate") &
                             !str_detect(name, "popestimatesbase") ~ "est"),
         year=str_sub(name, -4, -1) %>% as.integer())

ny <- dfall4 %>%
  filter(state=="36")
tmp <- ny %>% filter(str_detect(geoname, "Dexter"))

saveRDS(dfall4, file.path(dcenpop, "popann.rds"))

```


```{r ONETIME_pad_projections}

f <- function(cnty){
  # NOTE: I had to open these files as xls and save as xlsx for this to work
  read_excel(here::here("data", paste0("padprojections", cnty,".xlsx")))
  }
pad1 <- map_dfr(c(91, 113, 115), f)

pad2 <- pad1 %>%
  setNames(str_to_lower(names(.))) %>%
  pivot_longer(-c(1:8), names_to = "year") %>%
  mutate(year=str_sub(year, 4, 7) %>% as.integer)
glimpse(pad2)


pad3 <- pad2 %>%
  select(-racecode, -race_descr) %>%
  rename(ccode=county, county=county_descr, 
         sex=sex_descr,
         agecode=agegrpcode, agegrp=agegrp_descr) %>%
  mutate(sex=str_to_lower(sex))
glimpse(pad3)

pad3 %>%
  filter(sex=="all", agecode==-999) %>%
  group_by(county) %>%
  mutate(pdvalue=value / value[year==2015] - 1) %>%
  ggplot(aes(year, pdvalue, colour=county)) +
  geom_line() +
  geom_point()

saveRDS(pad3, here::here("data", "popproj_pad_cnty.rds"))

```


```{r HUD_tables}
# save each table as its own file, cleaned a bit
dchas <- r"(E:\data\acs\hud_chas\)"
dtabs <- paste0(dchas, "tables/")

stdir <- r"(E:\data\acs\hud_chas\2014thru2018-040-csv_states\040\)"
codir <- r"(E:\data\acs\hud_chas\2014thru2018-050-csv_counties\050\)"
mcddir <- r"(E:\data\acs\hud_chas\2014thru2018-060-csv\060\)"
placedir <- r"(E:\data\acs\hud_chas\2014thru2018-160-csv_places\160\)"
citydir <- r"(E:\data\acs\hud_chas\2014thru2018-170-csv_consolidatedcities\170\)"
chasdirs <- c(stdir, codir, mcddir, placedir, citydir)

# the state directory should have a master list of tables
tabs <- list.files(path=stdir, pattern="*.csv", full.names = FALSE)
tabs
tools::file_path_sans_ext(tabs)
tab <- tabs[1]
dir <- chasdirs[4]

for(tab in tabs){
  a <- proc.time()
  print(tab)
  getfile <- function(dir, tab){
    
    print(dir)
    type <- case_when(str_detect(dir, "states") ~ "state",
                      str_detect(dir, "counties") ~ "county",
                      str_detect(dir, "060") ~ "mcd",
                      str_detect(dir, "places") ~ "place",
                      str_detect(dir, "consolidatedcities") ~ "concit",
                      )

    # dirlist <- list.files(path=stdir, pattern="*.csv", full.names = FALSE)
    path <- paste0(dir, tab)
    idlist <- c("source", "sumlevel", "geoid", "name", "st", "cnty", "mcd", "concit", "place")
    
    df <- read_csv(path, col_types = cols(.default="c")) %>%
      pivot_longer(-any_of(idlist), names_to="vname") %>%
      mutate(type=!!type,
             value=as.numeric(value)) %>%
      select(type, geoid, geoname=name, st, vname, value)# %>%
      # separate(vname, into=c("table", "est")) # %>%
      # mutate(etype=str_sub(est, 1, 3))
           #estnum=str_sub(est, 4, nchar(est)) %>% as.integer())
    df
  }
  df <- map_dfr(chasdirs, getfile, tab)
  # df2 <- df %>%
  #   separate(vname, into=c("table", "est")) %>%
  #   mutate(etype=str_sub(est, 1, 3),
  #          estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
  #   pivot_wider(names_from = etype)
  
  outfile <- tools::file_path_sans_ext(tab) %>% str_to_lower()
  
  saveRDS(df, paste0(dtabs, outfile, ".rds"))
  b <- proc.time()
  print(b - a)
}

glimpse(df2)





```



```{r HUD_data}
# https://www.huduser.gov/portal/datasets/cp.html
# states, counties, places, consolidated cities
dchas <- r"(E:\data\acs\hud_chas\)"

stdir <- r"(E:\data\acs\hud_chas\2014thru2018-040-csv_states\040\)"
codir <- r"(E:\data\acs\hud_chas\2014thru2018-050-csv_counties\050\)"
mcddir <- r"(E:\data\acs\hud_chas\2014thru2018-060-csv\060\)"
placedir <- r"(E:\data\acs\hud_chas\2014thru2018-160-csv_places\160\)"
citydir <- r"(E:\data\acs\hud_chas\2014thru2018-170-csv_consolidatedcities\170\)"
chasdirs <- c(stdir, codir, mcddir, placedir, citydir)

f <- function(path){
  idlist <- c("source", "sumlevel", "geoid", "name", "st", "cnty", "mcd", "concit", "place")
  read_csv(path) %>%
    pivot_longer(-any_of(idlist), names_to="vname")
}

for(dir in chasdirs){
  print(dir)
  paths <- list.files(path=dir, pattern="*.csv", full.names = TRUE)
  df <- map_dfr(paths, f)
  saveRDS(df, paste0(dir, "allfiles.rds"))
}


# slim and trim each file in an effort to make it easier to get good files
# dir <- chasdirs[1]
for(dir in chasdirs[4:5]){
  print(dir)
  df <- readRDS(paste0(dir, "allfiles.rds"))
  df2 <- df %>%
    select(-source, -sumlevel) %>%
    rename(geoname=name) %>%
    separate(vname, into=c("table", "est"), remove=FALSE) %>%
    mutate(type=case_when(str_sub(geoid, 1, 3)=="040" ~ "state",
                        str_sub(geoid, 1, 3)=="050" ~ "county",
                        str_sub(geoid, 1, 3)=="060" ~ "mcd",
                        str_sub(geoid, 1, 3)=="160" ~ "place",
                        str_sub(geoid, 1, 3)=="170" ~ "concit",
                        TRUE ~ "other"
                        ),
           st=str_sub(geoid, 8, 9),
           etype=str_sub(est, 1, 3),
           estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
    select(geoid, geoname, st, type, table, etype, estnum, value)
  saveRDS(df2, paste0(dir, "clean.rds"))
}


# now combine the different chas files
get_clean <- function(dir){
  # don't keep nonessential variables
  print(dir)
  readRDS(paste0(dir, "clean.rds")) %>%
    select(geoid, name, vname, value)
}
df <- map_dfr(chasdirs, get_clean)
saveRDS(df, paste0(dchas, "chasall.rds"))

# now create a clean file
chasall <- readRDS(paste0(dchas, "chasall.rds")) # 162m obs
head(chasall)

chas2 <- chasall %>%
  mutate(type=case_when(str_sub(geoid, 1, 3)=="040" ~ "state",
                        str_sub(geoid, 1, 3)=="050" ~ "county",
                        str_sub(geoid, 1, 3)=="160" ~ "place",
                        str_sub(geoid, 1, 3)=="170" ~ "concit",
                        TRUE ~ "other"
                        ))
count(chas2, type)

chasny <- chas2 %>%
  filter(str_sub(geoid, 8, 9)=="36") %>%
  # filter(row_number() < 10e3) %>%
  separate(vname, into=c("table", "est"), remove=FALSE) %>%
  mutate(etype=str_sub(est, 1, 3),
         estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
  select(geoid, name, type, table, etype, estnum, value) %>%
  pivot_wider(names_from = etype)
count(chasny, type)

saveRDS(chasny, paste0(dchas, "chasny.rds"))


tmp <- chasny %>%
  filter(str_detect(name, "Cambridge"))

# T1_est3	Subtotal	Owner occupied	has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)	All
# T1_est4	Subtotal	Owner occupied	has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)	less than or equal to 30% of HAMFI

tmp <- chasny %>%
  filter(table=="T1", estnum %in% 1:4) %>%
  mutate(estnum=paste0("est", estnum)) %>%
  select(-moe) %>%
  pivot_wider(names_from = estnum, values_from = est) %>%
  mutate(pctoo=est2 / est1,
         oopctprob=est3 / est2)

# determine places of interest
nyareas <- chasny %>%
  select(geoid, name, type) %>%
  distinct()

counties <- c("Albany", "Saratoga", "Warren", "Washington")
places <- c("Cambridge", "Greenwich", "Argyle", "Salem")
poi <- nyareas %>%
  filter(type=="state" |
           type=="county" & str_detect_any(name, counties) |
           type=="place" & str_detect_any(name, places))

tmp %>%
  filter(geoid %in% poi$geoid) %>%
  arrange(oopctprob)

# has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)

# df <- readRDS(paste0(chasdirs[3], "allfiles.rds"))
# dim(df)
# sumlevel
# 1 char
# 2 char, 15.9m recs
# 3 


```


```{r irs_data}
dmig <- r"()"
 zpath <- paste0(r"(E:\data\acs\sf\)", year, r"(_5year\ny\NewYork_All_Geographies_Not_Tracts_Block_Groups.zip)")
  print(zpath)
  files <- unzip(zpath, list=TRUE)
  read_files <- files %>%
    filter(str_sub(Name, 1, 2) %in% c("e2", "m2"))

```

```{r arolls}
path <- r"(E:\data\local\Assessment rolls\2021_final_rolls\countywide_pacels_extracts011922.xls)"
df <- read_excel(path)
df2 <- df %>%
  setNames(str_to_lower(names(.)))

ns(df2)



df3 <- df2 %>%
  filter(str_detect(owner, coll("Boyd", ignore_case = TRUE)),
         str_detect(owner, coll("Don", ignore_case = TRUE))) %>%
  select(owner, owner1, owner2, prop_addr, muni, acres, full_marke, sale_price, sale_date)

df3 <- df2 %>%
  filter(muni=="Jackson") %>%
  select(owner, owner1, owner2, prop_addr, muni, acres, full_marke, sale_price, sale_date) %>%
  mutate(ppa=full_marke / acres) %>%
  arrange(desc(full_marke)) %>%
  filter(row_number() <= 50)


```


# DATA ANALYSIS
```{r load_data}
uvacs <- readRDS(here::here("data", "uvacs.rds"))
acsdata <- readRDS(here::here("data", "acsdata.rds"))
# popwash <- readRDS(here::here("data", "popproj_pad_washco.rds"))
popproj <- readRDS(here::here("data", "popproj_pad_cnty.rds"))
popannold <- readRDS(file.path(dcenpop, "popann.rds"))
popann <- readRDS(file.path(dcenpop, "popann2020.rds"))
census2020 <- readRDS(file.path(dpl, "census2020plny.rds"))

# count(acsdata, tableid, concept)
names(census2020)
tmp <- census2020 %>%
  filter(stusab=="NY", 
         as.integer(sumlev) < 200, 
         !sumlev %in% c("140", "150"),
         !str_detect(name, "(part)")) %>%
  select(sumlev, geoid, geocode, county, basename, name, pop100, hu100)
count(tmp, sumlev)

tmp2 <- tmp %>%
  mutate(geoidold=geoid,
         usgeoname=name)
#         geoid=ifelse(sumlev %in% c("040", "050", "060"), paste0(sumlev, "00US", geocode), geoidold))


pop2020 <- subareas %>%
  left_join(tmp2 %>% select(-geoid), by="usgeoname") %>%
  select(geoid, sgeotype, usgeoname, basename, name, pop100, hu100)


tmp %>%
  filter(str_detect(name, "White Creek"))
tmp %>%
  filter(str_detect(name, "Cambridge town"))

subareas %>%
  filter(str_detect(usgeoname, "White Creek"))

```



# Population in and around the Village of Cambridge

```{r load_info}
#.. get all lookup information ----
# we want these data frames in the environment
geoall <- readRDS(paste0(dacssf, "geoall.rds"))
sumlevels <- readRDS(paste0(dacssf, "sumlevels.rds"))
tabseq <- readRDS(paste0(dacssf, "tabseq.rds"))
varsall <- readRDS(paste0(dacssf, "varsall.rds"))
tabdescribe <- readRDS(paste0(dacssf, "tabdescribe.rds"))

ds2009 <- paste0(dny2009, "em20095ny.parquet")
ds2014 <- paste0(dny2014, "em20145ny.parquet")
ds2019 <- paste0(dny2019, "em20195ny.parquet")
dspaths <- c(ds2009, ds2014, ds2019)

source(here::here("r", "functions_acssf.r"), verbose = TRUE)

```


```{r define_geos}
gpath <- r"(E:\data\acs\sf\boyd_acs_table_tools.xlsx)"
geodf <- read_excel(gpath, sheet="geos_keep", skip=1)
keepdf <- geodf %>% filter(keep==1)

geokeep <- geoall %>%
  filter(geoid %in% keepdf$geoid)
geokeep

subareas <- geokeep %>%
  mutate(statekeep=sgeotype=="state" & geoid %in% c("04000US36", "04043US36"),
         countykeep=sgeotype=="county" & 
           str_detect_any(usgeoname, c("Saratoga", "Warren", "Washington")),
         washcotown=sgeotype=="cosub" & str_sub(geoid, 8, 12)=="36115", # Washco towns
         droptown=washcotown & str_detect_any(usgeoname, c("Dresden", "Hampton", "Putnam")),
         townkeep=washcotown & !droptown,
         villagekeep=sgeotype=="place" & !str_detect_any(usgeoname, "Schuy")) %>%
  mutate(anykeep=statekeep | countykeep | townkeep | villagekeep) %>%
  filter(anykeep) %>%
  select(!contains("keep"))

```


```{r get_save_acs_tables}
tabdescribe
count(tabdescribe, subject)
tmp <- tabdescribe %>% filter(subject=="Educational Attainment", year==2019)
count(tabdescribe %>% filter(table=="B01001"), year)
count(tabdescribe %>% filter(table=="B07009"), year)
count(tabdescribe %>% filter(table=="B15001"), year)
count(tabdescribe %>% filter(table=="B15002"), year)
count(tabdescribe %>% filter(table=="B15003"), year)


tabdescribe %>% 
  filter(table=="C24050", year==2019) %>%
  select(tabtitle)

# .. population -- get the fewest-variables table for total population ----
#.. B01003	Total population ----
tab_B01003 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B01003")
glimpse(tab_B01003)
saveRDS(tab_B01003, here::here("data", "tab_B01003.rds"))

#.. B01002	 		MEDIAN AGE BY SEX ----
# B01002	 		Universe:  Total population
# B01002	0.5		Median age --
# B01002	1	B01002_001	Total:
# B01002	2	B01002_002	Male
# B01002	3	B01002_003	Female
tab_B01002 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B01002")
tab_B01002
saveRDS(tab_B01002, here::here("data", "tab_B01002.rds"))

#.. B01001 Sex By Age ----
tab_B01001 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B01001")
tab_B01001
saveRDS(tab_B01001, here::here("data", "tab_B01001.rds"))

#.. B06012 poverty ----
tab_B06012 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B06012")
tab_B06012
saveRDS(tab_B06012, here::here("data", "tab_B06012.rds"))

#.. educational attainment ----
#.. B07009 GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR CURRENT RESIDENCE IN THE UNITED STATES
tab_B07009 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B07009")
tab_B07009
saveRDS(tab_B07009, here::here("data", "tab_B07009.rds"))

tab_B15001 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B15001")
tab_B15001
saveRDS(tab_B15001, here::here("data", "tab_B15001.rds"))

#.. B07001 Geographical Mobility In The Past Year By Age For Current Residence In The United States ----
tab_B07001 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B07001")
tab_B07001
saveRDS(tab_B07001, here::here("data", "tab_B07001.rds"))


#.. B07409 GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR RESIDENCE 1 YEAR AGO IN THE UNITED STATES
tab_B07409 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B07409")
tab_B07409
saveRDS(tab_B07409, here::here("data", "tab_B07409.rds"))


#.. B07403 GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY SEX FOR RESIDENCE 1 YEAR AGO IN THE UNITED STATES ----


# .. B09005 HOUSEHOLD TYPE FOR CHILDREN UNDER 18 YEARS IN HOUSEHOLDS (EXCLUDING HOUSEHOLDERS, SPOUSES, AND UNMARRIED PARTNERS) ----
tab_B09005 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B09005")
tab_B09005
saveRDS(tab_B09005, here::here("data", "tab_B09005.rds"))

#.. B11001  HOUSEHOLD TYPE (INCLUDING LIVING ALONE) ----
tab_B11001 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B11001")
tab_B11001
saveRDS(tab_B11001, here::here("data", "tab_BB11001.rds"))


#.. B15002 SEX BY EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER ----
tab_B15002 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B15002")
tab_B15002
saveRDS(tab_B15002, here::here("data", "tab_B15002.rds"))

# tab_C15002 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "C15002")

#.. B19013 MEDIAN HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2019 INFLATION-ADJUSTED DOLLARS) ----
tab_B19013 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B19013")
tab_B19013
saveRDS(tab_B19013, here::here("data", "tab_B19013.rds"))


#.. B19113 MEDIAN FAMILY INCOME IN THE PAST 12 MONTHS (IN 2019 INFLATION-ADJUSTED DOLLARS) ----

# HOUSING ---- https://censusreporter.org/topics/housing/ the American Community
# Survey also gathers extensive data about the housing conditions of
# respondents, including whether they own or rent their home, how much they
# spend on housing, and the physical characteristics of homes. The ACS primarily
# reports housing data in tables with codes beginning with 25.

# Every housing unit is recorded as either occupied or vacant. Some vacancies
# are market related, such as houses for sale or apartments for rent. Other
# housing units are seasonally vacant. Table B25004 (Vacancy Status) records the
# number of vacancies in each category.

#.. B25004: Vacancy Status ----
tab_B25004 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B25004")
tab_B25004
saveRDS(tab_B25004, here::here("data", "tab_B25004.rds"))

#.. B25008  TOTAL POPULATION IN OCCUPIED HOUSING UNITS BY TENURE ----
tab_B25008 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B25008")
tab_B25008
saveRDS(tab_B25008, here::here("data", "tab_B25008.rds"))

#.. B25037	Median Year Structure Built by Tenure ----
tab_B25037 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B25037")
tab_B25037
saveRDS(tab_B25037, here::here("data", "tab_B25037.rds"))

#.. B25071: Median Gross Rent as a Percentage of Household Income (Dollars) ----
tab_B25071 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B25071")
tab_B25071
saveRDS(tab_B25071, here::here("data", "tab_B25071.rds"))

#.. B25077 Owner-occupied housing units Median Value (Dollars)  ----
tab_B25077 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B25077")
tab_B25077
saveRDS(tab_B25077, here::here("data", "tab_B25077.rds"))

#.. B25092: Median Selected Monthly Owner Costs as a Percentage of Household Income ----
tab_B25092 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B25092")
tab_B25092
saveRDS(tab_B25092, here::here("data", "tab_B25092.rds"))

#.. B25106	Tenure by Housing Costs as a Percentage of Household Income ----
# https://censusreporter.org/tables/B25106/
tab_B25106 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B25106")
tab_B25106
saveRDS(tab_B25106, here::here("data", "tab_B25106.rds"))


#.. NO DATA C15003 EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER ----
# tab_C15003 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "C15003")
# tab_C15003
# saveRDS(tab_C15003, here::here("data", "tab_C15003.rds"))


#.. C24050 Industry By Occupation For The Civilian  Employed Population 16 Years And Over ----
tab_C24050 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "C24050")
tab_C24050
saveRDS(tab_C24050, here::here("data", "tab_C24050.rds"))
# tab_C24050 %>% filter(geoid=="16000US3611825", year==2019) %>% write_csv(here::here("data", "check.csv"))

#.. C24060 OCCUPATION BY CLASS OF WORKER FOR THE CIVILIAN EMPLOYED POPULATION 16 YEARS AND OVER ----
tab_C24060 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "C24060")
tab_C24060
saveRDS(tab_C24060, here::here("data", "tab_C24060.rds"))

# C25004	 		VACANCY STATUS


```

```{r functions_census_acs_tables}
fcenpop_table <- function(tabdata, .title){
  fnote <- "NOTE: 2020 Decennial estimate for Greenwich village is considerably lower than previous Census Bureau annual estimates."
  tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(stabbr, sgeotype)) %>%
  tab_header(
    title = .title
      ) %>%
  cols_label(usgeoname="",
             pop2010="2010",
             pop2020="2020",
             change=html("change"),
             pch=html("% change")
             ) %>%
  # tab_spanner(
  #   label = html("Percent change"),
  #   columns = contains("pch")
  #   ) %>%
  cols_align(align="left", columns = usgeoname) %>%
  fmt_number(
    columns=c(pop2010, pop2020, change),
    decimals=0
  ) %>%
  fmt_percent(
    columns = pch,
    decimals = 1) %>%
  tab_source_note(paste0("Source: ", source_decennialpop, " (Redistricting file for 2020).")) %>%
  tab_footnote(
    footnote = fnote,
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      # cell_text(weight = "bold") # size = px(15), , font = "arial"
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ pct(50),
    everything() ~ pct(50)
    ) %>%
  tab_options(
    table.width = pct(100)
  )
  # cols_width(
  #   usgeoname ~ px(150),
  #   starts_with("y") ~ px(100),
  #   starts_with("pch") ~ px(100)
  # )
  # %>%   tab_options(row_group.as_column=TRUE)
  # cells_row_groups()
tab
}

fpch_table <- function(tabdata, .title, ydecimals=0){
  tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(table, tabvarname, sgeotype, geoid)) %>%
  tab_header(
    title = .title
      ) %>%
  cols_label(usgeoname="",
             y2009="2009",
             y2014="2014",
             y2019="2019",
             pch0914=html("2009<br>to 2014"),
             pch1419=html("2014<br>to 2019"),
             pch0919=html("2009<br>to 2019"),
             ) %>%
  tab_spanner(
    label = html("5-years ending in:"),
    columns = starts_with("y")
    ) %>%
  tab_spanner(
    label = html("Percent change"),
    columns = starts_with("pch")
    ) %>%
  cols_align(align="left", columns = usgeoname) %>%
  fmt_number(
    columns=starts_with("y"),
    decimals=ydecimals
  ) %>%
  fmt_percent(
    columns = starts_with("pch"),
    decimals = 1) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      # cell_text(weight = "bold") # size = px(15), , font = "arial"
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ px(150),
    starts_with("y") ~ px(100),
    starts_with("pch") ~ px(100)
  )
  # %>%   tab_options(row_group.as_column=TRUE)
  # cells_row_groups()
tab
}


fch_table <- function(tabdata, .title, decimals=1, type="number"){
  if(type=="percent") {
    scale <- 100
    pattern <- "{x}%"
    } else {
      scale=1
      pattern <- "{x}"
    }
  tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(any_of(c("table", "tabvarname", "sgeotype", "geoid"))) %>%
  tab_header(
    title = .title
      ) %>%
  cols_label(usgeoname="",
             y2009="2009",
             y2014="2014",
             y2019="2019",
             ch0914=html("2009<br>to 2014"),
             ch1419=html("2014<br>to 2019"),
             ch0919=html("2009<br>to 2019"),
             ) %>%
  tab_spanner(
    label = html("5-years ending in:"),
    columns = starts_with("y")
    ) %>%
  tab_spanner(
    label = html("Change"),
    columns = starts_with("ch")
    ) %>%
  cols_align(align="left", columns = usgeoname) %>%
  fmt_number(
    columns=c(starts_with("y"), starts_with("ch")),
    decimals=decimals,
    scale_by = scale,
    pattern = pattern,
  ) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      # cell_text(weight = "bold") # size = px(15), , font = "arial"
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  # cols_width(
  #   usgeoname ~ px(250),
  #   starts_with("y") ~ px(150),
  #   starts_with("ch") ~ px(150)
  # ) %>%
  cols_width(
    usgeoname ~ pct(60),
    everything() ~ pct(40)
    ) %>%
  tab_options(
    table.width = pct(100)
  )
  # %>%   tab_options(row_group.as_column=TRUE)
  # cells_row_groups()
tab
}

```


## Population size

```{r pop_decennial}
# count(popann %>% filter(state=="36"), sgeotype)

# popann %>% filter(state=="36", year==2020, str_detect(geoname, "Salem"))
# popannold %>% filter(state=="36", year==2020, str_detect(geoname, "Salem"))

census2010pop <- popann %>%
  filter(state=="36", 
         !is.na(sgeotype), 
         name=="popcensus2010",
         !str_detect(geoname, "(pt.)"),
         !str_detect(geoname, "Balance")) %>%
  filter(sgeotype=="state" | 
           sgeotype=="county" & str_detect_any(geoname, c("Saratoga", "Warren", "Washington")) |
           sgeotype=="cosub" & county=="115" |
           sgeotype=="place") %>%
  select(sgeotype, usgeoname=geoname, pop2010=value) %>%
  inner_join(subareas %>%
               filter(year==2019) %>%
               select(stabbr, geoid, sgeotype, usgeoname),
              by = c("sgeotype", "usgeoname"))

census2020pop <- subareas %>%
  filter(year==2019) %>%
  mutate(geocode=str_sub(geoid, 8, -1)) %>%
  select(stabbr, geoid, geocode, sgeotype, usgeoname) %>%
  left_join(census2020 %>%
              select(usgeoname=name, geocode, pop2020=pop100),
            by=c("usgeoname", "geocode"))

tabdata <- census2010pop %>%
  left_join(census2020pop %>%
              select(geoid, usgeoname, pop2020),
            by=c("geoid", "usgeoname")) %>%
  select(stabbr, sgeotype, usgeoname, pop2010, pop2020) %>%
  mutate(change=pop2020 - pop2010, 
         pch=change / pop2010,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata
  
tab <- fcenpop_table(tabdata, "Decennial census population in 2010 and 2020")
tab
# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_decennialpop.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_decennialpop_data.csv"))

```



```{r popann_census}
# prep popann data
glimpse(subareas)
count(subareas, year)
tmp <- count(popann %>% filter(state=="36"), geoname)
popann %>% filter(state=="36", str_detect(geoname, "Washington Cou"))
glimpse(popann)

pophist <- subareas %>%
  filter(year==2019) %>%
  select(stabbr, geoid, sgeotype, usgeoname) %>%
  inner_join(popann %>%
               filter(state=="36", !is.na(sgeotype)) %>%
               select(sgeotype, geoid, popgeoname=geoname, year, esttype, value), by = c("geoid", "sgeotype"))

count(pophist, usgeoname)

base <- 2010
pdata <- pophist %>%
  # filter(str_detect_any(usgeoname, c("Cambridge village", "Greenwich village"))) %>%
  filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
  filter(!str_detect(usgeoname, "Greenwich town")) %>%
  filter(esttype=="est") %>%
  mutate(year=as.integer(year)) %>%
  filter(year >= base) %>%
  group_by(geoid, usgeoname) %>%
  mutate(ivalue=value / value[year==base],
         cumpch=ivalue - 1) %>%
  ungroup

capt1 <- "Note: Several 2020 estimates are considerably different from corresponding decennial estimates."
capt2 <- paste0("Source: ", source_cenpop, ", 2020 vintage.")
capt <- paste0(capt1, "\n", capt2)
p <- pdata %>%
  ggplot(aes(year, cumpch, colour=usgeoname)) +
  geom_line(size=1) +
  geom_point(size=1.5) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(name=NULL, breaks=seq(2010, 2020, 1)) +
  scale_y_continuous(name=paste0("% change since ", base), 
                     breaks=seq(-1, 1, .005), 
                     labels=label_percent(accuracy=.1),
                     limits=c(NA, NA)) +
  scale_colour_discrete(name="age group") +
  ggtitle(label="Cambridge and selected other areas",
          subtitle = "Cumulative % change in population since 2010") +
  labs(caption = capt) +
  theme_bw() +
  caption_left +
  legend_notitle
p

ggsave(here::here("results", "fig_annpop.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_annpop_data.csv"))

# https://www.census.gov/content/dam/Census/programs-surveys/acs/guidance/training-presentations/20180418_MOE.pdf
# At a given confidence level, the estimate and the actual population value
# will differ by no more than the value of the MOE; 90% confidence level is the
# Census Bureau Standard (Margin of Error MOE = 1.645 x SE)

# quick check vs Census
# pophist %>%
#   filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
#   filter(!str_detect(usgeoname, "Greenwich town"), year %in% c(2010, 2020), esttype %in% c("est", "census")) %>%
#   filter(!is.na(popgeoname)) %>%
#   select(-stabbr, -popgeoname) %>%
#   pivot_wider(names_from = esttype) %>%
#   mutate(diff=est - census,
#          pdiff=diff / census)


# pophist %>%
#   filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
#   filter(!str_detect(usgeoname, "Greenwich town"), year %in% c(2010, 2020), esttype %in% c("est", "census")) %>%
#   filter(!is.na(popgeoname)) %>%
#   select(-stabbr, -popgeoname) %>%
#   pivot_wider(names_from = esttype) %>%
#   mutate(diff=est - census,
#          pdiff=diff / census)


# popcheck <- pophist %>%
#   filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
#   filter(!str_detect(usgeoname, "Greenwich town"), year %in% c(2010, 2020), esttype %in% c("est", "census")) %>%
#   mutate(esttype=ifelse(year==2020 & esttype=="census", "censusest", esttype)) %>%
#   filter(!is.na(popgeoname)) %>%
#   select(-stabbr, -popgeoname) %>%
#   pivot_wider(names_from=c(esttype, year)) %>%
#   left_join(pop2020 %>%
#               select(sgeotype, usgeoname, census_2020=pop100) %>%
#               filter(!is.na(census_2020)) %>%
#               distinct(),
#             by = c("sgeotype", "usgeoname"))

# %>%
  # pivot_longer(-c(geoid, sgeotype, usgeoname)) %>%
  # separate(name, c("esttype", "year")) %>% 
  # pivot_wider(names_from = year, names_prefix = "y")
# popcheck %>%
#   mutate(ee=est_2020 / est_2010 - 1,
#          cc=census_2020 / census_2010 - 1,
#          cce=censusest_2020 / census_2020 -1) %>%
#   select(-c(geoid, sgeotype)) %>%
#   gt() %>%
#   fmt_percent(
#     columns = c(ee, cc, cce),
#     decimals = 1)


```


```{r fig_copopproj}
pdata <- popproj %>%
  filter(sex=="all", agecode==-999) %>%
  group_by(county) %>%
  mutate(pdvalue=value / value[year==2015] - 1)

p <- pdata %>%
  ggplot(aes(year, pdvalue, colour=county)) +
  geom_line() +
  geom_point()

capt <- paste0("Source: ", source_cornell, ", as released in 2018.")
p <- pdata %>%
  ggplot(aes(year, pdvalue, colour=county)) +
  geom_line(size=1) +
  geom_point(size=1.5) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(name=NULL, breaks=seq(2010, 2040, 5)) +
  scale_y_continuous(name=paste0("% change since 2015"), 
                     breaks=seq(-1, 1, .02), 
                     labels=label_percent(accuracy=1),
                     limits=c(NA, NA)) +
  scale_colour_discrete(name="county") +
  ggtitle(label="Projected population in selected counties",
          subtitle = "Cornell estimates released in 2018") +
  labs(caption = capt) +
  theme_bw() +
  caption_left +
  legend_notitle
p

ggsave(here::here("results", "fig_copopproj.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_copopproj_data.csv"))

```



```{r fig_washcoproj_age}
glimpse(popwash)
count(popwash, agecode, agegrp) %>% ht

pdata1 <- popwash %>%
  filter(sex=="all") %>%
  mutate(agegrp2=case_when(agecode == -999 ~ "total",
                           agecode %in% 0:17 ~ "agele17",
                           agecode %in% 18:24 ~ "age1824",
                           agecode %in% 25:34 ~ "age2534",
                           agecode %in% 35:44 ~ "age3544",
                           agecode %in% 45:64 ~ "age4564",
                           agecode %in% 65:84 ~ "age6584",
                           agecode == 85 ~ "age85p",
                           agecode == 999 ~ "median")) %>%
  group_by(year, agegrp=agegrp2) %>%
  summarise(n=n(), value=sum(value), .groups="drop")

pdata1
pdata1 %>% filter(agegrp=="median") %>% ggplot(aes(year, value)) + geom_line() + geom_point()

pdata1 %>%
  filter(str_detect(agegrp, "age")) %>%
  ggplot(aes(year, value, colour=agegrp)) +
  geom_line() +
  geom_point()

capt1 <- "Note: vertical axis does not start at zero."
capt2 <- paste0("Source: ", source_padcoproj, ".")
capt <- paste0(capt1, "\n", capt2)
pdata <- pdata1 %>%
  filter(str_detect(agegrp, "age")) %>%
  mutate(agegrp = case_when(agegrp %in% c("agele17", "age1824") ~ "agele24",
                            agegrp %in% c("age2534", "age3544") ~ "age2544",
                            agegrp %in% c("age6584", "age85p") ~ "age65p",
                            TRUE ~ agegrp)) %>%
  group_by(year, agegrp) %>%
  summarise(value=sum(value), .groups="drop")

p <- pdata %>%
  mutate(agegrp=factor(agegrp, 
                       levels=c("agele24", "age2544", "age4564", "age65p"),
                       labels=c("<= 24", "25-44", "45-64", "65+"))) %>%
  # arrange(year, agegrp) %>%
  ggplot(aes(year, value, colour=agegrp)) +
  geom_line(size=1) +
  geom_point(size=1) +
  scale_x_continuous(name=NULL) +
  scale_y_continuous(name="# of people", 
                     breaks=seq(0, 60e3, 2e3), 
                     labels=label_comma(accuracy=1),
                     limits=c(NA, NA)) +
  scale_colour_discrete(name="age group") +
  ggtitle("Cornell population projections for Washington County") +
  labs(caption = capt) +
  theme_bw() +
  caption_left
p

ggsave(here::here("results", "fig_washco_popproj.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_washco_popproj_data.csv"))

```


```{r acspop_DONOTUSE}
# do not use ACS for trends in total population
tab_B01003 <- readRDS(here::here("data", "tab_B01003.rds"))
count(tab_B01003, tabvarname, vdescription)

tabdata <- tab_B01003 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  select(year, table, tabvarname, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(pch0914=y2014 / y2009 - 1,
         pch1419=y2019 / y2014 - 1,
         pch0919=y2019 / y2009 - 1,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fpch_table(tabdata, .title="Population in selected areas", ydecimals=0)
gtsave(tab, filename="tab_poptot.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_poptot_data.csv"))

```

## Household structure
```{r}
tab_B11001 <- readRDS(here::here("data", "tab_BB11001.rds"))
tab_B09005 <- readRDS(here::here("data", "tab_B09005.rds"))

```

### Single parent or householder families
```{r}
# B09005	 		HOUSEHOLD TYPE FOR CHILDREN UNDER 18 YEARS IN HOUSEHOLDS (EXCLUDING HOUSEHOLDERS, SPOUSES, AND UNMARRIED PARTNERS)
# B09005	 		Universe:  Population under 18 years in households (excluding householders, spouses, and unmarried partners)
# B09005	1	B09005_001	Total:
# B09005	2	B09005_002	Married-couple household
# B09005	3	B09005_003	Cohabiting couple household
# B09005	4	B09005_004	In male householder, no spouse/partner present household
# B09005	5	B09005_005	In female householder, no spouse/partner present household
tmp <- count(tab_B09005, vnum, tabvarname, vdescription)
tmp <- tabdescribe %>% filter(table=="B09005")

tabdata <- tab_B09005 %>%
  filter(geoid %in% subareas$geoid, valtype=="est", vnum %in% c(1, 4, 5)) %>%
  mutate(vnum=factor(vnum, levels=c(1, 4, 5), labels=c("children", "malehead", "femalehead"))) %>%
  select(year, table, vnum, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = vnum) %>%
  mutate(singlepct=(malehead + femalehead) / children) %>%
  select(year, table, sgeotype, geoid, usgeoname, value=singlepct) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Percent of children living in households with only one household head", 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_singleheads.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_singleheads_data.csv"))
\

```



## Age

### Median age
```{r tab_median_age}
# tab <- "B01002"
tab_B01002 <- readRDS(here::here("data", "tab_B01002.rds"))
count(tab_B01002, tabvarname, vdescription)

tabdata <- tab_B01002 %>%
  filter(geoid %in% subareas$geoid, valtype=="est", tabvarname=="B01002_001") %>%
  select(year, table, tabvarname, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, .title="Median age in selected areas", ychdecimals=1)
tab
gtsave(tab, filename="tab_mdnage.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_mdnage_data.csv"))

```

### Age breakdown
```{r}
glimpse(tab_B01001)

varsall %>%
  filter(table=="B01001", year==2019) %>%
  arrange(vnum) %>%
  select(year, table, vnum, vname, vdescription)
# vnum: total is 1, 25 to 34 
# 2, 26 total male, female
# 11, 12 25-34 male
# 35, 36 25-34 female

td1 <- tab_B01001 %>%
  filter(vnum %in% c(2, 6, 11:12, 35:36),
         valtype=="est") %>%
  mutate(group=case_when(vnum %in% c(2, 26) ~ "total",
                         TRUE ~ "age2534")) %>%
  group_by(year, group) %>%
  summarise(value=sum(value), .groups="drop")

tabvars <- tab_B01001 %>%
  filter(year==2019)
  group_by(tabvarname)
tabvars <- count(tab_B01001, tabvarname, vdescription) %>%
  separate(vdescription, into=paste0("v", 1:8), sep="%", remove = FALSE)

```





```{r fig_pop_pyramid_areas}
tab_B01001 <- readRDS(here::here("data", "tab_B01001.rds"))
count(tab_B01001, tabvarname, vdescription)
glimpse(tab_B01001)

geokeeps <- c(newyork_state, washington_county, cambridge_village, greenwich_village)
# geokeeps <- c(newyork_state, washington_county, cambridge_village, greenwich_village,
#               cambridge_town, greenwich_town)

geokeeps <- subareas %>% 
  filter(year==2019) %>%
  select(geoid, sgeotype, usgeoname) %>%
  filter(geoid %in% c("04043US36", "05000US36115", "16000US3611825", "16000US3630675"))

# vnum ranges for age groups
agegroups <- read_csv(
"agegroup, agelabel, flow, fhigh, mlow, mhigh
0, total, 26, 26, 2, 2
1, <= 17, 27, 30, 3, 6
2, 18 to <= 24, 31, 34, 7, 10
3, 25 to <= 34, 35, 36, 11, 12
4, 35 to <= 64, 37, 43, 13, 19
5, 65 to <= 84, 44, 48, 20, 24
6, >=85, 49, 49, 25, 25")

# vnum values for age groups - vnums for female low, high, then male
# finer groups
agegroups <- read_csv(
"agegroup, agelabel, flow, fhigh, mlow, mhigh
0, total, 26, 26, 2, 2
1, <= 17, 27, 30, 3, 6
2, 18 to <= 24, 31, 34, 7, 10
3, 25 to <= 34, 35, 36, 11, 12
4, 35 to <= 44, 37, 38, 13, 14
5, 45 to <= 64, 39, 43, 15, 19
5, 65 to <= 84, 44, 48, 20, 24
6, >=85, 49, 49, 25, 25")

vals <- function(low, high) {
  tibble(vnum=low:high)
}

agegroups_long <- agegroups %>%
  pivot_longer(-c(agegroup, agelabel)) %>%
  mutate(sex=str_sub(name, 1, 1),
         type=str_sub(name, 2, -1)) %>%
  select(-name) %>%
  pivot_wider(names_from = type) %>%
  mutate(sex=factor(sex, levels=c("m", "f"), labels=c("male", "female"))) %>%
  group_by(agegroup, agelabel, sex) %>%
  summarise(vals(low, high), .groups="drop")

pdata <- tab_B01001 %>%
  filter(year==2019, valtype=="est") %>%
  filter(geoid %in% geokeeps$geoid) %>%
  select(year, table, geoid, sgeotype, usgeoname, vnum, value, vdescription) %>%
  left_join(agegroups_long, by="vnum") %>%
  filter(!is.na(sex), agegroup!=0) %>% # keep just the details
  group_by(sgeotype, geoid, usgeoname, sex, agegroup, agelabel, year) %>%
  summarise(value=sum(value), .groups="drop") %>% # sums by agegroup and sex
  # now get pct share of area total population
  group_by(sgeotype, geoid, usgeoname, year) %>%
  mutate(totpop=sum(value),
         share=value / totpop) %>%
  ungroup %>%
  # put areas in desired order
  mutate(geoid=factor(geoid, levels=geokeeps$geoid),
         order=as.integer(geoid),
         usgeoname=fct_reorder(usgeoname, order, min),
         pshare=ifelse(sex=="male", -share, share)) %>% # order we want
  arrange(usgeoname, year)

# check the sums
pdata %>%
  group_by(usgeoname) %>%
  summarise(value=sum(value),
            share=sum(share),
            totpop=first(totpop))

clrs_br <- c("blue", "red")
clrs <- c('#ef8a62', '#67a9cf') %>% rev()
brks <- seq(-1, 1, .05)
brk_labs <- percent(abs(brks), accuracy=.1)
p <- pdata %>%
  ggplot(aes(x=pshare,
             y=reorder(agelabel, agegroup),
             fill = sex)) + 
  geom_bar(stat = "identity") +
  scale_x_continuous(name="% of the area's total population", breaks=brks,
                     labels = percent(abs(brks), accuracy=.1)) +
  scale_y_discrete(name=NULL) +
  scale_fill_manual(values=clrs) +
  theme_bw() +
  legend_notitle +
  ggtitle("Population share by age group, for the 5 years ending in 2019") +
  facet_wrap(~ usgeoname, ncol = 2)
  # theme(axis.text.x = element_text(angle = 90, hjust = 1))
p

ggsave(here::here("results", "fig_pop_pyramid_areas.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_pop_pyramid_areas_data.csv"))

```


```{r fig_pop_pyramid_years}
#.. moes are too large to trust any of this! ----
# finer groups
agegroups <- read_csv(
"agegroup, agelabel, flow, fhigh, mlow, mhigh
0, total, 26, 26, 2, 2
1, <= 17, 27, 30, 3, 6
2, 18 to <= 24, 31, 34, 7, 10
3, 25 to <= 34, 35, 36, 11, 12
4, 35 to <= 44, 37, 38, 13, 14
5, 45 to <= 64, 39, 43, 15, 19
5, 65 to <= 84, 44, 48, 20, 24
6, >=85, 49, 49, 25, 25")


vals <- function(low, high) {
  tibble(vnum=str_pad(low:high, width = 3, side = "left", pad = "0"))
}

agegroups_long <- agegroups %>%
  pivot_longer(-c(agegroup, agelabel)) %>%
  mutate(sex=str_sub(name, 1, 1),
         type=str_sub(name, 2, -1)) %>%
  select(-name) %>%
  pivot_wider(names_from = type) %>%
  mutate(sex=factor(sex, levels=c("m", "f"), labels=c("male", "female"))) %>%
  group_by(agegroup, agelabel, sex) %>%
  summarise(vals(low, high), .groups="drop")

acsdata %>%
  filter(tableid=="B01001") %>%
  count(ulab4, ulab3, vnum) 

acsdata %>%
  filter(tableid=="B01001", geoid==cambridge_village, year==2019)
  
tmp <- acsdata %>%
  filter(tableid=="B01001",
         geoid ==cambridge_village) %>%
  select(geotype, geoid, sname, variable, year, estimate, moe, concept, 
         vnum, ulab3, ulab4, ulabel) %>%
  left_join(agegroups_long, by="vnum") %>%
  filter(!is.na(sex)) %>%
  group_by(geotype, geoid, sname, sex, agegroup, agelabel, year) 

tmp %>% filter(year==2019) %>%
  select(geotype, sname, year, vnum, sex, agegroup, agelabel, estimate, moe) %>%
  mutate(moepct=moe / estimate)
  

basedata <- acsdata %>%
  filter(tableid=="B01001",
         geoid ==cambridge_village) %>%
  select(geotype, geoid, sname, variable, year, estimate, moe, concept, 
         vnum, ulab3, ulab4, ulabel) %>%
  left_join(agegroups_long, by="vnum") %>%
  filter(!is.na(sex)) %>%
  group_by(geotype, geoid, sname, sex, agegroup, agelabel, year) %>%
  summarise(estimate=sum(estimate), .groups="drop") %>%
  # now get pct share of area total population
  group_by(geotype, geoid, sname, year) %>%
  mutate(share=estimate / estimate[agegroup==0]) %>%
  ungroup

basedata %>%
  filter(geoid==cambridge_village, year==2019)

pdata <- basedata %>%
  filter(agegroup!=0) %>%  # geoid %in% c(cambridge_village, greenwich_village), 
  mutate(geoid=factor(geoid, levels=geokeeps),
         order=as.integer(geoid),
         sname=fct_reorder(sname, order, min),
         pshare=ifelse(sex=="male", -share, share)) %>% # order we want
  arrange(sname, year)

clrs_br <- c("blue", "red")
clrs <- c('#ef8a62', '#67a9cf') %>% rev()
brks <- seq(-1, 1, .1)
brk_labs <- percent(abs(brks), accuracy=.1)
p <- pdata %>%
  ggplot(aes(x=pshare,
             y=reorder(agelabel, agegroup),
             fill = sex)) + 
  geom_bar(stat = "identity") +
  scale_x_continuous(name="% of the area's total population", breaks=brks,
                     labels = percent(abs(brks), accuracy=.1)) +
  scale_y_discrete(name=NULL) +
  scale_fill_manual(values=clrs) +
  theme_bw() +
  legend_notitle +
  ggtitle("Population share by age group") +
  facet_wrap(~ year, ncol = 1)
  # theme(axis.text.x = element_text(angle = 90, hjust = 1))

p

ggsave(here::here("results", "fig_pop_pyramid_years.png"), plot=p, width=8, height=10, scale=1)
write_csv(pdata, here::here("results", "fig_pop_pyramid_years_data.csv"))

```

```{r fig_washco_popproj}
glimpse(popwash)
count(popwash, agecode, agegrp) %>% ht

pdata1 <- popwash %>%
  filter(sex=="all") %>%
  mutate(agegrp2=case_when(agecode == -999 ~ "total",
                           agecode %in% 0:17 ~ "agele17",
                           agecode %in% 18:24 ~ "age1824",
                           agecode %in% 25:34 ~ "age2534",
                           agecode %in% 35:44 ~ "age3544",
                           agecode %in% 45:64 ~ "age4564",
                           agecode %in% 65:84 ~ "age6584",
                           agecode == 85 ~ "age85p",
                           agecode == 999 ~ "median")) %>%
  group_by(year, agegrp=agegrp2) %>%
  summarise(n=n(), value=sum(value), .groups="drop")

pdata1
pdata1 %>% filter(agegrp=="median") %>% ggplot(aes(year, value)) + geom_line() + geom_point()

pdata1 %>%
  filter(str_detect(agegrp, "age")) %>%
  ggplot(aes(year, value, colour=agegrp)) +
  geom_line() +
  geom_point()

capt1 <- "Note: vertical axis does not start at zero."
capt2 <- paste0("Source: ", source_padcoproj, ".")
capt <- paste0(capt1, "\n", capt2)
pdata <- pdata1 %>%
  filter(str_detect(agegrp, "age")) %>%
  mutate(agegrp = case_when(agegrp %in% c("agele17", "age1824") ~ "agele24",
                            agegrp %in% c("age2534", "age3544") ~ "age2544",
                            agegrp %in% c("age6584", "age85p") ~ "age65p",
                            TRUE ~ agegrp)) %>%
  group_by(year, agegrp) %>%
  summarise(value=sum(value), .groups="drop")

p <- pdata %>%
  mutate(agegrp=factor(agegrp, 
                       levels=c("agele24", "age2544", "age4564", "age65p"),
                       labels=c("<= 24", "25-44", "45-64", "65+"))) %>%
  # arrange(year, agegrp) %>%
  ggplot(aes(year, value, colour=agegrp)) +
  geom_line(size=1) +
  geom_point(size=1) +
  scale_x_continuous(name=NULL) +
  scale_y_continuous(name="# of people", 
                     breaks=seq(0, 60e3, 2e3), 
                     labels=label_comma(accuracy=1),
                     limits=c(NA, NA)) +
  scale_colour_discrete(name="age group") +
  ggtitle("Cornell population projections for Washington County") +
  labs(caption = capt) +
  theme_bw() +
  caption_left
p

ggsave(here::here("results", "fig_washco_popproj.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_washco_popproj_data.csv"))

```


## Income and poverty
```{r tab_mhhi}
tab_B19013 <- readRDS(here::here("data", "tab_B19013.rds"))

tmp <- count(tab_B19013, vnum, tabvarname, vdescription)
tmp <- tabdescribe %>% filter(table=="B19013")


tabdata <- tab_B19013 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  select(year, table, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Median household income, in survey-end-year dollars", 
                 decimals=0,
                 type="number")
tab
gtsave(tab, filename="tab_mhhi.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_mhhi_data.csv"))

```


```{r tab_povrate}
tab_B06012 <- readRDS(here::here("data", "tab_B06012.rds"))
tmp <- count(tab_B06012, vnum, tabvarname, vdescription)
tmp <- tabdescribe %>% filter(table=="B06012")


tabdata <- tab_B06012 %>%
  filter(geoid %in% subareas$geoid, valtype=="est", vnum %in% c(1, 2)) %>%
  mutate(vnum=factor(vnum, levels=c(1, 2), labels=c("popknown", "poppov"))) %>%
  select(year, table, vnum, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = vnum) %>%
  mutate(povpct=poppov / popknown) %>%
  select(year, table, sgeotype, geoid, usgeoname, value=povpct) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Percent of population below the poverty level", 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_povrate.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_povrate_data.csv"))

```



## Educational attainment
```{r tab_edattain}
#.. GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR CURRENT RESIDENCE IN THE UNITED STATES
# tab_B07009 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B07009")
tab_B07009 <- readRDS(here::here("data", "tab_B07009.rds"))

tmp <- count(tab_B07009, vnum, tabvarname, vdescription)
tmp <- tabdescribe %>% filter(table=="B07009")
# 1 B07009_001 totpop
# 5 B07009_005 BA
# 6 B07009_006 Grad prof

tabdata <- tab_B07009 %>%
  filter(geoid %in% subareas$geoid, valtype=="est", vnum %in% c(1, 5, 6)) %>%
  mutate(vnum=factor(vnum, levels=c(1, 5, 6), labels=c("totpop", "ba", "gradplus"))) %>%
  select(year, table, vnum, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = vnum) %>%
  mutate(bapluspct=(ba + gradplus) / totpop) %>%
  select(year, table, sgeotype, geoid, usgeoname, value=bapluspct) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Percent of population age 25+ with bachelor's degree or higher", 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_edattain.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_edattain_data.csv"))

```


## Geographic mobility
```{r move_prep}
#.. moveins ----
#.. GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR CURRENT RESIDENCE IN THE UNITED STATES
# tab_B07009 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B07009")
tab_B07009 <- readRDS(here::here("data", "tab_B07009.rds"))

tmp <- count(tab_B07009, vnum, tabvarname, vdescription)

x <- "GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR CURRENT RESIDENCE IN THE UNITED STATES%Population 25 years and over in the United States"
tmp <- count(tab_B07009 %>% 
               filter(year==2019, vnum %in% c(1, 13, 19, 25, 31)) %>%
               mutate(vdescription=str_remove(vdescription, x)),
             vnum, tabvarname, vdescription)

tmp <- tabdescribe %>% filter(table=="B07009")
#  1 B07009_001 totpop25p
# 13 B07009_013 Moved within same county
# 19 B07009_019 Moved from different county within same state
# 25 B07009_025 Moved from different state
# 31 B07009_031 Moved from abroad

moveins <- tab_B07009 %>%
  filter(geoid %in% subareas$geoid, valtype=="est", vnum %in% c(1, 13, 19, 25, 31)) %>%
  mutate(vnum=factor(vnum, 
                     levels=c(1, 13, 19, 25, 31), 
                     labels=c("totpop25p",
                              "misamecnty",
                              "misamestate",
                              "midiffstate",
                              "miabroad"))) %>%
  select(year, table, vnum, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = vnum) %>%
  mutate(movein=(misamecnty + misamestate + midiffstate + miabroad),
         stay=totpop25p - movein,
         moveinpct=movein / totpop25p)

moveins %>%
  filter(str_detect(usgeoname, "Cambridge village"))

#.. moveouts ----
# note that we don't have moved abroad because they aren't in a U.S. survey anymore!
tab_B07409 <- readRDS(here::here("data", "tab_B07409.rds"))

x <- "GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR RESIDENCE 1 YEAR AGO IN THE UNITED STATES"
tmp <- count(tab_B07409 %>% 
               filter(year==2019) %>%
               filter(vnum %in% c(1, 13, 19, 25)) %>% # no code 31 for moved abroad!!
               mutate(vdescription=str_remove(vdescription, x)),
             vnum, tabvarname, vdescription)

moveouts <- tab_B07409 %>%
  filter(geoid %in% subareas$geoid, valtype=="est", vnum %in% c(1, 13, 19, 25, 31)) %>%
  mutate(vnum=factor(vnum, 
                     levels=c(1, 13, 19, 25), 
                     labels=c("totpop25p",
                              "mosamecnty",
                              "mosamestate",
                              "modiffstate"))) %>%
  select(year, table, vnum, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = vnum) %>%
  mutate(moveout=(mosamecnty + mosamestate + modiffstate),
         stay=totpop25p - moveout,
         moveoutpct=moveout / totpop25p)

moveouts %>%
  filter(str_detect(usgeoname, "Cambridge village"))

```


```{r tab_netmoves2019}

netmoves1 <- left_join(
  moveins %>% 
    filter(year==2019) %>% 
    select(year, table, sgeotype, geoid, usgeoname, stay, movein),
  moveouts %>% 
    filter(year==2019) %>%
    select(geoid, stay_check=stay, moveout),
  by="geoid")

tabdata <- netmoves1 %>%
  filter(!(is.na(movein) | is.na(moveout))) %>%
  filter(stay == stay_check) %>%
  select(-stay_check) %>%
  mutate(movenet=movein - moveout,
         across(c(movein, moveout, movenet),
                ~ .x / stay,
                .names = "pct_{.col}"),
         rowlab=get_rowlab(sgeotype))
tabdata

tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(year, table, sgeotype, geoid)) %>%
  tab_header(
    title = "Movement into and out of an area, average for the 5 years ending in 2019",
    subtitle = "Population 25 years and older"
      ) %>%
  cols_label(usgeoname="",
             stay=html("# in area in current <i>and</i> prior year"),
             movein="Moved in",
             moveout="Moved out",
             movenet="Net moves",
             pct_movein="Moved in",
             pct_movein="Moved out",
             pct_movenet="Net moves") %>%
  cols_align(align="left", columns = usgeoname) %>%
  tab_spanner(
    label = html("Number of people who moved"),
    columns = c(movein, moveout, movenet)
    ) %>%
  tab_spanner(
    label = html("Moves as % of those who stayed"),
    columns = c(pct_movein, pct_moveout, pct_movenet)
    ) %>%
  fmt_number(
    columns=c(stay, movein, moveout, movenet),
    pattern = "{x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pct"),
    decimals = 1) %>%
  # fmt_missing(columns=everything(), missing_text="") %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ pct(60),
    everything() ~ pct(40)
    ) %>%
  tab_options(
    table.width = pct(100)
  )

# webshot options
# default zoom=2, expand=5
tab
gtsave(tab, filename="tab_netmoves2019.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_netmoves2019_data.csv"))

```

```{r tab_moveins_where_2019}
tabdata <- moveins %>%
  filter(year==2019) %>%
  select(year, table, sgeotype, geoid, usgeoname, starts_with("mi"), movein) %>%
  relocate(movein, .after = usgeoname) %>%
  mutate(mitot=movein,
         across(starts_with("mi"), ~ .x / movein),
         rowlab=get_rowlab(sgeotype))

tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(year, table, sgeotype, geoid)) %>%
  tab_header(
    title = "Movement into an area by previous location, average for the 5 years ending in 2019",
    subtitle = "Population 25 years and older"
      ) %>%
  cols_label(usgeoname="",
             movein=html("Number who<br>moved in"),
             misamecnty="Same county",
             misamestate=html("Different county<br>in the state"),
             midiffstate="Different state",
             miabroad="Abroad",
             mitot="Total") %>%
  cols_align(align="left", columns = usgeoname) %>%
  tab_spanner(
    label = "Previous location (location as % of total who moved in)",
    columns = starts_with("mi")
    ) %>%
  fmt_number(
    columns=movein,
    pattern = "{x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = starts_with("mi"),
    decimals = 1) %>%
  # fmt_missing(columns=everything(), missing_text="") %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ pct(60),
    everything() ~ pct(40)
    ) %>%
  tab_options(
    table.width = pct(100)
  )

# webshot options
# default zoom=2, expand=5
tab
gtsave(tab, filename="tab_moveins_where_2019.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_moveins_where_2019_data.csv"))

```


```{r tab_moveins_age_2019}
# B07001	 		GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY AGE FOR CURRENT RESIDENCE IN THE UNITED STATES

# B07001	1	B07001_001	Total:
# B07001	2	B07001_002	1 to 4 years 
# B07001	3	B07001_003	5 to 17 years 
# B07001	4	B07001_004	18 and 19 years 
# B07001	5	B07001_005	20 to 24 years
# B07001	6	B07001_006	25 to 29 years
# B07001	7	B07001_007	30 to 34 years
# B07001	8	B07001_008	35 to 39 years
# B07001	9	B07001_009	40 to 44 years
# B07001	10	B07001_010	45 to 49 years
# B07001	11	B07001_011	50 to 54 years
# B07001	12	B07001_012	55 to 59 years 
# B07001	13	B07001_013	60 to 64 years 
# B07001	14	B07001_014	65 to 69 years 
# B07001	15	B07001_015	70 to 74 years
# B07001	16	B07001_016	75 years and over 

tab_B07001 <- readRDS(here::here("data", "tab_B07001.rds"))
x <- "GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY AGE FOR CURRENT RESIDENCE IN THE UNITED STATES%Population 1 year and over in the United States%"
tmp <- count(tab_B07001 %>% 
               filter(year==2019) %>%
               # filter(vnum %in% c(1, 13, 19, 25)) %>% # no code 31 for moved abroad!!
               mutate(vdescription=str_remove(vdescription, x)),
             vnum, tabvarname, vdescription)


agegroups <- tab_B07001 %>%
  filter(year==2019, valtype=="est") %>%
  mutate(agegroup=case_when(vnum %in% c(1, 17, 33, 49, 65, 81) ~ "total",
                            str_detect_any(vdescription, 
                                           c("1 to 4",
                                             "5 to 17",
                                             "18 and 19",
                                             "20 to 24")) ~ "age0124",
                            str_detect_any(vdescription,
                                           c("25 to 29", "30 to 34")) ~ "age2534",
                            str_detect_any(vdescription,
                                           as.character(seq(35, 60, 5))) ~ "age3564",
                            str_detect_any(vdescription,
                                           c("65", "70", "75")) ~ "age65plus",
                            TRUE ~ paste0(vnum, vdescription)),
         movestatus=case_when(vnum %in% 1:16 ~ "total",
                            vnum %in% 17:32 ~ "stay",
                            vnum %in% 33:96 ~ "movein"))

tabdata <- agegroups %>%
  filter(movestatus=="movein", geoid %in% subareas$geoid) %>%
  group_by(year, table, sgeotype, geoid, usgeoname, agegroup) %>%
  summarise(value=sum(value), .groups="drop") %>%
  pivot_wider(names_from = agegroup) %>%
  mutate(tot25p=total - age0124) %>%
  relocate(tot25p, .after = usgeoname) %>%
  select(-age0124) %>%
  select(year, table, sgeotype, geoid, usgeoname, tot25p, starts_with("age")) %>%
  mutate(agetot=tot25p,
         across(starts_with("age"), ~ .x / tot25p),
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab)

tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(year, table, sgeotype, geoid)) %>%
  tab_header(
    title = "Movement into an area by age group, average for the 5 years ending in 2019",
    subtitle = "Population 25 years and older"
      ) %>%
  cols_label(usgeoname="",
             tot25p=html("Number who<br>moved in"),
             age2534="25 to 34",
             age3564=html("35 to 65"),
             age65plus="65 plus",
             agetot="Total") %>%
  cols_align(align="left", columns = usgeoname) %>%
  tab_spanner(
    label = "Age group (as % of total who moved in)",
    columns = starts_with("age")
    ) %>%
  fmt_number(
    columns=tot25p,
    pattern = "{x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = starts_with("age"),
    decimals = 1) %>%
  # fmt_missing(columns=everything(), missing_text="") %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ pct(60),
    everything() ~ pct(40)
    ) %>%
  tab_options(
    table.width = pct(100)
  )

# webshot options
# default zoom=2, expand=5
tab
gtsave(tab, filename="tab_moveins_age_2019.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_moveins_age_2019_data.csv"))

```



```{r tab_moveins_ownrent}
# B07013	 		GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY TENURE FOR CURRENT RESIDENCE IN THE UNITED STATES
# B07013	 		Universe:  Population 1 year and over in households in the United States
# B07013	1	B07013_001	Total:
# B07013	2	B07013_002	Householder lived in owner-occupied housing units 
# B07013	3	B07013_003	Householder lived in renter-occupied housing units  
# B07013	4	B07013_004	Same house 1 year ago:
# B07013	5	B07013_005	Householder lived in owner-occupied housing units  
# B07013	6	B07013_006	Householder lived in renter-occupied housing units  
# B07013	7	B07013_007	Moved within same county:
# B07013	8	B07013_008	Householder lived in owner-occupied housing units  
# B07013	9	B07013_009	Householder lived in renter-occupied housing units  
# B07013	10	B07013_010	Moved from different county within same state:
# B07013	11	B07013_011	Householder lived in owner-occupied housing units  
# B07013	12	B07013_012	Householder lived in renter-occupied housing units  
# B07013	13	B07013_013	Moved from different state:
# B07013	14	B07013_014	Householder lived in owner-occupied housing units  
# B07013	15	B07013_015	Householder lived in renter-occupied housing units  
# B07013	16	B07013_016	Moved from abroad:
# B07013	17	B07013_017	Householder lived in owner-occupied housing units  
# B07013	18	B07013_018	Householder lived in renter-occupied housing units  

```



# Housing in and around the Village of Cambridge

## Number of units and vacancies
```{r census_housing_pch}
cenhu <- readRDS(here::here("data", "cenhousing.rds"))

tabdata <- subareas %>%
  filter(year==2019) %>%
  select(geoid, usgeoname) %>%
  mutate(usgeoname=str_trim(usgeoname)) %>%
  left_join(cenhu %>%
              mutate(usgeoname=str_extract_before_first(usgeoname, ",")) %>%
              select(usgeoname, sgeotype, year, total, occupied),
            by="usgeoname") %>%
  filter(!is.na(year)) %>%
  pivot_wider(names_from = year, values_from = c(total, occupied)) %>%
  mutate(totpch=total_2020 / total_2010 - 1,
         occpch=occupied_2020 / occupied_2010 - 1,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab)
tabdata




tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(geoid, sgeotype)) %>%
  tab_header(
    title = "Number of housing units in 2010 and 2010"
      ) %>%
  cols_label(usgeoname="",
             total_2010=html("2010"),
             total_2020 ="2020",
             occupied_2010=html("2010"),
             occupied_2020=html("2020"),
             totpch="Total",
             occpch="Occupied") %>%
  cols_align(align="left", columns = usgeoname) %>%
  tab_spanner(
    label = "# of housing units in total",
    columns = starts_with("total")
    ) %>%
  tab_spanner(
    label = "# of occupied housing units",
    columns = starts_with("occupied")
    ) %>%
  tab_spanner(
    label = "% change",
    columns = contains("pch")
    ) %>%
  fmt_number(
    columns=c(starts_with("total"), starts_with("occupied")),
    pattern = "{x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pch"),
    decimals = 1
    ) %>%
  # fmt_missing(columns=everything(), missing_text="") %>%
  tab_source_note(paste0("Source: ", source_decennialpop, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ pct(60),
    everything() ~ pct(40)
    ) %>%
  tab_options(
    table.width = pct(100)
  )
  
tab
# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_decennial_housing.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_decennial_housing_data.csv"))

```


```{r census_housing_vacpct}
cenhu <- readRDS(here::here("data", "cenhousing.rds"))

tabdata <- subareas %>%
  filter(year==2019) %>%
  select(geoid, usgeoname) %>%
  mutate(usgeoname=str_trim(usgeoname)) %>%
  left_join(cenhu %>%
              mutate(usgeoname=str_extract_before_first(usgeoname, ",")) %>%
              select(usgeoname, sgeotype, year, total, vacant),
            by="usgeoname") %>%
  filter(!is.na(year)) %>%
  mutate(vacpct=vacant / total) %>%
  select(year, usgeoname, sgeotype, vacpct) %>%
  pivot_wider(names_from = year, values_from = vacpct, names_prefix="vacpct") %>%
  mutate(change=vacpct2020 - vacpct2010,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab)
tabdata

tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(sgeotype)) %>%
  tab_header(
    title = "Housing vacancy rate in 2010 and 2010"
      ) %>%
  cols_label(usgeoname="",
             vacpct2010 =html("2010"),
             vacpct2020  ="2020",
             change="Change") %>%
  cols_align(align="left", columns = usgeoname) %>%
  tab_spanner(
    label = "Vacancy rate",
    columns = starts_with("vacpct")
    ) %>%
  fmt_percent(
    columns = c(vacpct2010, vacpct2020, change),
    decimals = 1
    ) %>%
  # fmt_missing(columns=everything(), missing_text="") %>%
  tab_source_note(paste0("Source: ", source_decennialpop, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ pct(60),
    everything() ~ pct(40)
    ) %>%
  tab_options(
    table.width = pct(100)
  )
  
tab
# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_decennial_housing_vacpct.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_decennial_housing_vacpct_data.csv"))

```

## Kinds of vacancies
```{r}
tab_B25004 <- readRDS(here::here("data", "tab_B25004.rds"))
```


## Year structure built
```{r}
#.. B25037	Median Year Structure Built by Tenure ----
tab_B25037 <- readRDS(here::here("data", "tab_B25037.rds"))
```


## Home value
```{r tab_mdn_house_value}
tab_B25077 <- readRDS(here::here("data", "tab_B25077.rds"))

tmp <- count(tab_B25077, vnum, tabvarname, vdescription)
tmp <- tabdescribe %>% filter(table=="B25077")
# vnum 1 B25077_001 MEDIAN VALUE (DOLLARS)% Owner-occupied housing units%Median value (dollars)

tabdata <- tab_B25077 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  select(year, table, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Median value owner-occupied housing, in survey-end-year dollars", 
                 decimals=0,
                 type="number")
tab
gtsave(tab, filename="tab_mdn_house_value.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_mdn_house_value_data.csv"))

```

## Costs relative to income
```{r tab_rentcosts_hhi}
#.. B25071: Median Gross Rent as a Percentage of Household Income (Dollars) ----
tab_B25071 <- readRDS(here::here("data", "tab_B25071.rds"))
# Renter-occupied housing units paying cash rent
# Median Gross Rent As A Percentage Of Household Income In The Past 12 Months (Dollars)

tmp <- count(tab_B25071, vnum, tabvarname, vdescription)
tmp <- tabdescribe %>% filter(table=="B25071")
# vnum 1

tabdata <- tab_B25071 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  select(year, table, sgeotype, geoid, usgeoname, value) %>%
  mutate(value=value / 100) %>% # data are in percent
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Median gross rent as a percentage of household income", 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_rentcosts_hhi.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_rentcosts_hhi_data.csv"))


```


```{r tab_ownercosts_all}
#.. B25092: Median Selected Monthly Owner Costs as a Percentage of Household Income ----
tab_B25092 <- readRDS(here::here("data", "tab_B25092.rds"))


tmp <- count(tab_B25092, vnum, tabvarname, year, vdescription)
tmp <- tabdescribe %>% filter(table=="B25092")
# vnum 1

tabdata <- tab_B25092 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  filter(vnum==1) %>%  # all units, not just those with mortgage
  select(year, table, sgeotype, geoid, usgeoname, value) %>%
  mutate(value=value / 100) %>% # data are in percent
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Median selected monthly owner costs as a percentage of household income", 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_ownercosts_hhi.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_ownercosts_hhi_data.csv"))

```


```{r tab_ownercosts_mortgage}
#.. B25092: Median Selected Monthly Owner Costs as a Percentage of Household Income ----
tab_B25092 <- readRDS(here::here("data", "tab_B25092.rds"))


tmp <- count(tab_B25092, vnum, tabvarname, year, vdescription)
tmp <- tabdescribe %>% filter(table=="B25092")
# vnum 1

tabdata <- tab_B25092 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  filter(vnum==2) %>%  # units with a mortgage
  select(year, table, sgeotype, geoid, usgeoname, value) %>%
  mutate(value=value / 100) %>% # data are in percent
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Median selected monthly owner costs as a percentage of household income, units with a mortgage", 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_ownercosts_mortgage_hhi.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_ownercosts_mortgage_hhi_data.csv"))

```



```{r tab_ownercosts_nomortgage}
#.. B25092: Median Selected Monthly Owner Costs as a Percentage of Household Income ----
tab_B25092 <- readRDS(here::here("data", "tab_B25092.rds"))


tmp <- count(tab_B25092, vnum, tabvarname, year, vdescription)
tmp <- tabdescribe %>% filter(table=="B25092")
# vnum 1

tabdata <- tab_B25092 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  filter(vnum==3) %>%  # units with a mortgage
  select(year, table, sgeotype, geoid, usgeoname, value) %>%
  mutate(value=value / 100) %>% # data are in percent
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title="Median selected monthly owner costs as a percentage of household income, units without a mortgage", 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_ownercosts_nomortgage_hhi.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_ownercosts_nomortgage_hhi_data.csv"))

```


```{r tabbase_costs_pcthhi}
# #.. B25106	Tenure by Housing Costs as a Percentage of Household Income ----
tab_B25106 <- readRDS(here::here("data", "tab_B25106.rds"))

tmp <- count(tab_B25106, vnum, tabvarname, year, vdescription)
tmp <- tabdescribe %>% filter(table=="B25106")
# vnum 1

# explore
vmap <- read_excel(here::here("BoydLumberyard.xlsx"), sheet="costburden", range="A1:F47")
td1 <- tab_B25106 %>%
  filter(valtype=="est") %>%
  left_join(vmap, by = c("vnum", "tabvarname"))
# nrow(tab_B25106) == nrow(td1)
td1 %>% filter(year==2019, 
                str_detect(usgeoname, "Cambridge village"), 
                income=="incall", 
                tenure=="renter") %>%
  select(usgeoname, income, tenure, pct, value)

# collapse unknowns
td2 <- td1 %>%
  filter(income != "incall", pct!="pctall")  %>%  # will compute totals
  # create and collapse the other income group
  mutate(income=ifelse(income %in% c("inczneg", "incunk"), "incother", income)) %>%
  group_by(table, year, sgeotype, geoid, usgeoname, tenure, income, pct) %>%
  summarise(value=sum(value), .groups="drop")
count(td2, income)
td2 %>% 
  filter(year==2019, str_detect(usgeoname, "Cambridge village"), tenure=="renter") %>%
  arrange(income, pct)

# verify totals
td2 %>% 
  filter(year==2019, str_detect(usgeoname, "Cambridge village")) %>%
  group_by(tenure) %>%
  summarise(value=sum(value))

# construct totals
inctots <- td2 %>%
  group_by(table, year, sgeotype, geoid, usgeoname, tenure, pct) %>%
  summarise(value=sum(value), .groups="drop") %>%
  mutate(income="incall")

# verify
inctots %>% 
  filter(year==2019, 
         str_detect(usgeoname, "Cambridge village"),
         income=="incall") %>%
  group_by(tenure) %>%
  summarise(value=sum(value))

pcttots <- td2 %>%
  group_by(table, year, sgeotype, geoid, usgeoname, tenure, income) %>%
  summarise(value=sum(value), .groups="drop") %>%
  mutate(pct="pctall")

# verify
pcttots %>% 
  filter(year==2019, 
         str_detect(usgeoname, "Cambridge village"),
         pct=="pctall") %>%
  group_by(tenure) %>%
  summarise(value=sum(value))


grandtots <- td2 %>%
  group_by(table, year, sgeotype, geoid, usgeoname, tenure) %>%
  summarise(value=sum(value), .groups="drop") %>%
  mutate(income="incall", pct="pctall")

tdall <- bind_rows(td2, inctots, pcttots, grandtots) %>%
  arrange(table, year, sgeotype, usgeoname, tenure, income,  pct)

tdall %>% 
  filter(year==2019, 
         str_detect(usgeoname, "Cambridge village"),
         income=="incall",
         pct=="pctall")

# make wide file with % of units that are 30+% of income
inclevs <- c("incall", "inclt20k",  "inc2035k", "inc3550k", "inc5075k", "inc75kp", "incother")
inclabs <- c("All income groups", "< $20,000", "$20,000 to $34,999", "$35,000 to $49,999",
             "$50,000 to $74,999", "$75,000+", "no income")
tabbase <- tdall %>%
  filter(pct %in% c("pct30p", "pctall")) %>%
  pivot_wider(names_from = pct, values_fill = 0) %>%
  rename(occunits=pctall) %>%
  mutate(pct30p=pct30p / occunits)  %>% # ok to generate NA values if occunits is zero
  pivot_wider(names_from=tenure, values_from = c(occunits, pct30p)) %>%
  mutate(incomef=factor(income, levels=inclevs, labels=inclabs)) %>%
  arrange(year, sgeotype, usgeoname, incomef) %>%
  select(table, year, sgeotype, geoid, usgeoname, income, incomef, contains("owner"), contains("renter")) %>%
  mutate(occunits_total=occunits_owner + occunits_renter,
         pct30p_total=(occunits_owner / occunits_total * naz(pct30p_owner) +
                         occunits_renter / occunits_total * naz(pct30p_renter)))
# count(tabbase, income)
# tabbase %>% filter(year==2019, str_detect(usgeoname, "Cambridge village"), income=="incall")
tabbase %>% filter(year==2019, str_detect(usgeoname, "Cambridge village"))

```


```{r tabbase_costs_pcthhi}

tabdata <- tabbase %>%
  filter(geoid %in% subareas$geoid, income=="incall") %>%
  select(year, table, sgeotype, geoid, usgeoname, value=pct30p_total) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, 
                 .title=html("Percentage of households for which housing costs are 30+% of household income<br>(includes both owners and renters)"), 
                 decimals=1,
                 type="percent")
tab
gtsave(tab, filename="tab_costs_pcthhi.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_costs_pcthhi_data.csv"))

```

```{r tab_cambvill_costs_pcthhi}

tabdata <- tabbase %>%
  filter(str_detect(usgeoname, "Cambridge village"), year==2019)

tab <- tabdata %>%
  gt() %>%
  cols_hide(c(table, year, sgeotype, geoid, usgeoname, income)) %>%
  tab_header(
    title = html("Cambridge village housing units and % of households<br>for which housing costs are 30+% of household income"),
    subtitle="5 years ending in 2019"
      ) %>%
  cols_label(incomef="Income",
             occunits_owner=html("# of units"),
             pct30p_owner=html("% with costs 30+ % of income"),
             occunits_renter=html("# of units"),
             pct30p_renter=html("% with costs 30+ % of income"),
             occunits_total=html("# of units"),
             pct30p_total=html("% with costs 30+ % of income")
             ) %>%
  tab_spanner(
    label = html("Owner-occupied"),
    columns = contains("owner")
    ) %>%
  tab_spanner(
    label = html("Renter-occupied"),
    columns = contains("renter")
    ) %>%
  tab_spanner(
    label = html("Total occupied"),
    columns = contains("total")
    ) %>%
  cols_align(align="left", columns = incomef) %>%
  fmt_number(
    columns=contains("units"),
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pct"),
    decimals = 1) %>%
  fmt_missing(
    columns=contains("pct"),
    missing_text = "-"
  ) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      # cell_text(weight = "bold") # size = px(15), , font = "arial"
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=1
      )
    ) %>%
  cols_width(
    incomef ~ px(100),
    contains("units") ~ px(100),
    contains("pct") ~ px(100)
  ) 

tab
gtsave(tab, filename="tab_cambvill_costs_pcthhi.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_cambvill_costs_pcthhi_data.csv"))

```



## Property tax data
```{r}
# https://data.ny.gov/Government-Finance/Parcel-Counts-By-Type-By-Municipality-Beginning-Ro/tnwc-mx3q
# levies
# https://data.ny.gov/Government-Finance/Real-Property-Tax-Rates-Levy-Data-By-Municipality-/iq85-sdzs
# http://data.ny.gov/d/e6pv-77bh
# rars http://data.ny.gov/d/bsmp-6um6


# other
# NYSERDA
# https://data.ny.gov/Energy-Environment/RSBS-MOM-Part-2-of-2-New-York-State-Residential-St/hc4z-b2p5

# search
# https://data.ny.gov/Government-Finance/Local-Data-Index/vgx8-sf6x

parcels1 <- read_csv("https://data.ny.gov/api/views/tnwc-mx3q/rows.csv?accessType=DOWNLOAD&sorting=true")
glimpse(parcels1)
vnames <- c("rollyear", "swis", "muniname", "county",
            "agricultural_100", "residential_200", "vacant_300", "commercial_400",
            "recreation_500", "communityservice_600", "industrial_700",
            "publicservice_800", "forest_900", "total")
parcels2 <- parcels1 %>%
  setNames(vnames) %>%
  pivot_longer(-c(rollyear, swis, muniname, county)) %>%
  separate(name, c("type", "code"), remove=FALSE) %>%
  mutate(code=as.integer(code))

parcels2 %>%
  filter(rollyear==2020, str_detect(muniname, coll("Cambridge", ignore_case=TRUE)))

parcels2 %>%
  filter(str_detect(muniname, coll("Cambridge", ignore_case=TRUE))) %>%
  filter(code %in% c(100, 200, 300, 400)) %>%
  ggplot(aes(rollyear, value, colour=type)) +
  geom_line() +
  geom_point()



```


## TO DO

```{r gt_example}
gt() %>%
  cols_hide(stabbr) %>%
  tab_header(
    title = "State correctional officer wages, selected years"
      ) %>%
  cols_label(stname="",
             wage_2012="2012",
             wage_2016="2016",
             wage_2020="2020",
             pdiff_2012="2012",
             pdiff_2016="2016",
             pdiff_2020="2020") %>%
  cols_align(align="left", columns = stname) %>%
  tab_spanner(
    label = html("Average wage"),
    columns = contains("wage")
    ) %>%
  tab_spanner(
    label = "California wage % above other area",
    columns = contains("pdiff")
    )  %>%
  fmt_number(
    columns=c(contains("wage")),
    pattern = "${x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pdiff"),
    decimals = 1) %>%
  fmt_missing(columns=everything(), missing_text="") %>%
  fmt_missing(contains("pdiff"), rows=2) %>%
  tab_source_note(paste0("Sources: ", source_oesres, ".")) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_body(
      rows = c(1, 4, 7)
    )
  ) %>%
  cols_width(
    stname ~ px(200),
    everything() ~ px(100)
    )

tab
gtsave(tab, filename="tab_wages_states_oes.png", path=here::here("results"))
```


```{r define_poi}
# places of interest
# ONETIME
# dhtabs <- r"(E:\data\acs\hud_chas\tables\)"
# poi1 <- readRDS(paste0(dhtabs, "table1.rds")) %>%
#   filter(st=="36")
#   
# poi2 <- poi1 %>%
#   select(geoid, geoname, type) %>%
#   distinct()
# saveRDS(poi2, here::here("data", "hud_nyareas.rds"))
# count(poi2, type)

nyareas <- readRDS(here::here("data", "hud_nyareas.rds"))

counties <- c("Albany", "Saratoga", "Warren", "Washington")
places <- c("Cambridge", "Greenwich", "Argyle", "Salem", "White Creek")
nypoi <- nyareas %>%
  filter(type=="state" |
           type=="county" & str_detect_any(geoname, counties) |
           type=="place" & str_detect_any(geoname, places) |
           type=="mcd" & 
           str_detect(geoname, "Washington County") & 
           str_detect_any(geoname, places))
nypoi

```


```{r hudny_prep}
dhtabs <- r"(E:\data\acs\hud_chas\tables\)"
  
# df2 <- df %>%
  #   separate(vname, into=c("table", "est")) %>%
  #   mutate(etype=str_sub(est, 1, 3),
  #          estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
  #   pivot_wider(names_from = etype)

df1 <- readRDS(paste0(dhtabs, "table1.rds"))
glimpse(df1)

df14a <- readRDS(paste0(dhtabs, "table14a.rds"))
glimpse(df14a)

df14b <- readRDS(paste0(dhtabs, "table14b.rds"))
glimpse(df14b)

nyhud1 <- bind_rows(df1 %>% filter(st=="36"),
                   df14a %>% filter(st=="36"),
                   df14b %>% filter(st=="36")) %>%
  select(-st)


nyhud2 <- nyhud1 %>%
  filter(geoid %in% nypoi$geoid) %>%
  separate(vname, c("table", "estmoe")) %>%
  mutate(vtype=str_sub(estmoe, 1, 3),
         vnum=str_sub(estmoe, 4, nchar(estmoe)) %>% as.integer)
glimpse(nyhud2)
summary(nyhud2)
count(nyhud2, table)


# .. key variables ----
# T14A_est1	Total	Total: Vacant-for-sale housing units	All
# T14A_est2	Detail	Vacant-for-sale	housing unit lacks complete kitchen or plumbing facilities
# T14B_est1	Total	Total: Vacant-for-rent housing units	All
# T14B_est2	Detail	Vacant-for-rent	housing unit lacks complete kitchen or plumbing facilities

# T1_est1	 Total	Total: Occupied housing units

# owner occupied
# T1_est2	 .	Owner occupied
# T1_est3	 .. has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)
# T1_est4  ... less than or equal to 30% of HAMFI
# T1_est11 ... greater than 30% but less than or equal to 50% of HAMFI
# T1_est18 ... greater than 50% but less than or equal to 80% of HAMFI
# T1_est25 ... greater than 80% but less than or equal to 100% of HAMFI

# T1_est75 .  Renter occupied
# T1_est76 .. has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)
# T1_est77 ... less than or equal to 30% of HAMFI
# T1_est84 ... greater than 30% but less than or equal to 50% of HAMFI
# T1_est91 ... greater than 50% but less than or equal to 80% of HAMFI
# T1_est98 ... greater than 80% but less than or equal to 100% of HAMFI
# T1_est105 ... greater than 100% of HAMFI

t1enums <- c(1:4, 11, 18, 25, 75:77, 84, 91, 98, 105)

nyhud3 <- nyhud2 %>%
  filter((table=="T1" & vnum %in% t1enums) |
           (table %in% c("T14A", "T14B") & vnum %in% 1:2))
count(nyhud3, table, vnum)

# check on moe
nyhud4 <- nyhud3 %>%
  select(-estmoe) %>%
  pivot_wider(names_from = vtype) %>%
  mutate(moepct=moe / est)

```


```{r stock}
tabdata <- nyhud4 %>%
  filter(vnum==1) %>%
  select(type, geoname, table, est) %>%
  mutate(table=factor(table,
                    levels=c("T1", "T14A", "T14B"),
                    labels=c("occ", "vfs", "vfr"))) %>%
  pivot_wider(names_from = table, values_from = est) %>%
  mutate(vacant=vfs + vfr,
         avail=occ + vacant,
         vacpct=vacant / avail,
         geoname=ifelse(type=="state", paste0(geoname, " State"), geoname),
         geoname=str_extract(geoname, '^[^,]+')
         ) %>%
  select(type, geoname, avail, occ, vacant, vacpct)

tab <- tabdata %>%
  #  select(-type) %>%
  group_by(type) %>%
  gt() %>%
  tab_header(
    title = "Occupied or vacant & available housing"
      ) %>%
  cols_label(type="",
             geoname="",
             avail="Total # units",
             occ="# occupied",
             vacant="# vacant & available",
             vacpct="vacant as % of total") %>%
  cols_align(align="left", columns = geoname) %>%
  fmt_number(
    columns=c(avail, occ,  vacant),
    decimals=0
  ) %>%
  fmt_percent(
    columns = vacpct,
    decimals = 1) %>%
  tab_source_note(paste0("Source: ", source_hud, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    locations = cells_column_labels(columns = c(vacant, vacpct))
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_body(
      rows=str_detect(geoname, "Cambridge")
      )
  ) 

gtsave(tab, filename="tab_stock_hud.png", path=here::here("results"))
write_csv(tabdata, file=here::here("results", "tab_stock_hud_data.csv"))

```


```{r tenure}

# tenure
tabdata <- hudnuy_base %>%
  filter(estnum %in% c(1, 2, 75)) %>%
  select(-moe) %>%
  mutate(estnum=factor(estnum,
                       levels=c(1, 2, 75),
                       c("total", "own", "rent"))) %>%
  pivot_wider(names_from = estnum, values_from = c(est, moepct)) %>%
  mutate(est_ownpct=est_own / est_total) %>%
  select(type, geoid, geoname, est_total, est_own, est_rent, est_ownpct, everything())

tab <- tabdata %>%
  select(geoname, starts_with("est")) %>%
  gt() %>%
  tab_header(
    title = "Housing tenure in our area"
      ) %>%
  cols_label(geoname="",
             est_total="Total # units",
             est_own="# owner occupied"
             est_rent="# renter occupied"
             wage_2016="2016",
             wage_2020="2020",
             pdiff_2012="2012",
             pdiff_2016="2016",
             pdiff_2020="2020") %>%
  cols_align(align="left", columns = stname) %>%
  tab_spanner(
    label = html("Average wage"),
    columns = contains("wage")
    ) %>%
  tab_spanner(
    label = "California wage % above other area",
    columns = contains("pdiff")
    )  %>%
  fmt_number(
    columns=c(contains("wage")),
    pattern = "${x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pdiff"),
    decimals = 1) 
  
```



## Housing affordability
```{r plot_median_rent_income}
excludes <- c("Argyle", "Fort", "Dresden", "Hampton", "Hebron", "Whitehall", "Putnam", "Granville", "Kingsb", "Hartf")

pdata <- acsdata %>%
  filter(tableid=="B25071", year==2019, !str_detect_any(sname, excludes)) %>%
  mutate(cambvillage=geoid==cambridge_village)

capt1 <- paste0("Note: Costs above 30 percent are generally often defined as burdensome. Smaller geographic areas generally have a larger margin of error.")
capt2 <- paste0("Source: ", source_acs, ", 2015-2019.")
capt <- paste0(capt1, "\n", capt2)
# xlab <- "% of household income\n<--- more affordable : less affordable --->"
xlab <- "% of household income"

xlims <- c(22.25, 31.5)
p <- pdata %>%
  ggplot(aes(x=estimate, y=reorder(sname, estimate))) +
  # geom_errorbar(aes(xmin=pmax(estimate - moe, xlims[1]),
  #                   xmax=pmin(estimate + moe, xlims[2])),
  #               width=.05, colour="grey") +
  geom_point(aes(colour=cambvillage), size=3) +
  scale_colour_manual(values=c("blue", "red")) +
  # geom_col(fill="blue", size=2.5, width=0.3) +
  geom_vline(xintercept = 30, linetype="solid", colour="darkgrey", size=.5) +
  theme_bw() +
  labs(x=xlab,
       y=NULL,
       caption=capt) +
  ggtitle(label=str_to_sentence("MEDIAN GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME, 2015-2019 average"),
          subtitle = NULL) +
  # theme(axis.text.y = element_text(hjust = 0)) +
  scale_x_continuous(breaks=seq(0, 100, 1), labels=label_comma(accuracy=.1), limits=xlims) +
  legend_none +
  caption_left
p

ggsave(here::here("results", "fig_rent_affordability_2019.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_rent_affordability_2019_data.csv"))

```


# Older

```{r census_geo}
gdir <- r"(E:\data\acs\sf\2019_5year\)"
fn <- "5_year_Mini_Geo.xlsx"

rgeo1 <- read_excel(paste0(gdir, fn), sheet="ny")

rgeo2 <- rgeo1 %>%
  setNames(c("stabbr", "logrecno", "geoid", "geoname")) %>%
  mutate(geoleft=str_sub(geoid, 1, 5),
         geomid=str_sub(geoid, 6, 7),
         georight=str_sub(geoid, 8, nchar(geoid)))
count(rgeo2, geoleft) %>% ht
count(rgeo2, geomid) %>% ht
count(rgeo2, georight) %>% ht

rgeo3 <- rgeo2 %>%
  select(stabbr, logrecno, geoid, geoname, geotype=geoleft, geonums=georight)

# which are the uniques?
rgeo3 %>%
  group_by(geotype) %>%
  mutate(n=n()) %>%
  ungroup %>%
  filter(n==1)

# geonums that start with something other than 36 are...
rgeoxpart <- rgeo3 %>%
  filter(!str_detect(geoname, "part"),
         !str_detect(geoname, "Remainder"))
count(rgeoxpart, geotype)

tmp <- rgeo3 %>%
  group_by(geotype) %>%
  mutate(n=n()) %>%
  ungroup %>%
  arrange(geotype, geoid)

# logrecno geoid     geoname                                                               geoty
# <chr>    <chr>     <chr>                                                                 <chr>
# 0000001  04000US36 New York                                                              04000
# 0000002  04001US36 New York -- Urban                                                     04001
# 0000003  04043US36 New York -- Rural                                                     04043
# 0000004  040A0US36 New York -- In metropolitan or micropolitan statistical area          040A0
# 0000005  040C0US36 New York -- In metropolitan statistical area                          040C0
# 0000006  040C1US36 New York -- In metropolitan statistical area -- in principal city     040C1
# 0000007  040C2US36 New York -- In metropolitan statistical area -- not in principal city 040C2
# 0000008  040E0US36 New York -- In micropolitan statistical area                          040E0
# 0000009  040E1US36 New York -- In micropolitan statistical area -- in principal city     040E1
# 0000010  040E2US36 New York -- In micropolitan statistical area -- not in principal city 040E2
# 0000011  040G0US36 New York -- Not in metropolitan or micropolitan statistical area      040G0
# 0000012  040H0US36 New York -- Not in metropolitan statistical area                      040H0

# we'll want geotypes
# 04000, 04001, 04043
# 05000 counties (5 nyc)
# 06000 cities, towns, villages, CDPs


rgcounty <- rgeo3 %>%
  filter(geotype=="05000")


gdf <- read_csv(paste0(gdir, "ny/", "g20195ny.csv"),
                col_names = FALSE)


```

```{r census_txt}
dir <- r"(E:\data\acs\sf\2019_5year\ny\)"
fn <- "e20195ny.txt"

# FILEID File Identification 6 Characters
# FILETYPE File Type 6 Characters
# STUSAB State/U.S.-Abbreviation (USPS) 2 Characters
# CHARITER Character Iteration 3 Characters
# SEQUENCE Sequence Number 4 Characters
# LOGRECNO Logical Record Number 7 Characters
idvars <- c("fileid", "filetype", "stusab", "chariter", "sequence", "logrecno")

rdf <- vroom(paste0(dir, fn), col_names=FALSE, 
             col_types = cols("c", "c", "c", "c", "c", "c",
                              .default= col_double()))
# rdf <- read_csv(paste0(dir, fn))
glimpse(rdf[, 1:7])
names(rdf)

# xvars <- paste0("x", 1:(ncol(rdf) - length(idvars)))
# vnames <- c(idvars, xvars)
names(rdf)[1:length(idvars)] <- idvars
glimpse(rdf)
names(rdf) <- str_to_lower(names(rdf))

saveRDS(rdf, paste0(dir, "e20195ny.rds"))

rdf <- readRDS(paste0(dir, "e20195ny.rds"))
glimpse(rdf[, 1:10])

tmp <- rdf %>%
  filter(sequence=="0001") %>%
  select(1:x55)

```

```{r census_reporter}
# https://censusreporter.org/profiles/16000US3611825-cambridge-ny/

```

```{r cornell}
# https://pad.human.cornell.edu/profiles/Washington.pdf


```


## acs package
```{r}
library(acs)
showClass("acs")
# ONETIME
# api.key.install(key=census_apikey, file = "key.rda")
# acs.tables.install()

geo_us <- geo.make(us=TRUE)
geo_nys <- geo.make(state="NY")
geo_nyscounties <- geo.make(state="NY", county="*")
geo_nysusds <- geo.make(state="NY", school.district.unified="*")
geo_zips <- geo.make(zip.code=c(12816, 12834))
geo_all <- geo_us + geo_nys + geo_nyscounties + geo_nysusds

geo_zips <- geo.make(zip.code="12816")
geo_all <- geo_zips

obj <- acs.fetch(endyear=2014, 
                       span = 5, 
                       geography=geo_all, 
                       table.number="B01001",
                       key=census_apikey)


f <- function(obj){
  geog <- geography(obj)
  ests <- tibble(geog, 
                 endyear=endyear(obj), 
                 type="est",
                 as_tibble(estimate(obj)))
  se <- tibble(geog,
               endyear=endyear(obj), 
               type="se",
               as_tibble(standard.error(obj)))
  
  df <- bind_rows(ests, se) %>%
    pivot_longer(-all_of(c(names(geog), "endyear", "type")))
}

df <- f(obj)

```


# WHY DO YOUNG PEOPLE COME TO A RURAL AREA?

# HOW DO IMPORTANT CHARACTERISTICS OF THE CAMBRIDGE AREA COMPARE AND CHANGE OVER TIME?

# ZIP CODES
```{r}
library(tigris)
library(ggmap)
options(tigris_use_cache = TRUE)

Tooele       <- c('84074','84029')
NEUtahCo     <- c('84003', '84004', '84042', '84062')
NWUtahCounty <- c('84005','84013','84043','84045')
utah_zips <- bind_rows(
  tibble(area = "Tooele", zip = Tooele),
  tibble(area = "NEUtahCo", zip = NEUtahCo),
  tibble(area = "NWUtahCounty", zip = NWUtahCounty)
)

zips_sf <- zctas(cb = T, starts_with = "84", class = "sf") %>%
  select(zip = ZCTA5CE10, geometry)

head(zips_sf)
#> Simple feature collection with 6 features and 1 field
#> geometry type:  MULTIPOLYGON
#> dimension:      XY
#> bbox:           xmin: -114.0504 ymin: 37.60461 xmax: -109.0485 ymax: 41.79228
#> epsg (SRID):    4269
#> proj4string:    +proj=longlat +datum=NAD83 +no_defs
#>       zip                       geometry
#> 37  84023 MULTIPOLYGON (((-109.5799 4...
#> 270 84631 MULTIPOLYGON (((-112.5315 3...
#> 271 84334 MULTIPOLYGON (((-112.1608 4...
#> 272 84714 MULTIPOLYGON (((-113.93 37....
#> 705 84728 MULTIPOLYGON (((-114.0495 3...
#> 706 84083 MULTIPOLYGON (((-114.0437 4...
#> 
utah_sf <- zips_sf %>%
  inner_join(utah_zips, by = "zip")
head(utah_sf)

ggmap_show_api_key()
ggmap_hide_api_key()


#43.0278499,-73.3841795
basemap <- get_map(location = c(lon=-111.9, lat= 40.7), zoom = 9)

ggmap(basemap) +
  geom_sf(aes(fill = zip), data = utah_sf, inherit.aes = F, size = 0, alpha = 0.6) +
  coord_sf(ndiscr = F) +
  theme(legend.position = "none")

#43.0278499,-73.3841795
lat <- 43.0278499
lon <- -73.3841795

Tooele       <- c('84074','84029')
NEUtahCo     <- c('84003', '84004', '84042', '84062')
NWUtahCounty <- c('84005','84013','84043','84045')

camb_zips <- bind_rows(
  tibble(area = "12816", zip = "12816"),
  tibble(area = "12834", zip = "12834")
)

camb_zips_sf <- zctas(cb = TRUE, starts_with = "128", class = "sf") %>%
  select(zip = ZCTA5CE10, geometry)

camb_sf <- camb_zips_sf %>%
  inner_join(camb_zips, by = "zip")
head(camb_sf)

camb_basemap5 <- get_map(location = c(lon=lon, lat= lat), 
                        zoom = 5) # maptype = "hybrid", 

camb_basemap10 <- get_map(location = c(lon=lon, lat= lat), 
                          maptype = "hybrid",
                          zoom = 10) # maptype = "hybrid", 


camb_basemap11 <- get_map(location = c(lon=lon, lat= lat), 
                        zoom = 11) # maptype = "hybrid", 

camb_basemap12 <- get_map(location = c(lon=lon, lat= lat), 
                        zoom = 12)


camb_basemap10 <- get_map(location = c(lon=lon, lat= lat), 
                          terrain = "roadmap", # hybrid, terrain, roadmap
                          zoom = 10) # maptype = "hybrid", 

camb_basemap10 <- get_map(location = c(lon=lon, lat= lat), 
                          terrain = "terrain", # hybrid, terrain, roadmap
                          zoom="auto", scale=2)

camb_basemap <- camb_basemap10 
ggmap(camb_basemap) +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.6) +
  coord_sf(ndiscr = 100,
           xlim=c(-73.65, -73.25),
           ylim=c(42.9, 43.25)) +
  # scale_x_continuous(name=NULL, breaks=NULL, labels=NULL) +
  # scale_y_continuous(name=NULL, breaks=NULL, labels=NULL) +
  legend_notitle +
  ggtitle("Zip code boundaries in Cambridge area") + 
  theme(axis.line = element_line(color = NA)) + 
  xlab("") + ylab("")

get_map("houston, texas")
get_map("cambridge, new york") %>%
  ggmap()

lat <- 43.0278499
lon <- -73.3841795
get_map(location = c(lon=lon, lat= lat), 
        terrain = "roadmap", # hybrid, terrain, roadmap
        maprange=TRUE,
        zoom="auto", scale=2) %>%
  ggmap() +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.2) +
  coord_sf(ndiscr = 100,
           xlim=c(-73.65, -73.25),
           ylim=c(42.9, 43.25)) +
  theme_void() + 
  ggtitle("Zip code boundaries in Cambridge area") +
  theme(
    plot.title = element_text(colour = "blue"), 
    panel.border = element_rect(colour = "grey", fill=NA, size=2)
    ) +
  legend_notitle

chi_bb <- c(
  left = -87.936287,
  bottom = 41.679835,
  right = -87.447052,
  top = 42.000835
)

chicago_stamen <- get_stamenmap(
  bbox = chi_bb,
  zoom = 11
)

ggmap(chicago_stamen)

# camb bounding box
camb_bb <- c(
  left = -73.65,
  bottom = 42.9,
  right = -73.25,
  top = 43.25
)
camb_stamen <- get_stamenmap(bbox = camb_bb, zoom = 13)
camb_stamen <- get_stamenmap(
  bbox = camb_bb
)
# get_stamenmap(bbox = camb_bb, zoom = 13, maptype="terrain-labels") %>%
get_map(location=camb_bb, source="osm", maptype = "hybrid") %>%  
  ggmap() +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.2) +
  # coord_sf(ndiscr = 100,
  #          xlim=c(-73.65, -73.25),
  #          ylim=c(42.9, 43.25)) +
  theme_void() + 
  ggtitle("Zip code boundaries in Cambridge area") +
  theme(
    plot.title = element_text(colour = "blue"), 
    panel.border = element_rect(colour = "grey", fill=NA, size=2)
    ) +
  legend_notitle

  # theme(axis.line = element_blank(),
  #       axis.text = element_blank(),
  #       axis.ticks = element_blank(),
  #       plot.margin = unit(c(0, 0, -1, -1), 'lines')) +
  # xlab('') +
  # ylab('')


# bounding box
left_bottom <- c(43.005063, -73.440002)
right_top <- c(43.060715, -73.336668)
(map <- get_map(c(left = left_bottom[1], bottom = left_bottom[2],
                  right = right_top[1], top = right_top[2])))

(map <- get_map(c(left = left_bottom[2], bottom = left_bottom[1],
                  right = right_top[2], top = right_top[1]),
                maptype="watercolor"))
ggmap(map)


map <- get_googlemap("Montpellier, France", zoom = 8, maptype = "terrain")
 # Plot it
ggmap(map) + 
  theme_void() + 
  ggtitle("terrain") + 
  theme(
    plot.title = element_text(colour = "orange"), 
    panel.border = element_rect(colour = "grey", fill=NA, size=2)
  )


big_streets <- getbb("Asheville United States")%>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("motorway", "primary", "motorway_link", "primary_link")) %>%
  osmdata_sf()

big_streets

med_streets <- getbb("Asheville United States")%>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("secondary", "tertiary", "secondary_link", "tertiary_link")) %>%
  osmdata_sf()


small_streets <- getbb("Asheville United States") %>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("residential", "living_street",
                            "unclassified",
                            "service", "footway"
                  )) %>%
  osmdata_sf()

river <- getbb("Asheville United States")%>%
  opq()%>%
  add_osm_feature(key = "waterway", value = "river") %>%
  osmdata_sf()

railway <- getbb("Asheville United States") %>%
  opq()%>%
  add_osm_feature(key = "railway", value="rail") %>%
  osmdata_sf()

# http://joshuamccrain.com/tutorials/maps/streets_tutorial.html
cbb <- getbb("Cambridge New York")
# camb bounding box
camb_bb <- c(
  left = -73.65,
  bottom = 42.9,
  right = -73.25,
  top = 43.25
)

big_streets <- camb_bb %>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("motorway", "primary", "motorway_link", "primary_link")) %>%
  osmdata_sf()

big_streets

med_streets <- camb_bb %>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("secondary", "tertiary", "secondary_link", "tertiary_link")) %>%
  osmdata_sf()

ggplot() +
  geom_sf(data = big_streets$osm_lines,
          inherit.aes = FALSE,
          color = "black") +
  geom_sf(data = med_streets$osm_lines,
          inherit.aes = FALSE,
          color = "black")

# http://gis.ny.gov/civil-boundaries/
# http://gis.ny.gov/gisdata/inventories/details.cfm?DSID=927
map('county', 'new jersey')
map_data("county", "iowa")
map_data("village", "new york")

require(rgdal)
require(ggplot2)
fn <- file.path(tempdir(), "GBR_adm_gdb.zip", fsep = "\\")
download.file("http://biogeo.ucdavis.edu/data/gadm2.8/shp/GBR_adm_shp.zip", fn)
utils::unzip(fn, exdir = tempdir())
shp <- readOGR(dsn = file.path(tempdir(), "GBR_adm1.shp"), stringsAsFactors = F)
shp <- readOGR(here::here("map_data", "NYS_Civil_Boundaries.shp", "Villages.shp"), stringsAsFactors = FALSE)
head(shp)
count(shp, NAME)
shp@data$NAME
shp2 <- subset(shp, NAME=="Cambridge")

camb_bb <- c(
  left = -73.65,
  bottom = 42.9,
  right = -73.25,
  top = 43.25
)

get_map(location=camb_bb, source="osm", maptype = "hybrid") %>%  
  ggmap() +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.2)  +
  geom_polygon(data = shp2, aes(x = long, y = lat, group = group), colour = "black", fill = NA)

ggplot() + 
  geom_polygon(data = shp2, aes(x = long, y = lat, group = group), colour = "black", fill = NA)


scale_x_continuous( limits = c( -95.5 , -95.3 ) , expand = c( 0 , 0 ) )+
scale_y_continuous( limits = c( 29.6 , 29.8 ) , expand = c( 0 , 0 ) )


library(sf)
vlg_path <- here::here("map_data", "NYS_Civil_Boundaries.shp", "Villages.shp")
vlg_sf <- st_read(vlg_path)
vlg_sf
subset(vlg_sf, NAME=="Cambridge")
camb_bb
xmin <- -73.65; xmax <- -73.25
ymin <- 42.90; ymax <- 43.25
# the bound box
tibble(long=c(xmin, xmin, xmax, xmax),
       lat=c(ymin, ymax, ymin, ymax)) %>%
  ggplot(aes(x = long, y = lat)) +
  geom_sf(data=vlg_sf)
  geom_polygon()
  
vlg_sf %>%
  filter(NAME == "Cambbridge") %>%
  ggplot() +
  geom_sf(fill="blue") + 
  coord_sf() +
  scale_x_continuous(limits=c(xmin, xmax)) +
  scale_y_continuous(limits=c(ymin, ymax))
  scale_fill_manual(values=clrs) +
  theme_map()
  
basemap <- get_map(location = c(lon=-111.9, lat= 40.7), zoom = 9)
basemap <- get_map(location = camb_bb)
ggmap(basemap) +
  layer_spatial(vlg_sf) 
  geom_sf(data=vlg_sf)
  
  

us_counties(states = "NY") %>%
  dplyr::select(-13) %>%
  ggplot() + 
  geom_sf(aes(fill="blue"))  + 
  coord_sf()

library(ggspatial)
library(sf)
ggplot() +
  layer_spatial(sf::st_bbox(camb_bb))

st_bbox(c(xmin = camb_bb["left"], xmax = camb_bb["right"],
          ymax = camb_bb["top"], ymin = camb_bb["bottom"]),
        crs = st_crs(4326))

a <- st_bbox(c(xmin = 16.1, xmax = 16.6, ymax = 48.6, ymin = 47.9), crs = st_crs(4326))
str(a)

load_longlake_data()
longlake_waterdf # is a simple features object
a <- st_bbox(longlake_waterdf)
a
 #    xmin      ymin      xmax      ymax 
 # 409949.5 5083315.6  412606.5 5087084.0 
ggplot() +
  layer_spatial(sf::st_bbox(longlake_waterdf)) +
  layer_spatial(longlake_depthdf) 

library(OpenStreetMap)
# define upleft lowright as lat, lon
# camb_bb
upleft <- c(43.25, -73.65)
lowright <- c(42.90, -73.25)
ggplot() +
  openmap(c(LAT2,LON1), c(LAT1,LON2), zoom = NULL,
               type = c("osm", "stamen-toner", "stamen-terrain","stamen-watercolor", "esri","esri-topo")[6],
               mergeTiles = TRUE)
  

```

```{r}
# https://cran.r-project.org/web/packages/osmdata/vignettes/osmdata.html
# https://wiki.openstreetmap.org/wiki/Category:Keys
# All overpass queries begin with a bounding box, defined in osmdata with the function opq():

# The overpass API only accepts simple rectangular bounding boxes, and so data requested with a bounding polygon will actually be all data within the corresponding rectangular bounding box, but such data may be subsequently trimmed to within the polygon with the trim_osmdata() function, demonstrated in the code immediately below.

# usual format: 
# bbox = left,bottom,right,top
# bbox = min Longitude , min Latitude , max Longitude , max Latitude 
# ie xmin, ymin, xmax, ymax

q <- opq(bbox = c(51.1, 0.1, 51.2, 0.2))
# The following sub-section provides more detail on bounding boxes. Following the initial opq() call, osmdata queries are built by adding one or more ‘features,’ which are specified in terms of key-value pairs. For example, all paths, ways, and roads are designated in OSM with key=highway, so that a query all motorways in greater London (UK) can be constructed as follows:
q <- opq(bbox = 'greater london uk') %>%
    add_osm_feature(key = 'highway', value = 'motorway')

bb <- getbb ('london uk', format_out = 'polygon')
x <- opq(bbox = bb) %>%
    add_osm_feature(key = 'highway', value = 'motorway') %>%
    osmdata_sf () %>%
    trim_osmdata (bb)

# osmdata_sf() returns OSM data in Simple Features (SF) format, defined by the
# Open Geospatial Consortium, and implemented in the R package sf. This package
# provides a direct interface to the C++ Graphical Data Abstraction Library
# (GDAL) which also includes a so-called ‘driver’ for OSM data. This means that
# OSM data may also be read directly with sf, rather than using osmdata. In this
# case, data must first be saved to disk, which can be readily achieved using
# osmdata_xml() described above, or through downloading directly from the
# overpass interactive query builder.

opq(bbox = 'Trentham, Australia') %>%
    add_osm_feature(key = 'name') %>%
    # osmdata_xml(filename = 'trentham.osm')
    osmdata_xml(filename = here::here("map_data", 'trentham.osm'))

# The GDAL drivers used by sf can only load single ‘layers’ of features, for
# example, points, lines, or polygons. In contrast, osmdata loads all features
# simultaneously:
sf::st_read(here::here("map_data", 'trentham.osm'), layer = 'points')
sf::st_read(here::here("map_data", 'trentham.osm'), layer = 'lines')
sf::st_read(here::here("map_data", 'trentham.osm'), layer = 'polygons')

# The GDAL drivers used by sf can only load single ‘layers’ of features, for
# example, points, lines, or polygons. In contrast, osmdata loads all features
# simultaneously:
(a <- osmdata_sf(q, here::here("map_data", 'trentham.osm')))
names(a$osm_points)
names(osmdata_sf(q, 'trentham.osm')$osm_points)
# IMPORTANT!!
# https://www.liamdbailey.com/post/building-maps-using-openstreetmap-content/
# The first step is to specify the area within which we want to search for
# OpenStreetMap features. We can specify the latitude and longitude limits
# manually, but you can also use the getbb() function to return the limits of a
# particular place (e.g. a city).
getbb(place_name = "Greater Melbourne, Australia")
melb_bb <- getbb(place_name = "Greater Melbourne, Australia")
melb_bb

##     min   max
## x 144.4 146.2
## y -38.5 -37.4

# didn't work; altneratively
# ie xmin, ymin, xmax, ymax
melb_bb2 <- matrix(data=c(144.6, 146.2,
                          -38.5, -37.4), 
                   ncol=2, byrow=TRUE,
                   dimnames=list(c("x", "y"), c("min", "max")))
melb_bb2
melb_bb <- melb_bb2

make_bb <- function(xmin, ymin, xmax, ymax){
  matrix(data=c(xmin, xmax, ymin, ymax), 
         ncol=2, byrow=TRUE,
         dimnames=list(c("x", "y"), c("min", "max")))
}
make_bb(144.6, -38.5, 146.2, -37.4)

# define queries
# query railway lines
melb_query_line <- opq(bbox = melb_bb2, timeout = 120) %>% 
  add_osm_feature(key = 'route', value = 'train')

melb_query_station <- opq(bbox = melb_bb2, timeout = 120) %>% 
  add_osm_feature(key = 'railway', value = 'station')

melbourne_trainline <- melb_query_line %>% 
  osmdata_sf()

melbourne_station <- melb_query_station %>% 
  osmdata_sf()

melbourne_trainline

melbourne_trainline_lines <- melbourne_trainline$osm_lines
melbourne_station_points  <- melbourne_station$osm_points

ggplot() +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "black") +
  geom_sf(data = melbourne_station_points, size = 1, shape = 21, colour = "black", fill = "dark grey") +
  theme_void()

# Although we queried within the greater Melbourne area, the lines and polygons
# can extend outside this bounding box. We can deal with this a number of ways.
# Here we’ll use a combination of trim_osmdata() from within osmdata to clip our
# lines and the coord_sf() function to adjust the limits of plot to match the
# bounding box of Melbourne we’ve been using.

# melb_bb_poly <- getbb(place_name = "Melbourne, Australia",
#                       format_out = "sf_polygon")

# create the polygon (my workaround)
xmin <- 144.6; ymin <- -38.5; xmax <- 146.3; ymax <- -37.4
Poly_Coord_df = data.frame(lon=c(xmin, xmax), lat=c(ymin, ymax))
melb_bb_poly = Poly_Coord_df %>% 
  st_as_sf(coords = c("lon", "lat"), crs = 4326) 

melbourne_trainline_trim <- melbourne_trainline %>% 
  #Use exclude = FALSE to include lines that partially overlap our boundaries
  trim_osmdata(bb_poly = melb_bb_poly, exclude = FALSE)

melbourne_station_trim <- melbourne_station %>% 
  trim_osmdata(bb_poly = melb_bb_poly, exclude = FALSE)

melbourne_trainline_lines <- melbourne_trainline_trim$osm_lines
melbourne_station_points  <- melbourne_station_trim$osm_points

ggplot() +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "black") +
  geom_sf(data = melbourne_station_points, size = 1, shape = 21, colour = "black", fill = "dark grey") +
  theme_void() +
  coord_sf(xlim = melb_bb[1, ], ylim = melb_bb[2, ])

#For each station, determine the distance to all train lines
min_dist <- sf::st_distance(melbourne_station_points,
                            melbourne_trainline_lines) %>% 
  #Determine the minimum distance for each station
  apply(MARGIN = 1, FUN = min)

melbourne_station_points_subset <- melbourne_station_points %>% 
  dplyr::mutate(dist = min_dist) %>% 
  dplyr::filter(dist <= 1000)
  
ggplot() +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "black") +
  geom_sf(data = melbourne_station_points_subset, size = 1, shape = 21,
          colour = "black", fill = "dark grey") +
  theme_void() +
  coord_sf(xlim = melb_bb[1, ], ylim = melb_bb[2, ])

bass_strait <- opq(bbox = melb_bb, timeout = 120) %>% 
  add_osm_feature(key = 'natural', value = 'strait') %>% 
  add_osm_feature(key = "name", value = "Bass Strait", value_exact = FALSE) %>%
  osmdata_sf()

bass_strait_polygon <- bass_strait$osm_multipolygons

yarra <- opq(bbox = melb_bb, timeout = 120) %>% 
  add_osm_feature(key = 'waterway', value = 'river') %>% 
  add_osm_feature(key = "name", value = "Yarra River", value_exact = FALSE) %>%
  osmdata_sf()

yarra_line <- yarra$osm_multilines

ggplot() +
  geom_sf(data = bass_strait_polygon, fill = "blue", colour = NA) +
  geom_sf(data = yarra_line, colour = "blue", size = 1.5) +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "gray") +
  geom_sf(data = melbourne_station_points_subset, size = 2, shape = 21,
          colour = "black", fill = "dark grey") +
  theme_void() +
  coord_sf(xlim = melb_bb[1, ], ylim = melb_bb[2, ])


```



```{r}
library(USAboundaries)
data(package="USAboundaries")
us_zipcodes() %>% filter(zipcode==12816)
us_zipcodes() %>% filter(zipcode %in% c(12816, 12834))
us_cities() %>% filter(state_abbr=="NY", county_name=="Washington")

# ny data
ny1 <- nytroll %>%
  filter(stabbr=="NY", date==max(date))
# create nyc records
# 36000 New York
# 36005 Bronx
# 36047 Kings
# 36061 New York
# 36081 Queens
# 36085 Richmond
nyc <- tribble(
  ~fips, ~county,
  "36000", "New York",
  "36005", "Bronx",
  "36047", "Kings",
  "36061", "New York",
  "36081", "Queens",
  "36085", "Richmond") %>%
  mutate(cap100k=ny1$cap100k[ny1$fips=="36998"])
nybase <- bind_rows(ny1, nyc)

nydata <- us_counties(states = "NY") %>%
  dplyr::select(-13) %>%  # state_name is 9 and 13, so delete second as duplicated and unnecessary
  left_join(nybase %>%
              dplyr::select(geoid=fips, cap100k),
            by="geoid")

# ggplot(nydata) + 
#   geom_sf() + 
#   coord_sf()

nydata %>%
  mutate(f=cut(cap100k, seq(0, 100, 10))) %>%
  count(f)
# good cuts look like 40-80 bt 10, 80-100, > 200
nydata %>% mutate(f=cut(cap100k, seq(0, 100, 10))) %>% filter(is.na(f))

# brewer.pal.info
# clrs <- c(brewer.pal(5, "Paired"), "black")
clrs <- brewer.pal(7, "RdBu") %>% rev()

p <- nydata %>%
  mutate(f=cut(cap100k, c(seq(30, 80, 10), 100, Inf))) %>%
  ggplot() + 
  geom_sf(aes(fill=f)) + 
  coord_sf() +
  scale_fill_manual(values=clrs) +
  theme_map() +
  geom_sf_text(aes(label = name), colour="black", size=2) +
  guides(fill = guide_legend(reverse = TRUE)) +
  theme(legend.position = "right") +
  ggtitle("Covid-9 cases per 100,000 population",
          subtitle=paste0("Most recent 7-day average as reported on ", format(today(), "%B %d, %Y"))) +
  theme(legend.position = c(.85, .4)) +
  legend_notitle
p

ggsave(plot=p, filename=here::here("results", "nyco_map.png"), width=10, height=6.5, units="in")
```

