---
title: "Cambridge Lumberyard analysis"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook: 
    df_print: paged
    fig_height: 6
    fig_width: 8
    toc: yes
    number_sections: yes
    code_folding: hide
editor_options:
  chunk_output_type: console
---

# SETUP SECTION

```{r setup, eval=TRUE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}

# note that eval=TRUE unless set to FALSE
# to have a chunk's output show in the html file, set include=TRUE in the chunk's options

knitr::opts_chunk$set(eval=TRUE, include=FALSE, echo=FALSE, message=FALSE, rows.print=20)
options(width = 150)
```

```{r libraries}
library(tidyverse)
tprint <- 50  # default tibble print
options(tibble.print_max = tprint, tibble.print_min = tprint) # show up to tprint rows

# tools
library(vroom)
library(readxl)
library(lubridate)
library(RColorBrewer)
library(RcppRoll)
library(fredr)
library(btools)
library(tidycensus)
library(fs)
library(archive)
library(arrow)

# graphics
library(scales)
library(ggbeeswarm)
library(patchwork)
library(gridExtra)
library(ggrepel)
library(ggbreak)

# tables
library(knitr)
library(kableExtra)
library(DT)
library(gt)

# maps
library(maps)
# https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html
library(usmap)
library(ggmap)
register_google(key = gmaps_apikey)
library(ggspatial)
library(sf)
library(tigris)
options(tigris_use_cache = TRUE)
# library(remotes)
# remotes::install_github("ropensci/osmdata")
library(osmdata) # package for working with streets
# library(showtext) # for custom fonts
library(rvest)

```

```{r locations}
# dsacs <- r"(E:\data\CA_sacs/)"
# dsacs_all <- paste0(dsacs, "data/allyears/")
# 
# dj90 <- r"(E:\data\CA_j90/)"
# dj90_all <- paste0(dj90, "data/allyears/")
# dcenpop <- r"(E:\data\census_annpop\)"
dcenpop <- r"(E:\data\census_annpop)"
dpl <- r"(E:\data\census_redistricting)"

dacssf <- r"(E:\data\acs\sf\)"
dny2009 <- r"(E:\data\acs\sf\2009_5year\ny\)"
dny2014 <- r"(E:\data\acs\sf\2014_5year\ny\)"
dny2019 <- r"(E:\data\acs\sf\2019_5year\ny\)"



```


```{r functions_utility}
source(here::here("r", "functions_utility.r"))

get_rowlab <- function(sgeotype){
  factor(sgeotype,
         levels=c("state", "county", "place", "cosub"),
         labels=c("Statewide",
                  "Selected counties",
                  "Selected villages",
                  "Selected towns"))
}


```


```{r constants}
#.. geoids of interest ----
cambridge_town <- "3611511836"
cambridge_village <- "3611825"
cambridge_schools <- "3606210"
greenwich_town <- "3611530686"
greenwich_village <- "3630675"
greenwich_schools <- "3612900"
washington_county <- "36115"
newyork_state <- "36"

#.. api keys ----
source("~/R_projects/api_keys.r", verbose=TRUE)
fredr_set_key(fred_apikey)
# gmaps_apikey <- "AIzaSyDFWxscpciI2HDziBJ3CIhqxKWEqbaD6VM"
## Not run: 
# census_api_key(census_apikey, install = TRUE, overwrite=TRUE)
# First time, reload your environment so you can use the key without restarting R.
# readRenviron("~/.Renviron")
# Sys.getenv("CENSUS_API_KEY")  # check

#.. graph theme items ----
legend_none <- theme(legend.position = "None")
legend_notitle <- theme(legend.title = element_blank())
caption_left <- theme(plot.caption = element_text(hjust = 0))

#.. source notes ----
source_acs <- "American Community Survey 5-year summary file"
source_decennialpop <- "U.S. Census Bureau Decennial Census"
source_cenpop <- "U.S. Census Bureau City and Town Population Estimates"
# (https://www.census.gov/data/tables/time-series/demo/popest/2010s-total-cities-and-towns.html)
source_hud <- "HUD Comprehensive Housing Affordability Strategy data, based on 2014-2018 ACS"
source_padcoproj <- "Cornell Program on Applied Demographics, County Projections 2018 (https://pad.human.cornell.edu/counties/projections.cfm)"

# https://pad.human.cornell.edu/schools/projections.cfm
# https://www.nyeducationdata.org/
# https://www.ers.usda.gov/data-products/atlas-of-rural-and-small-town-america/download-the-data/

```

```{r geos_dataframe}
geos <- read_delim(
"geotype;geoid;geoname

state; 36; New York

county; 36001; Albany County, New York
county; 36091; Saratoga County, New York
county; 36113; Warren County, New York
county; 36115; Washington County, New York

cosub; 36115; Washington County, New York

place; 3602550; Argyle village, New York
place; 3611825; Cambridge village, New York
place; 3630675; Greenwich village, New York
place; 3664771; Salem village, New York
place; 3665750; Schuylerville village, New York

school; 3603210; Argyle Central School District, New York
school; 3606210; Cambridge Central School District, New York
school; 3612900; Greenwich Central School District, New York
school; 3625470; Salem Central School District, New York
school; 3625770; Saratoga Springs City School District, New York
school; 3626160; Schuylerville Central School District, New York

zcta; 12816; 12816
zcta; 12834; 12834

", col_types=cols(.default = col_character()), trim_ws=TRUE
)
geos
```


# GOALS

The goal is to understand the current local housing situation and help inform decisions about what kind of housing might be appropriate to consider within the Lumber Yard.

I think the big questions are: • What does the census and other publicly available records tell us about the population and housing within Village of Cambridge (and perhaps the CCS school district catchment area of White Creek, Cambridge and Jackson and how they compare to prior censuses to see what the trends are?.\
• What is the current status of housing in Village of Cambridge?\
• What is needed or might be the right mix of housing options in the Village of Cambridge, generally to ensure a vibrant, dynamic, diverse, multi-generational caring rural community?\
• Are there case studies/lessons learned from other ' housing developments' that attract younger people (25-35 year olds) and entrepreneurs and remote workers to rural communities?

# DATA PREPARATION SECTION

```{r acs_notes}
# https://www.census.gov/programs-surveys/acs/data/summary-file.2019.html

```

```{r tidycensus_notes}
# https://walker-data.com/tidycensus/articles/basic-usage.html 
# load_variables() takes two required arguments: year of Census or endyear of ACS sample, and dataset name
# For decennial Census, possible dataset choices include "pl" for the redistricting files (currently the only choice for 2020), "sf1" or "sf2" (2000 and 2010) and "sf3" or "sf4" (2000 only)
#  For ACS, use either "acs1" or "acs5" for the ACS detailed tables, and append /profile for the Data Profile and /subject for the Subject Tables.

# 5-year ACS for all geographies down to the block group level starting with 2005-2009

#.. get_acs and geography ----
# https://walker-data.com/tidycensus/articles/basic-usage.html#working-with-acs-data-1
# geography="county subdivision", state="NY", county="Washington", # gets all in county
# geography="place", state="NY", # DON'T USE COUNTY, gets all in state
# geography="school district (unified)", state="NY", # DON'T USE COUNTY, gets all
# geography="zcta", state="NY", zcta=c(12816, 12834) # DON'T USE COUNTY, gets all

# keep_geo_vars=TRUE doesn't seem to matter for what I'm doing

```

```{r tidycensus_nonacs}
# median age by state in 2010
age10 <- get_decennial(geography = "state", 
                       variables = "P013001", 
                       year = 2010)

get_estimates(
  geography="county",
  product = "characteristics",
  # variables = NULL,
  breakdown = "AGEGROUP",
  state="NY",
  county="Washington",
  time_series = TRUE)

tpop <- get_estimates(
  geography="county subdivision",
  product = "characteristics",
  # variables = NULL,
  breakdown = "AGEGROUP",
  state="NY",
  county="Washington",
  time_series = TRUE)

```


```{r tidycensus_functions}

get_acstab <- function(acstab, years, dict=uvacs, geos=geos){
  
  get_geo <- function(geotype, year, acstab){
    print(geotype)
    if(geotype=="state"){
      df <- get_acs(geography="state",
                    state=states,
                    table=acstab,
                    year=year)
      } else if(geotype=="county") {
        df <- get_acs(geography="county",
                      state=states,
                      county=counties,
                      table=acstab,
                      year=year)
       } else if(geotype=="cosub"){
          df <- get_acs(geography="county subdivision",
                        state=cosubs_state,
                        county=cosubs_county,
                        table=acstab,
                   year=year)
        } else if(geotype=="place"){
          df <- get_acs(geography="place",
                   state=states,
                   table=acstab,
                   year=year)
        } else if(geotype=="school"){
          df <- get_acs(geography="school district (unified)",
                   state=states,
                   table=acstab,
                   year=year)
        } else if (geotype=="zcta" & year > 2009) {
          df <- get_acs(geography="zcta",
                        state="NY",
                        zcta=zctas,
                        table=acstab,
                        year=year)
          
        } else {
          df <- tibble(GEOID=NA_character_,
                       NAME=NA_character_,
                       variable=NA_character_,
                       estimate=NA_real_,
                       moe=NA_real_)
        }
        
        df <- df %>%
          setNames(str_to_lower(names(.))) %>%
          mutate(geotype=!!geotype,
                 year=!!year)  %>%
          select(geotype, year, geoid, geoname=name, variable, estimate, moe)
        
        df <- df %>%
          # drop non-cosub govts that are not specified in the geos file (revisit)
          left_join(geos %>% 
              select(geoid, geotype, geos_geoname=geoname) %>%
              mutate(ingeo=TRUE),
            by=c("geoid", "geotype")) %>%
          filter((geotype=="cosub") | ingeo) %>%
          select(-ingeo)
        return(df)
        }
  
  get_year <- function(year, acstab, geos){
    # the main program -- direct action for a single year
    print(year)
    if(acstab %in% tabs_avail$tableid[tabs_avail$year==year]) {
      map_dfr(geotypes, get_geo, year, acstab)
    } else {
      tibble(geo=NULL,
                  geoid=NULL,
                  name=NULL,
                  variable=NULL,
                  estimate=NULL,
                  moe=NULL)
    }
  }
  
  # these variables are available throughout the function
  geotypes <- unique(geos$geotype)
  states <- geos %>% filter(geotype=="state") %>% .$geoid
  counties <- geos %>% 
    filter(geotype=="county") %>% 
    mutate(counties=str_sub(geoid, 3, 5)) %>%
    .$counties
  places <- geos %>% filter(geotype=="place") %>% .$geoid
  cosubs <- geos %>% filter(geotype=="cosub") %>% .$geoid
  cosubs_state <- str_sub(cosubs, 1, 2)
  cosubs_county <- ifelse(nchar(cosubs)==5, str_sub(cosubs, 3, 5), NULL)
  zctas <- geos %>% filter(geotype=="zcta") %>% .$geoid
  
  tabs_avail <- count(dict, tableid, year=endyear)
  df <- map_dfr(years, get_year, acstab, geos)
  df
}

# tmp <- get_acstab(acstab="B25071", years=c(2009, 2014, 2019), dict=uvacs, geos=geos)

```

```{r ONETIME_tidycensus_uvacs}
# build a full variable list and clean it up so that it has uniform titles
vacs2009 <- load_variables(2009, "acs5", cache = TRUE)
vacs2014 <- load_variables(2014, "acs5", cache = TRUE)
vacs2018 <- load_variables(2018, "acs5", cache = TRUE)
vacs2019 <- load_variables(2019, "acs5", cache = TRUE)
vacs <- 
  bind_rows(vacs2009 %>% mutate(endyear=2009),
            vacs2014 %>% mutate(endyear=2014),
            vacs2018 %>% mutate(endyear=2018),
            vacs2019 %>% mutate(endyear=2019))

# create uniform labels based on latest year and count # years
uvacs <- vacs %>%
  separate(name, c("tableid", "vnum"), remove=FALSE) %>%
  group_by(name) %>%
  arrange(endyear) %>%
  mutate(nyears=n(), ulabel=label[endyear==max(endyear)], maxyear=max(endyear)) %>%
  ungroup %>%
  # there are never more than 8 parts to the uniform lable
  separate(ulabel, into=paste0("ulab", 1:8), sep="!!", remove=FALSE)

saveRDS(uvacs, here::here("data", "uvacs.rds"))

```


```{r tidycensus_table_selection}
# https://data.census.gov/cedsci/table
# ACS_2019_SF_5YR_Appendices.xlsx sheet Appendics A
# ACS2019_Table_Shells.xlsx

uvacs <- readRDS(here::here("data", "uvacs.rds"))

# possible concepts of interest
# AGE BY DISABILITY STATUS BY HEALTH INSURANCE COVERAGE STATUS
# AGE BY IMPUTATION OF INDEPENDENT LIVING DIFFICULTY FOR THE CIVILIAN NONINSTITUTIONALIZED POPULATION 15 YEARS AND OVER
# AGE BY NUMBER OF DISABILITIES
# AGE BY PRESENCE OF A COMPUTER AND TYPES OF INTERNET SUBSCRIPTION IN HOUSEHOLD
# AGE BY VETERAN STATUS BY EMPLOYMENT STATUS FOR THE CIVILIAN POPULATION 18 TO 64 YEARS
# AGE OF HOUSEHOLDER BY GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS

tabs <- count(uvacs, tableid, concept)

s <- "educational attain"
s <- "geographical mobility"
s <- "percent of"
s <- "rent"
s <- "age"
(look <- tabs %>% 
  # filter(str_sub(tableid, 1, 1)=="B") %>%
  filter(str_detect(concept, coll(s, ignore_case = TRUE))) %>% select(tableid, concept))


# if needed:
df <- get_acs(geography="county",
            state="NY",
            # county=c("115"),
            table="B25071",
            year=2019)

```

```{r tidycensus_save_individual_tables}

# Universe if NOT Population 25 years and over in the United States (from table shell) is listed below
# B01001 SEX BY AGE
# total population
# B01002   MEDIAN AGE BY SEX
# Universe: Total population
# B07001    GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY AGE FOR CURRENT RESIDENCE IN THE UNITED STATES
# Universe:  Population 1 year and over in the United States
# B07009 GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR CURRENT RESIDENCE IN THE UNITED STATES
# B07409   GEOGRAPHICAL MOBILITY IN THE PAST YEAR BY EDUCATIONAL ATTAINMENT FOR RESIDENCE 1 YEAR AGO IN THE UNITED STATES
# B15003   EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER
# B25071  MEDIAN GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS (DOLLARS)
# Universe:  Renter-occupied housing units paying cash rent

save_table <- function(tab){
  # print(tab)
  df <- get_acstab(acstab=tab, years=c(2009, 2014, 2019), dict=uvacs, geos=geos)
  df <- df %>% mutate(tableid=tab)
  fn <- paste0("tab_", tab, ".rds")
  saveRDS(df, here::here("data", fn))
  df
}

# get tables one at a time depending on exploration above
df <- save_table("B01001")
df <- save_table("B01002")
df <- save_table("B07001")
df <- save_table("B07009")
# df <- readRDS(here::here("data", "tab_B07009.rds"))
df <- save_table("B07409")
df <- save_table("B15003")
df <- save_table("B25071")


```


```{r tidycensus_combine_save}

# tmp <- get_acstab(acstab="B25071", years=c(2009, 2014, 2019), dict=uvacs, geos=geos)
# combine tables ----
combine_tabs <- function(tabnames){
  get_tab <- function(tabname){
    fname <- paste0("tab_", tabname, ".rds")
    df <- readRDS(here::here("data", fname))
    df
  }
  # get all the tabs
  df <- map_dfr(tabnames, get_tab)
  # clean them up
  df <- df %>%
    filter(!is.na(variable)) %>%
    select(-geos_geoname)%>%
    left_join(uvacs %>% 
                filter(endyear==maxyear) %>%
                select(variable=name, vnum, concept, starts_with("ulab")),
              by="variable") %>%
    mutate(concept=str_to_sentence(concept),
           across(ulab1:ulab8, ~ str_remove(.x, ":")),
           sname=str_extract(geoname, "^[^,]+"),
           sname=case_when(geoid=="36" ~ "New York State",
                           str_detect(sname, "ZCTA") ~ str_replace(sname, "ZCTA5", "Zip"),
                           TRUE ~ sname),
           sname=ifelse(sname %in% c("Salem village", "Salem CDP"),
                        "Salem village/CDP",
                        sname)) %>%
    select(geotype, geoid, sname, variable, tableid, vnum, year, estimate, moe,
           concept, ulab1:ulab8, ulabel, geoname) %>%
    arrange(geotype, geoid, variable, year)
}

# tabnames <- c("B01002", "B07001", "B07009", "B07409", "B15003", "B25071")
(tabfiles <- list.files(here::here("data"), pattern="tab_"))
tabnames <- tabfiles %>% str_remove("tab_") %>% str_remove(".rds")
acsdata <- combine_tabs(tabnames)
glimpse(acsdata)
count(acsdata, tableid)
count(acsdata, sname)
saveRDS(acsdata, here::here("data", "acsdata.rds"))

```


```{r ONETIME_CensusCityTown_pop}
# https://community.rstudio.com/t/get-file-name-from-url/25505/4
# https://fs.r-lib.org/reference/index.html
# library(fs)
# uplace %>%
#   path_file() %>% 
#   path_ext_remove()

# https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/sub-est2019.pdf

# 2020 and 2021 state-level births, deaths, migration
# https://www2.census.gov/programs-surveys/popest/datasets/2020-2021/state/totals/NST-EST2021-alldata.csv

# 2020 and 2021 state-level ests and changes
# https://www2.census.gov/programs-surveys/popest/datasets/2020-2021/state/totals/NST-EST2021-popchg2020_2021.csv

#..2010-2020 data csv format ----
# 2010-2020 place-level ests
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/SUB-EST2020_ALL.csv
# 2010-2020 county-level ests
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv
# 2010-2020 county-level ests plus births deaths migration
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020-alldata.csv
# 2010-2020 county-level housing estimates
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/housing/HU-EST2020_ALL.csv
# US, states, and regions
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020.csv
# ... popests and changes
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020-popchg2010-2020.csv
# ... popests and births, deaths, migration
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020-alldata.csv

#.. vintage 2021 data info ---- December 21, 2021 states data, and national and
#state components of change
#https://www.census.gov/newsroom/press-releases/2021/2021-population-estimates.html
#https://www.census.gov/programs-surveys/popest/data/tables.html 2020 county
#data from redistricting files
#https://www.census.gov/library/visualizations/interactive/2020-population-and-housing-state-data.html
#https://www.census.gov/programs-surveys/decennial-census/about/rdo/summary-files.html#P1
# The 2020 Census Redistricting Data (P.L. 94-171) Summary File data are
# available for all 50 states, the District of Columbia, and the Commonwealth of
# Puerto Rico through data.census.gov and FTP download (in the Legacy Format).
# But they also appear to have county data (djb)
#  Washington County, NY
# 
# Total population (2020): 61,302 
# ----
# Population Data
# Total population (2020): 61,302
# Total population (2010): 63,216
# Numeric change (2010–2020): -1,914
# Percent change (2010–2020): -3.0
# from techdoc:
# This product contains summary statistics on population and housing subjects. Population
# counts for the total population and for the population 18 years and over are presented by race
# and by Hispanic or Latino origin, and for the total group quarters population by major group
# quarters type. The product includes one housing table showing occupancy status (occupied,
# vacant). The official titles of the six tables are:
# P1. Race
# P2. Hispanic or Latino, and Not Hispanic or Latino by Race
# P3. Race for the Population 18 Years and Over
# P4. Hispanic or Latino, and Not Hispanic or Latino by Race for the Population 18 Years and
# Over
# P5. Group Quarters Population by Major Group Quarters Type
# H1. Occupancy Status




ubase <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/"
ubase <- "# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/"

f <- function(url) download.file(url, file.path(dcenpop, path_file(url)), mode="wb")

#.. all (?) as csv ----
uallcsv <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/cities/totals/sub-est2019_all.csv"
f(uallcsv)

#.. population ----
# comp means components of change
ucounty <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/counties/totals/co-est2019-annres.xlsx"
f(ucounty)
ucocomp <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/counties/totals/co-est2019-comp.xlsx"
f(ucocomp)

# places, cities
uplace <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/cities/totals/SUB-IP-EST2019-ANNRES.xlsx"
f(uplace)

umcdny <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/mcds/totals/SUB-MCD-EST2019-ANNRES-36.xlsx"
f(umcdny)

ucbsa <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/cbsa-met-est2019-annres.xlsx"
f(ucbsa)
ucbsacomp <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/cbsa-met-est2019-comp.xlsx"
f(ucbsacomp)

ucsa <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/csa-est2019-annres.xlsx"
f(ucsa)
ucsacomp <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/metro/totals/csa-est2019-comp.xlsx"
f(ucsacomp)

#.. housing ----
usthousing <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/housing/totals/NST-EST2019-ANNHU.xlsx"
f(usthousing)

ucohousing <- "https://www2.census.gov/programs-surveys/popest/tables/2010-2019/housing/totals/CO-EST2019-ANNHU.xlsx"
f(ucohousing)

```


```{r popann_2020}

# just estimates, not components of change:
# US, states, and regions
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020.csv
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/SUB-EST2020_ALL.csv

# 2010-2020 county-level ests plus births deaths migration
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020-alldata.csv
# 2010-2020 county-level housing estimates
# https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/housing/HU-EST2020_ALL.csv

dcenpop <- r"(E:\data\census_annpop)"
ustate <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/totals/nst-est2020.csv"
ucounty <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv"
usubco <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/cities/SUB-EST2020_ALL.csv"

# dcenpop <- r"(E:\data\census_annpop\)"
# nst-est2020.csv co-est2020.csv SUB-EST2020_ALL.csv HU-EST2020_ALL.csv
popfiles <- c("nst-est2020.csv", "co-est2020.csv", "SUB-EST2020_ALL.csv") 

f <- function(url) download.file(url, file.path(dcenpop, path_file(url)), mode="wb")
f(ustate)
f(ucounty)
f(usubco)

# combine files and clean
f2 <- function(url, dcenpop){
  df <- vroom(file.path(dcenpop, path_file(url)), col_types=cols(.default="c"))
  df %>%
    mutate(src=path_file(url))
}
df <- map_dfr(list(ustate, ucounty, usubco), f2, dcenpop)
names(df)

# use !! to unquote one variable or !!! to unquote a vector of variables inside
# of arrange(). When you pass those columns, if they are bare, quote them using
# quo() for one variable or quos() for a vector
idvars <- quos(c(sumlev, region, division, state, 
         county, place, cousub, concit, primgeo_flag, funcstat,
         stname, ctyname, name))

df2 <- df %>%
  setNames(str_to_lower(names(.))) %>%
  select(src, !!!idvars, everything()) %>%
  # we want all pop variables to start with "pop" and end with the year
  rename(popcensus2010=census2010pop,
         popestimatesbase2010=estimatesbase2010,
         popcensusestimate2020=popestimate042020) %>%
  mutate(across(starts_with("pop"), as.numeric))

count(df2, sumlev, src)
names(df2)
count(df2 %>% filter(is.na(name)), sumlev)

# get rid of duplicate sumlev 040
tmp <- df2 %>% 
  filter(sumlev=="040") %>% 
  mutate(name2=ifelse(is.na(stname), name, stname)) %>%
  select(src, !!!idvars, name2, popcensus2010, popcensusestimate2020) %>%
  arrange(name2, src)
# nst-est2020.csv has PR, others don't; all pop numbers appear the same

# get county names to put on file
counties <- df2 %>%
  filter(sumlev=="050", !is.na(ctyname)) %>%
  select(state, county, ctyname) %>%
  distinct()

df3 <- df2 %>%
  filter(!(sumlev=="040" & src != "nst-est2020.csv")) %>%
  # fill in names
  mutate(stname=ifelse(sumlev=="040", name, stname),
         name=ifelse(sumlev=="050", ctyname, name)) %>%
  select(-ctyname) %>%
  left_join(counties, by=c("state", "county")) %>% # bring in ctyname
  relocate(ctyname, .after=stname) %>%
  # filter(state=="36")
  # create geoid for NY records
  mutate(sgeotype=case_when(state=="36" & sumlev=="040" ~ "state",
                            state=="36" & sumlev=="050" ~ "county",
                            state=="36" & sumlev=="061" ~ "cosub", # cities and towns
                            state=="36" & sumlev=="157" ~ "place", # villages
                            TRUE ~ NA_character_),
         geoid=case_when(sgeotype=="state" ~   paste0("04000US", state),
                         sgeotype=="county" ~  paste0("05000US", state, county),
                         sgeotype=="cosub" ~   paste0("06000US", state, county, cousub),
                         sgeotype=="place" ~   paste0("16000US", state, place)))
names(df3)

# create long file
df4 <- df3 %>%
  select(geoid, sumlev, sgeotype, state, stname, geoname=name,
         county, place, cousub, concit, starts_with("pop")) %>%
  pivot_longer(starts_with("pop")) %>%
  mutate(esttype=case_when(str_detect(name, "popcensus") ~ "census",
                           str_detect(name, "popestimatesbase") ~ "estsbase",
                           str_detect(name, "popestimate") &
                             !str_detect(name, "popestimatesbase") ~ "est"),
         year=str_sub(name, -4, -1) %>% as.integer())

ny <- df4 %>%
  filter(state=="36")
tmp <- ny %>% filter(str_detect(geoname, "Dexter"))

saveRDS(df4, file.path(dcenpop, "popann2020.rds"))


```



```{r OLD_read_popann_and_xwalk}

#.. read data ----
# https://www.statsamerica.org/geography-tools.aspx
dcenpop <- r"(E:\data\census_annpop\)"
uallcsv <- "https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/cities/totals/sub-est2019_all.csv"
path_file(uallcsv)
dfall1 <- read_csv(file.path(dcenpop, path_file(uallcsv)))
glimpse(dfall1)
names(dfall1)

# why is CENSUS2010POP character?
bad <- dfall1 %>%
  mutate(rn=row_number()) %>%
  filter(is.na(as.numeric(CENSUS2010POP))) %>%
  select(SUMLEV:POPESTIMATE2010, rn)
bad
nrow(bad) # 430 rows

count(dfall1, FUNCSTAT)
# https://www.census.gov/library/reference/code-lists/functional-status-codes.html
#   FUNCSTAT     n
#   <chr>    <int>
# 1 A        69600  active govt
# 2 B           24
# 3 C           62
# 4 F        11195  fictitious entity to fill Census hierarchy, includes many types of areas
# 5 G            1
# 6 I          108  inactive govt with special purpose powers
# 7 N           70
# 8 S          374  statistical entity

# clean up and make an rds file ----
dfall2 <- dfall1 %>%
  setNames(str_to_lower(names(.))) %>%
  # we want all pop variables to start with "pop" and end with the year
  rename(popcensus2010=census2010pop,
         popestimatesbase2010=estimatesbase2010) %>%
  mutate(popcensus2010=as.numeric(popcensus2010))

# https://www.census.gov/programs-surveys/geography/technical-documentation/naming-convention/cartographic-boundary-file/carto-boundary-summary-level.html
# https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html
# https://www.census.gov/geographies/reference-files/2010/geo/state-local-geo-guides-2010/new-york.html
# https://mcdc.missouri.edu/geography/sumlevs/more-about-sumlevels.html
# https://www2.census.gov/geo/docs/reference/

# use the codes in the codes folder, not in the codes/files folder
# https://www2.census.gov/geo/docs/reference/codes/national_county.txt
# State,State ANSI,County ANSI,County Name,ANSI Cl
# AL,01,001,Autauga County,H1

# https://www2.census.gov/geo/docs/reference/codes/COUSUBlist.txt
# STATE,STATEFP,COUNTYFP,COUNTYNAME,COUSUBFP,COUSUBNAME,FUNCSTAT
# AL,01,001,Autauga County,90171,Autaugaville CCD,S

# https://www2.census.gov/geo/docs/reference/codes/PLACElist.txt  note the | delimiter
# STATE|STATEFP|PLACEFP|PLACENAME|TYPE|FUNCSTAT|COUNTY
# AL|01|00100|Abanda CDP|Census Designated Place|S|Chambers County

# https://www2.census.gov/geo/docs/reference/codes/SDlist.txt
# STATE,STATEFP,LEA,SDNAME,TYPE
# AL,01,00001,Fort Rucker School District,Unified

# delimited files, names?, and delimiter
# https://www2.census.gov/geo/docs/reference/codes/files/
# [TXT]	national_county.txt	09-May-2014 08:12	92K	 no, ,
# https://www2.census.gov/geo/docs/reference/codes/national_county.txt yes, ,
# [TXT]	national_cousub.txt	09-May-2014 08:12	1.8M	 yes, ,
# [TXT]	national_places.txt	09-May-2014 08:12	2.7M	    yes, |
# [TXT]	national_schdist.txt	09-May-2014 08:12	739K	 yes, ,

#   sumlev     n
#   <chr>  <int>
# 1 040       51  state
# 2 050     3142  county
# 3 061    21063  towns -- are 060 in geoid
# 4 071    13839  city -- 070 in geoid
# 5 157    23714  place (village) WITHIN COUNTY
# 6 162    19502  place (village) county is 000, just like geoid
# 7 170        8
# 8 172      115
# does not have sumlev 970 schooldistrict 

# selected ACS codes
# 04000US36,"New York"
# 04001US36,"New York -- Urban"
# 04043US36,"New York -- Rural"
# 05000US36001,"Albany County, New York"
# 05000US36115,"Washington County, New York"
# 06000US3600101000,"Albany city, Albany County, New York",,,
# 06000US3600106211,"Berne town, Albany County, New York",,,
# 06000US3611511836,"Cambridge town, Washington County, New York"
# 16000US3611825,"Cambridge village, New York"
# 16000US3664771,"Salem CDP, New York"
# 97000US3606210,"Cambridge Central School District, New York" NOT IN POPEST DATA

# construct acs geoid -- investigate
part <- "Albany city"
part <- "Berne town"
part <- "Cambridge"
part <- "Salem"  # CDP or village does not seem to be in popest data
dfall2 %>%
  filter(str_detect(name, part), state=="36") %>%
  select(sumlev:popcensus2010)
count(dfall2, sumlev)


# selected popest data
# sumlev state county place cousub concit primgeo_flag funcstat name
# 050    36    001    00000 00000  00000             0 A        Albany County
# 061    36    001    00000 06211  00000             1 A        Berne town
# 061    36    115    00000 11836  00000             0 A        Cambridge town

# summary paste rules for NY based on sgeotype
# state: 04000US36
# county: 05000US36,county
# cosub(town/city 061-->060): 06000US36,county,cousub 
# place(village 162-->160): 16000US36,place


dfall3 <- dfall2 %>%
  mutate(sgeotype=case_when(state=="36" & sumlev=="040" ~ "state",
                            state=="36" & sumlev=="050" ~ "county",
                            state=="36" & sumlev=="061" ~ "cosub",
                            state=="36" & sumlev=="162" ~ "place",
                            TRUE ~ NA_character_),
         geoid=case_when(sgeotype=="state" ~   paste0("04000US", state),
                         sgeotype=="county" ~  paste0("05000US", state, county),
                         sgeotype=="cosub" ~   paste0("06000US", state, county, cousub),
                         sgeotype=="place" ~   paste0("16000US", state, place)))
dfall3 %>% filter(state=="36")
dfall3 %>% filter(state=="36", sgeotype=="state")
tmp <- dfall3 %>% filter(state=="36", sgeotype=="county")
tmp <- dfall3 %>% filter(state=="36", sgeotype=="cosub", county=="115")
tmp <- dfall3 %>% filter(state=="36", sgeotype=="place")

# The “GEO.ID” field contains 14-digit codes that identify the summary level of
# data, the geographic component of the data and FIPS codes that uniquely
# identify the data. For example, the 14-digit “GEO.ID” for Harris County, TX is
# “0500000US48201” where “050” represents the summary level of the data, “0000”
# represents the 2-digit geographic variant and the 2-digit geographic
# component, “US” represents the United States, “48” represents the state of
# Texas and “201” represents Harris County.

# do final cleaning and save
dfall4 <- dfall3 %>%
  select(geoid, sumlev, sgeotype, state, stname, geoname=name,
         county, place, cousub, concit, starts_with("pop")) %>%
  pivot_longer(starts_with("pop")) %>%
  mutate(esttype=case_when(str_detect(name, "popcensus") ~ "census",
                           str_detect(name, "popestimatesbase") ~ "estsbase",
                           str_detect(name, "popestimate") &
                             !str_detect(name, "popestimatesbase") ~ "est"),
         year=str_sub(name, -4, -1) %>% as.integer())

ny <- dfall4 %>%
  filter(state=="36")
tmp <- ny %>% filter(str_detect(geoname, "Dexter"))

saveRDS(dfall4, file.path(dcenpop, "popann.rds"))

```


```{r ONETIME_pad_projections}
# Cornell Washington County projections
pad1 <- read_excel(here::here("data", "padprojections115.xlsx"))

pad2 <- pad1 %>%
  setNames(str_to_lower(names(.))) %>%
  pivot_longer(-c(1:8), names_to = "year") %>%
  mutate(year=str_sub(year, 4, 7))
glimpse(pad2)
count(pad2, county, county_descr)
count(pad2, sexcode, sex_descr)
count(pad2, agegrpcode, agegrp_descr)
count(pad2, racecode, race_descr) # all races

pad3 <- pad2 %>%
  select(-racecode, -race_descr) %>%
  rename(ccode=county, county=county_descr, 
         sex=sex_descr,
         agecode=agegrpcode, agegrp=agegrp_descr) %>%
  mutate(year=as.integer(year), sex=str_to_lower(sex))
glimpse(pad3)

pad3 %>%
  filter(sex=="all", agecode==-999) %>%
  ggplot(aes(year, value)) +
  geom_line() +
  geom_point()

saveRDS(pad3, here::here("data", "popproj_pad_washco.rds"))

```


```{r HUD_tables}
# save each table as its own file, cleaned a bit
dchas <- r"(E:\data\acs\hud_chas\)"
dtabs <- paste0(dchas, "tables/")

stdir <- r"(E:\data\acs\hud_chas\2014thru2018-040-csv_states\040\)"
codir <- r"(E:\data\acs\hud_chas\2014thru2018-050-csv_counties\050\)"
mcddir <- r"(E:\data\acs\hud_chas\2014thru2018-060-csv\060\)"
placedir <- r"(E:\data\acs\hud_chas\2014thru2018-160-csv_places\160\)"
citydir <- r"(E:\data\acs\hud_chas\2014thru2018-170-csv_consolidatedcities\170\)"
chasdirs <- c(stdir, codir, mcddir, placedir, citydir)

# the state directory should have a master list of tables
tabs <- list.files(path=stdir, pattern="*.csv", full.names = FALSE)
tabs
tools::file_path_sans_ext(tabs)
tab <- tabs[1]
dir <- chasdirs[4]

for(tab in tabs){
  a <- proc.time()
  print(tab)
  getfile <- function(dir, tab){
    
    print(dir)
    type <- case_when(str_detect(dir, "states") ~ "state",
                      str_detect(dir, "counties") ~ "county",
                      str_detect(dir, "060") ~ "mcd",
                      str_detect(dir, "places") ~ "place",
                      str_detect(dir, "consolidatedcities") ~ "concit",
                      )

    # dirlist <- list.files(path=stdir, pattern="*.csv", full.names = FALSE)
    path <- paste0(dir, tab)
    idlist <- c("source", "sumlevel", "geoid", "name", "st", "cnty", "mcd", "concit", "place")
    
    df <- read_csv(path, col_types = cols(.default="c")) %>%
      pivot_longer(-any_of(idlist), names_to="vname") %>%
      mutate(type=!!type,
             value=as.numeric(value)) %>%
      select(type, geoid, geoname=name, st, vname, value)# %>%
      # separate(vname, into=c("table", "est")) # %>%
      # mutate(etype=str_sub(est, 1, 3))
           #estnum=str_sub(est, 4, nchar(est)) %>% as.integer())
    df
  }
  df <- map_dfr(chasdirs, getfile, tab)
  # df2 <- df %>%
  #   separate(vname, into=c("table", "est")) %>%
  #   mutate(etype=str_sub(est, 1, 3),
  #          estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
  #   pivot_wider(names_from = etype)
  
  outfile <- tools::file_path_sans_ext(tab) %>% str_to_lower()
  
  saveRDS(df, paste0(dtabs, outfile, ".rds"))
  b <- proc.time()
  print(b - a)
}

glimpse(df2)





```



```{r HUD_data}
# https://www.huduser.gov/portal/datasets/cp.html
# states, counties, places, consolidated cities
dchas <- r"(E:\data\acs\hud_chas\)"

stdir <- r"(E:\data\acs\hud_chas\2014thru2018-040-csv_states\040\)"
codir <- r"(E:\data\acs\hud_chas\2014thru2018-050-csv_counties\050\)"
mcddir <- r"(E:\data\acs\hud_chas\2014thru2018-060-csv\060\)"
placedir <- r"(E:\data\acs\hud_chas\2014thru2018-160-csv_places\160\)"
citydir <- r"(E:\data\acs\hud_chas\2014thru2018-170-csv_consolidatedcities\170\)"
chasdirs <- c(stdir, codir, mcddir, placedir, citydir)

f <- function(path){
  idlist <- c("source", "sumlevel", "geoid", "name", "st", "cnty", "mcd", "concit", "place")
  read_csv(path) %>%
    pivot_longer(-any_of(idlist), names_to="vname")
}

for(dir in chasdirs){
  print(dir)
  paths <- list.files(path=dir, pattern="*.csv", full.names = TRUE)
  df <- map_dfr(paths, f)
  saveRDS(df, paste0(dir, "allfiles.rds"))
}


# slim and trim each file in an effort to make it easier to get good files
# dir <- chasdirs[1]
for(dir in chasdirs[4:5]){
  print(dir)
  df <- readRDS(paste0(dir, "allfiles.rds"))
  df2 <- df %>%
    select(-source, -sumlevel) %>%
    rename(geoname=name) %>%
    separate(vname, into=c("table", "est"), remove=FALSE) %>%
    mutate(type=case_when(str_sub(geoid, 1, 3)=="040" ~ "state",
                        str_sub(geoid, 1, 3)=="050" ~ "county",
                        str_sub(geoid, 1, 3)=="060" ~ "mcd",
                        str_sub(geoid, 1, 3)=="160" ~ "place",
                        str_sub(geoid, 1, 3)=="170" ~ "concit",
                        TRUE ~ "other"
                        ),
           st=str_sub(geoid, 8, 9),
           etype=str_sub(est, 1, 3),
           estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
    select(geoid, geoname, st, type, table, etype, estnum, value)
  saveRDS(df2, paste0(dir, "clean.rds"))
}


# now combine the different chas files
get_clean <- function(dir){
  # don't keep nonessential variables
  print(dir)
  readRDS(paste0(dir, "clean.rds")) %>%
    select(geoid, name, vname, value)
}
df <- map_dfr(chasdirs, get_clean)
saveRDS(df, paste0(dchas, "chasall.rds"))

# now create a clean file
chasall <- readRDS(paste0(dchas, "chasall.rds")) # 162m obs
head(chasall)

chas2 <- chasall %>%
  mutate(type=case_when(str_sub(geoid, 1, 3)=="040" ~ "state",
                        str_sub(geoid, 1, 3)=="050" ~ "county",
                        str_sub(geoid, 1, 3)=="160" ~ "place",
                        str_sub(geoid, 1, 3)=="170" ~ "concit",
                        TRUE ~ "other"
                        ))
count(chas2, type)

chasny <- chas2 %>%
  filter(str_sub(geoid, 8, 9)=="36") %>%
  # filter(row_number() < 10e3) %>%
  separate(vname, into=c("table", "est"), remove=FALSE) %>%
  mutate(etype=str_sub(est, 1, 3),
         estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
  select(geoid, name, type, table, etype, estnum, value) %>%
  pivot_wider(names_from = etype)
count(chasny, type)

saveRDS(chasny, paste0(dchas, "chasny.rds"))


tmp <- chasny %>%
  filter(str_detect(name, "Cambridge"))

# T1_est3	Subtotal	Owner occupied	has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)	All
# T1_est4	Subtotal	Owner occupied	has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)	less than or equal to 30% of HAMFI

tmp <- chasny %>%
  filter(table=="T1", estnum %in% 1:4) %>%
  mutate(estnum=paste0("est", estnum)) %>%
  select(-moe) %>%
  pivot_wider(names_from = estnum, values_from = est) %>%
  mutate(pctoo=est2 / est1,
         oopctprob=est3 / est2)

# determine places of interest
nyareas <- chasny %>%
  select(geoid, name, type) %>%
  distinct()

counties <- c("Albany", "Saratoga", "Warren", "Washington")
places <- c("Cambridge", "Greenwich", "Argyle", "Salem")
poi <- nyareas %>%
  filter(type=="state" |
           type=="county" & str_detect_any(name, counties) |
           type=="place" & str_detect_any(name, places))

tmp %>%
  filter(geoid %in% poi$geoid) %>%
  arrange(oopctprob)

# has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)

# df <- readRDS(paste0(chasdirs[3], "allfiles.rds"))
# dim(df)
# sumlevel
# 1 char
# 2 char, 15.9m recs
# 3 


```


```{r irs_data}
dmig <- r"()"
 zpath <- paste0(r"(E:\data\acs\sf\)", year, r"(_5year\ny\NewYork_All_Geographies_Not_Tracts_Block_Groups.zip)")
  print(zpath)
  files <- unzip(zpath, list=TRUE)
  read_files <- files %>%
    filter(str_sub(Name, 1, 2) %in% c("e2", "m2"))

```


# DATA ANALYSIS
```{r load_data}
uvacs <- readRDS(here::here("data", "uvacs.rds"))
acsdata <- readRDS(here::here("data", "acsdata.rds"))
popwash <- readRDS(here::here("data", "popproj_pad_washco.rds"))
popannold <- readRDS(file.path(dcenpop, "popann.rds"))
popann <- readRDS(file.path(dcenpop, "popann2020.rds"))
census2020 <- readRDS(file.path(dpl, "census2020plny.rds"))

# count(acsdata, tableid, concept)
names(census2020)
tmp <- census2020 %>%
  filter(stusab=="NY", 
         as.integer(sumlev) < 200, 
         !sumlev %in% c("140", "150"),
         !str_detect(name, "(part)")) %>%
  select(sumlev, geoid, geocode, county, basename, name, pop100, hu100)
count(tmp, sumlev)

tmp2 <- tmp %>%
  mutate(geoidold=geoid,
         usgeoname=name)
#         geoid=ifelse(sumlev %in% c("040", "050", "060"), paste0(sumlev, "00US", geocode), geoidold))


pop2020 <- subareas %>%
  left_join(tmp2 %>% select(-geoid), by="usgeoname") %>%
  select(geoid, sgeotype, usgeoname, basename, name, pop100, hu100)


tmp %>%
  filter(str_detect(name, "White Creek"))
tmp %>%
  filter(str_detect(name, "Cambridge town"))

subareas %>%
  filter(str_detect(usgeoname, "White Creek"))



```



# Population in and around the Village of Cambridge

```{r load_info}
#.. get all lookup information ----
# we want these data frames in the environment
geoall <- readRDS(paste0(dacssf, "geoall.rds"))
sumlevels <- readRDS(paste0(dacssf, "sumlevels.rds"))
tabseq <- readRDS(paste0(dacssf, "tabseq.rds"))
varsall <- readRDS(paste0(dacssf, "varsall.rds"))
tabdescribe <- readRDS(paste0(dacssf, "tabdescribe.rds"))

ds2009 <- paste0(dny2009, "em20095ny.parquet")
ds2014 <- paste0(dny2014, "em20145ny.parquet")
ds2019 <- paste0(dny2019, "em20195ny.parquet")
dspaths <- c(ds2009, ds2014, ds2019)

source(here::here("r", "functions_acssf.r"), verbose = TRUE)

```


```{r define_geos}
gpath <- r"(E:\data\acs\sf\boyd_acs_table_tools.xlsx)"
geodf <- read_excel(gpath, sheet="geos_keep", skip=1)
keepdf <- geodf %>% filter(keep==1)

geokeep <- geoall %>%
  filter(geoid %in% keepdf$geoid)
geokeep

subareas <- geokeep %>%
  mutate(statekeep=sgeotype=="state" & geoid %in% c("04000US36", "04043US36"),
         countykeep=sgeotype=="county" & 
           str_detect_any(usgeoname, c("Saratoga", "Warren", "Washington")),
         washcotown=sgeotype=="cosub" & str_sub(geoid, 8, 12)=="36115", # Washco towns
         droptown=washcotown & str_detect_any(usgeoname, c("Dresden", "Hampton", "Putnam")),
         townkeep=washcotown & !droptown,
         villagekeep=sgeotype=="place" & !str_detect_any(usgeoname, "Schuy")) %>%
  mutate(anykeep=statekeep | countykeep | townkeep | villagekeep) %>%
  filter(anykeep) %>%
  select(!contains("keep"))

```




```{r get_save_acs_tables}
tabdescribe
count(tabdescribe, subject)
tmp <- tabdescribe %>% filter(subject=="Age-Sex", year==2019)
count(tabdescribe %>% filter(table=="B01001"), year)

tabdescribe %>% 
  filter(table=="C24050", year==2019) %>%
  select(tabtitle)

# .. population -- get the fewest-variables table for total population ----
#.. B01003	Total population ----
tab_B01003 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B01003")
glimpse(tab_B01003)
saveRDS(tab_B01003, here::here("data", "tab_B01003.rds"))

#.. B01002	 		MEDIAN AGE BY SEX ----
# B01002	 		Universe:  Total population
# B01002	0.5		Median age --
# B01002	1	B01002_001	Total:
# B01002	2	B01002_002	Male
# B01002	3	B01002_003	Female
tab_B01002 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B01002")
tab_B01002
saveRDS(tab_B01002, here::here("data", "tab_B01002.rds"))

#.. B01001 Sex By Age ----
tab_B01001 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "B01001")
tab_B01001
saveRDS(tab_B01001, here::here("data", "tab_B01001.rds"))

#.. C24050 Industry By Occupation For The Civilian  Employed Population 16 Years And Over ----
tab_C24050 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "C24050")
tab_C24050
saveRDS(tab_C24050, here::here("data", "tab_C24050.rds"))
# tab_C24050 %>% filter(geoid=="16000US3611825", year==2019) %>% write_csv(here::here("data", "check.csv"))

#.. C24060 OCCUPATION BY CLASS OF WORKER FOR THE CIVILIAN EMPLOYED POPULATION 16 YEARS AND OVER ----
tab_C24060 <- map_dfr(c(2009, 2014, 2019), get_yeartab, "C24060")
tab_C24060
saveRDS(tab_C24060, here::here("data", "tab_C24060.rds"))

# C25004	 		VACANCY STATUS


```

```{r functions_census_acs_tables}
fcenpop_table <- function(tabdata, .title){
  fnote <- "NOTE: 2020 Decennial estimate for Greenwich village is considerably lower than previous Census Bureau annual estimates."
  tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(stabbr, sgeotype)) %>%
  tab_header(
    title = .title
      ) %>%
  cols_label(usgeoname="",
             pop2010="2010",
             pop2020="2020",
             change=html("change"),
             pch=html("% change")
             ) %>%
  # tab_spanner(
  #   label = html("Percent change"),
  #   columns = contains("pch")
  #   ) %>%
  cols_align(align="left", columns = usgeoname) %>%
  fmt_number(
    columns=c(pop2010, pop2020, change),
    decimals=0
  ) %>%
  fmt_percent(
    columns = pch,
    decimals = 1) %>%
  tab_source_note(paste0("Source: ", source_decennialpop, " (Redistricting file for 2020).")) %>%
  tab_footnote(
    footnote = fnote,
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      # cell_text(weight = "bold") # size = px(15), , font = "arial"
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ pct(50),
    everything() ~ pct(50)
    ) %>%
  tab_options(
    table.width = pct(100)
  )
  # cols_width(
  #   usgeoname ~ px(150),
  #   starts_with("y") ~ px(100),
  #   starts_with("pch") ~ px(100)
  # )
  # %>%   tab_options(row_group.as_column=TRUE)
  # cells_row_groups()
tab
}

tab <- fcenpop_table(tabdata, "Decennial census population in 2010 and 2020")
tab
# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_decennialpop.png", path=here::here("results"), zoom=1, expand=10)


fpch_table <- function(tabdata, .title, ydecimals=0){
  tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(table, geoid, sgeotype, tabvarname)) %>%
  tab_header(
    title = .title
      ) %>%
  cols_label(usgeoname="",
             y2009="2009",
             y2014="2014",
             y2019="2019",
             pch0914=html("2009<br>to 2014"),
             pch1419=html("2014<br>to 2019"),
             pch0919=html("2009<br>to 2019"),
             ) %>%
  tab_spanner(
    label = html("Percent change"),
    columns = contains("pch")
    ) %>%
  cols_align(align="left", columns = usgeoname) %>%
  fmt_number(
    columns=starts_with("y"),
    decimals=ydecimals
  ) %>%
  fmt_percent(
    columns = starts_with("pch"),
    decimals = 1) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      # cell_text(weight = "bold") # size = px(15), , font = "arial"
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ px(150),
    starts_with("y") ~ px(100),
    starts_with("pch") ~ px(100)
  )
  # %>%   tab_options(row_group.as_column=TRUE)
  # cells_row_groups()
tab
}


fch_table <- function(tabdata, .title, ychdecimals=1){
  tab <- tabdata %>%
  gt(groupname_col = "rowlab") %>%
  cols_hide(c(table, geoid, sgeotype, tabvarname)) %>%
  tab_header(
    title = .title
      ) %>%
  cols_label(usgeoname="",
             y2009="2009",
             y2014="2014",
             y2019="2019",
             ch0914=html("2009<br>to 2014"),
             ch1419=html("2014<br>to 2019"),
             ch0919=html("2009<br>to 2019"),
             ) %>%
  tab_spanner(
    label = html("Change"),
    columns = contains("ch")
    ) %>%
  cols_align(align="left", columns = usgeoname) %>%
  fmt_number(
    columns=c(starts_with("y"), starts_with("ch")),
    decimals=ychdecimals
  ) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    # locations = cells_column_labels(columns = starts_with("est"))
    locations = cells_title(groups="title")
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_row_groups()
    ) %>%
  tab_style(
    style = list(
      # cell_text(weight = "bold") # size = px(15), , font = "arial"
      cell_fill(color = "lightcyan")
      ),
    locations = cells_body(
      rows=str_detect(usgeoname, "Cambridge")
      )
    ) %>%
  cols_width(
    usgeoname ~ px(250),
    starts_with("y") ~ px(150),
    starts_with("ch") ~ px(150)
  )
  # %>%   tab_options(row_group.as_column=TRUE)
  # cells_row_groups()
tab
}

```


## Population size

```{r pop_decennial}
# count(popann %>% filter(state=="36"), sgeotype)

# popann %>% filter(state=="36", year==2020, str_detect(geoname, "Salem"))
# popannold %>% filter(state=="36", year==2020, str_detect(geoname, "Salem"))

census2010pop <- popann %>%
  filter(state=="36", 
         !is.na(sgeotype), 
         name=="popcensus2010",
         !str_detect(geoname, "(pt.)"),
         !str_detect(geoname, "Balance")) %>%
  filter(sgeotype=="state" | 
           sgeotype=="county" & str_detect_any(geoname, c("Saratoga", "Warren", "Washington")) |
           sgeotype=="cosub" & county=="115" |
           sgeotype=="place") %>%
  select(sgeotype, usgeoname=geoname, pop2010=value) %>%
  inner_join(subareas %>%
               filter(year==2019) %>%
               select(stabbr, geoid, sgeotype, usgeoname),
              by = c("sgeotype", "usgeoname"))

census2020pop <- subareas %>%
  filter(year==2019) %>%
  mutate(geocode=str_sub(geoid, 8, -1)) %>%
  select(stabbr, geoid, geocode, sgeotype, usgeoname) %>%
  left_join(census2020 %>%
              select(usgeoname=name, geocode, pop2020=pop100),
            by=c("usgeoname", "geocode"))

tabdata <- census2010pop %>%
  left_join(census2020pop %>%
              select(geoid, usgeoname, pop2020),
            by=c("geoid", "usgeoname")) %>%
  select(stabbr, sgeotype, usgeoname, pop2010, pop2020) %>%
  mutate(change=pop2020 - pop2010, 
         pch=change / pop2010,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata
  
tab <- fcenpop_table(tabdata, "Decennial census population in 2010 and 2020")
tab
# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_decennialpop.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_decennialpop_data.csv"))

```



```{r popann_census}
# prep popann data
glimpse(subareas)
count(subareas, year)
tmp <- count(popann %>% filter(state=="36"), geoname)
popann %>% filter(state=="36", str_detect(geoname, "Washington Cou"))
glimpse(popann)

pophist <- subareas %>%
  filter(year==2019) %>%
  select(stabbr, geoid, sgeotype, usgeoname) %>%
  inner_join(popann %>%
               filter(state=="36", !is.na(sgeotype)) %>%
               select(sgeotype, geoid, popgeoname=geoname, year, esttype, value), by = c("geoid", "sgeotype"))

count(pophist, usgeoname)

base <- 2010
pdata <- pophist %>%
  # filter(str_detect_any(usgeoname, c("Cambridge village", "Greenwich village"))) %>%
  filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
  filter(!str_detect(usgeoname, "Greenwich town")) %>%
  filter(esttype=="est") %>%
  mutate(year=as.integer(year)) %>%
  filter(year >= base) %>%
  group_by(geoid, usgeoname) %>%
  mutate(ivalue=value / value[year==base],
         cumpch=ivalue - 1) %>%
  ungroup

capt1 <- "Note: White Creek probably will look better in 2020 when Census updates annual estimates."
capt2 <- paste0("Source: ", source_cenpop, ", 2020 vintage.")
capt <- paste0(capt1, "\n", capt2)
p <- pdata %>%
  ggplot(aes(year, cumpch, colour=usgeoname)) +
  geom_line(size=1) +
  geom_point(size=1.5) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(name=NULL, breaks=seq(2010, 2020, 1)) +
  scale_y_continuous(name=paste0("% change since ", base), 
                     breaks=seq(-1, 1, .005), 
                     labels=label_percent(accuracy=.1),
                     limits=c(NA, NA)) +
  scale_colour_discrete(name="age group") +
  ggtitle(label="Cambridge and selected other areas",
          subtitle = "Cumulative % change in population since 2010") +
  labs(caption = capt) +
  theme_bw() +
  caption_left
p

ggsave(here::here("results", "fig_annpop.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_annpop_data.csv"))

# https://www.census.gov/content/dam/Census/programs-surveys/acs/guidance/training-presentations/20180418_MOE.pdf
# At a given confidence level, the estimate and the actual population value
# will differ by no more than the value of the MOE; 90% confidence level is the
# Census Bureau Standard (Margin of Error MOE = 1.645 x SE)

# quick check vs Census
pophist %>%
  filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
  filter(!str_detect(usgeoname, "Greenwich town"), year %in% c(2010, 2020), esttype %in% c("est", "census")) %>%
  filter(!is.na(popgeoname)) %>%
  select(-stabbr, -popgeoname) %>%
  pivot_wider(names_from = esttype) %>%
  mutate(diff=est - census,
         pdiff=diff / census)


pophist %>%
  filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
  filter(!str_detect(usgeoname, "Greenwich town"), year %in% c(2010, 2020), esttype %in% c("est", "census")) %>%
  filter(!is.na(popgeoname)) %>%
  select(-stabbr, -popgeoname) %>%
  pivot_wider(names_from = esttype) %>%
  mutate(diff=est - census,
         pdiff=diff / census)


popcheck <- pophist %>%
  filter(str_detect_any(usgeoname, c("Cambridge", "Greenwich", "White Creek", "Washington County"))) %>%
  filter(!str_detect(usgeoname, "Greenwich town"), year %in% c(2010, 2020), esttype %in% c("est", "census")) %>%
  mutate(esttype=ifelse(year==2020 & esttype=="census", "censusest", esttype)) %>%
  filter(!is.na(popgeoname)) %>%
  select(-stabbr, -popgeoname) %>%
  pivot_wider(names_from=c(esttype, year)) %>%
  left_join(pop2020 %>%
              select(sgeotype, usgeoname, census_2020=pop100) %>%
              filter(!is.na(census_2020)) %>%
              distinct(),
            by = c("sgeotype", "usgeoname"))

# %>%
  # pivot_longer(-c(geoid, sgeotype, usgeoname)) %>%
  # separate(name, c("esttype", "year")) %>% 
  # pivot_wider(names_from = year, names_prefix = "y")
popcheck %>%
  mutate(ee=est_2020 / est_2010 - 1,
         cc=census_2020 / census_2010 - 1,
         cce=censusest_2020 / census_2020 -1) %>%
  select(-c(geoid, sgeotype)) %>%
  gt() %>%
  fmt_percent(
    columns = c(ee, cc, cce),
    decimals = 1)


```



```{r }
tab_B01003 <- readRDS(here::here("data", "tab_B01003.rds"))
count(tab_B01003, tabvarname, vdescription)

tabdata <- tab_B01003 %>%
  filter(geoid %in% subareas$geoid, valtype=="est") %>%
  select(year, table, tabvarname, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(pch0914=y2014 / y2009 - 1,
         pch1419=y2019 / y2014 - 1,
         pch0919=y2019 / y2009 - 1,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fpch_table(tabdata, .title="Population in selected areas", ydecimals=0)
gtsave(tab, filename="tab_poptot.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_poptot_data.csv"))

```


## Age

### Median age
```{r median_age_raw}
# tab <- "B01002"
tab_B01002 <- readRDS(here::here("data", "tab_B01002.rds"))
count(tab_B01002, tabvarname, vdescription)

tabdata <- tab_B01002 %>%
  filter(geoid %in% subareas$geoid, valtype=="est", tabvarname=="B01002_001") %>%
  select(year, table, tabvarname, sgeotype, geoid, usgeoname, value) %>%
  pivot_wider(names_from = year, names_prefix = "y") %>%
  mutate(ch0914=y2014 - y2009,
         ch1419=y2019 - y2014,
         ch0919=y2019 - y2009,
         rowlab=get_rowlab(sgeotype)) %>%
  arrange(rowlab, usgeoname)
tabdata

# webshot options
# default zoom=2, expand=5
tab <- fch_table(tabdata, .title="Median age in selected areas", ychdecimals=1)
tab
gtsave(tab, filename="tab_mdnage.png", path=here::here("results"), zoom=1, expand=10)
write_csv(tabdata, file=here::here("results", "tab_mdnage_data.csv"))

```


```{r OLD_median_age_bars}
# capt1 <- paste0("Note: Costs above 30 percent are generally often defined as burdensome. Smaller geographic areas generally have a larger margin of error.")
capt <- paste0("Source: ", source_acs, ".")
# capt <- paste0(capt1, "\n", capt2)

p <- pdata %>%
  ggplot(aes(x=reorder(sname, order), y=estimate, fill=as.factor(year))) +
  geom_col(position=position_dodge()) +
  # scale_fill_brewer(palette = "Paired") +
  scale_fill_manual(values=c('#e0f3db','#a8ddb5','#43a2ca')) +
  theme_bw() +
  labs(x=NULL,
       y=NULL,
       caption=capt) +
  ggtitle(label=str_to_sentence("Median age, selected areas"),
          subtitle = NULL) +
  # theme(axis.text.y = element_text(hjust = 0)) +
  # scale_x_continuous(breaks=seq(0, 100, 1), labels=label_comma(accuracy=.1), limits=xlims) +
  legend_notitle +
  caption_left
p

# p + scale_y_break(c(0, 30))

ggsave(here::here("results", "fig_median_age_bars.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_median_age_bars_data.csv"))

```

### Age breakdown
```{r}
glimpse(tab_B01001)

varsall %>%
  filter(table=="B01001", year==2019) %>%
  arrange(vnum) %>%
  select(year, table, vnum, vname, vdescription)
# vnum: total is 1, 25 to 34 
# 2, 26 total male, female
# 11, 12 25-34 male
# 35, 36 25-34 female

td1 <- tab_B01001 %>%
  filter(vnum %in% c(2, 6, 11:12, 35:36),
         valtype=="est") %>%
  mutate(group=case_when(vnum %in% c(2, 26) ~ "total",
                         TRUE ~ "age2534")) %>%
  group_by(year, group) %>%
  summarise(value=sum(value), .groups="drop")

tabvars <- tab_B01001 %>%
  filter(year==2019)
  group_by(tabvarname)
tabvars <- count(tab_B01001, tabvarname, vdescription) %>%
  separate(vdescription, into=paste0("v", 1:8), sep="%", remove = FALSE)

```





```{r fig_pop_pyramid_areas}
geokeeps <- c(newyork_state, washington_county, cambridge_village, greenwich_village)
# geokeeps <- c(newyork_state, washington_county, cambridge_village, greenwich_village,
#               cambridge_town, greenwich_town)

# vnum values for age groups - vnums for female low, high, then male
# agegroups <- read_csv(
# "agegroup, agelabel, flow, fhigh, mlow, mhigh
# 0, total, 26, 26, 2, 2
# 1, <= 17, 27, 30, 3, 6
# 2, 18 to <= 24, 31, 34, 7, 10
# 3, 25 to <= 34, 35, 36, 11, 12
# 4, 35 to <= 64, 37, 43, 13, 19
# 5, 65 to <= 84, 44, 48, 20, 24
# 6, >=85, 49, 49, 25, 25")


# finer groups
agegroups <- read_csv(
"agegroup, agelabel, flow, fhigh, mlow, mhigh
0, total, 26, 26, 2, 2
1, <= 17, 27, 30, 3, 6
2, 18 to <= 24, 31, 34, 7, 10
3, 25 to <= 34, 35, 36, 11, 12
4, 35 to <= 44, 37, 38, 13, 14
5, 45 to <= 64, 39, 43, 15, 19
5, 65 to <= 84, 44, 48, 20, 24
6, >=85, 49, 49, 25, 25")


vals <- function(low, high) {
  tibble(vnum=str_pad(low:high, width = 3, side = "left", pad = "0"))
}

agegroups_long <- agegroups %>%
  pivot_longer(-c(agegroup, agelabel)) %>%
  mutate(sex=str_sub(name, 1, 1),
         type=str_sub(name, 2, -1)) %>%
  select(-name) %>%
  pivot_wider(names_from = type) %>%
  mutate(sex=factor(sex, levels=c("m", "f"), labels=c("male", "female"))) %>%
  group_by(agegroup, agelabel, sex) %>%
  summarise(vals(low, high), .groups="drop")

acsdata %>%
  filter(tableid=="B01001") %>%
  count(ulab4, ulab3, vnum) 

basedata <- acsdata %>%
  filter(tableid=="B01001",
         geoid %in% geokeeps) %>%
  select(geotype, geoid, sname, variable, year, estimate, moe, concept, 
         vnum, ulab3, ulab4, ulabel) %>%
  left_join(agegroups_long, by="vnum") %>%
  filter(!is.na(sex)) %>%
  group_by(geotype, geoid, sname, sex, agegroup, agelabel, year) %>%
  summarise(estimate=sum(estimate), .groups="drop") %>%
  # now get pct share of area total population
  group_by(geotype, geoid, sname, year) %>%
  mutate(share=estimate / estimate[agegroup==0]) %>%
  ungroup

basedata %>%
  filter(geoid==cambridge_village, year==2019)

pdata <- basedata %>%
  filter(year==2019, agegroup!=0) %>%  # geoid %in% c(cambridge_village, greenwich_village), 
  mutate(geoid=factor(geoid, levels=geokeeps),
         order=as.integer(geoid),
         sname=fct_reorder(sname, order, min),
         pshare=ifelse(sex=="male", -share, share)) %>% # order we want
  arrange(sname, year)

clrs_br <- c("blue", "red")
clrs <- c('#ef8a62', '#67a9cf') %>% rev()
brks <- seq(-1, 1, .1)
brk_labs <- percent(abs(brks), accuracy=.1)
p <- pdata %>%
  ggplot(aes(x=pshare,
             y=reorder(agelabel, agegroup),
             fill = sex)) + 
  geom_bar(stat = "identity") +
  scale_x_continuous(name="% of the area's total population", breaks=brks,
                     labels = percent(abs(brks), accuracy=.1)) +
  scale_y_discrete(name=NULL) +
  scale_fill_manual(values=clrs) +
  theme_bw() +
  legend_notitle +
  ggtitle("Population share by age group") +
  facet_wrap(~ sname, ncol = 2)
  # theme(axis.text.x = element_text(angle = 90, hjust = 1))

p

ggsave(here::here("results", "fig_pop_pyramid_areas.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_pop_pyramid_areas_data.csv"))

```


```{r fig_pop_pyramid_years}
#.. moes are too large to trust any of this! ----
# finer groups
agegroups <- read_csv(
"agegroup, agelabel, flow, fhigh, mlow, mhigh
0, total, 26, 26, 2, 2
1, <= 17, 27, 30, 3, 6
2, 18 to <= 24, 31, 34, 7, 10
3, 25 to <= 34, 35, 36, 11, 12
4, 35 to <= 44, 37, 38, 13, 14
5, 45 to <= 64, 39, 43, 15, 19
5, 65 to <= 84, 44, 48, 20, 24
6, >=85, 49, 49, 25, 25")


vals <- function(low, high) {
  tibble(vnum=str_pad(low:high, width = 3, side = "left", pad = "0"))
}

agegroups_long <- agegroups %>%
  pivot_longer(-c(agegroup, agelabel)) %>%
  mutate(sex=str_sub(name, 1, 1),
         type=str_sub(name, 2, -1)) %>%
  select(-name) %>%
  pivot_wider(names_from = type) %>%
  mutate(sex=factor(sex, levels=c("m", "f"), labels=c("male", "female"))) %>%
  group_by(agegroup, agelabel, sex) %>%
  summarise(vals(low, high), .groups="drop")

acsdata %>%
  filter(tableid=="B01001") %>%
  count(ulab4, ulab3, vnum) 

acsdata %>%
  filter(tableid=="B01001", geoid==cambridge_village, year==2019)
  
tmp <- acsdata %>%
  filter(tableid=="B01001",
         geoid ==cambridge_village) %>%
  select(geotype, geoid, sname, variable, year, estimate, moe, concept, 
         vnum, ulab3, ulab4, ulabel) %>%
  left_join(agegroups_long, by="vnum") %>%
  filter(!is.na(sex)) %>%
  group_by(geotype, geoid, sname, sex, agegroup, agelabel, year) 

tmp %>% filter(year==2019) %>%
  select(geotype, sname, year, vnum, sex, agegroup, agelabel, estimate, moe) %>%
  mutate(moepct=moe / estimate)
  

basedata <- acsdata %>%
  filter(tableid=="B01001",
         geoid ==cambridge_village) %>%
  select(geotype, geoid, sname, variable, year, estimate, moe, concept, 
         vnum, ulab3, ulab4, ulabel) %>%
  left_join(agegroups_long, by="vnum") %>%
  filter(!is.na(sex)) %>%
  group_by(geotype, geoid, sname, sex, agegroup, agelabel, year) %>%
  summarise(estimate=sum(estimate), .groups="drop") %>%
  # now get pct share of area total population
  group_by(geotype, geoid, sname, year) %>%
  mutate(share=estimate / estimate[agegroup==0]) %>%
  ungroup

basedata %>%
  filter(geoid==cambridge_village, year==2019)

pdata <- basedata %>%
  filter(agegroup!=0) %>%  # geoid %in% c(cambridge_village, greenwich_village), 
  mutate(geoid=factor(geoid, levels=geokeeps),
         order=as.integer(geoid),
         sname=fct_reorder(sname, order, min),
         pshare=ifelse(sex=="male", -share, share)) %>% # order we want
  arrange(sname, year)

clrs_br <- c("blue", "red")
clrs <- c('#ef8a62', '#67a9cf') %>% rev()
brks <- seq(-1, 1, .1)
brk_labs <- percent(abs(brks), accuracy=.1)
p <- pdata %>%
  ggplot(aes(x=pshare,
             y=reorder(agelabel, agegroup),
             fill = sex)) + 
  geom_bar(stat = "identity") +
  scale_x_continuous(name="% of the area's total population", breaks=brks,
                     labels = percent(abs(brks), accuracy=.1)) +
  scale_y_discrete(name=NULL) +
  scale_fill_manual(values=clrs) +
  theme_bw() +
  legend_notitle +
  ggtitle("Population share by age group") +
  facet_wrap(~ year, ncol = 1)
  # theme(axis.text.x = element_text(angle = 90, hjust = 1))

p

ggsave(here::here("results", "fig_pop_pyramid_years.png"), plot=p, width=8, height=10, scale=1)
write_csv(pdata, here::here("results", "fig_pop_pyramid_years_data.csv"))

```

```{r fig_washco_popproj}
glimpse(popwash)
count(popwash, agecode, agegrp) %>% ht

pdata1 <- popwash %>%
  filter(sex=="all") %>%
  mutate(agegrp2=case_when(agecode == -999 ~ "total",
                           agecode %in% 0:17 ~ "agele17",
                           agecode %in% 18:24 ~ "age1824",
                           agecode %in% 25:34 ~ "age2534",
                           agecode %in% 35:44 ~ "age3544",
                           agecode %in% 45:64 ~ "age4564",
                           agecode %in% 65:84 ~ "age6584",
                           agecode == 85 ~ "age85p",
                           agecode == 999 ~ "median")) %>%
  group_by(year, agegrp=agegrp2) %>%
  summarise(n=n(), value=sum(value), .groups="drop")

pdata1
pdata1 %>% filter(agegrp=="median") %>% ggplot(aes(year, value)) + geom_line() + geom_point()

pdata1 %>%
  filter(str_detect(agegrp, "age")) %>%
  ggplot(aes(year, value, colour=agegrp)) +
  geom_line() +
  geom_point()

capt1 <- "Note: vertical axis does not start at zero."
capt2 <- paste0("Source: ", source_padcoproj, ".")
capt <- paste0(capt1, "\n", capt2)
pdata <- pdata1 %>%
  filter(str_detect(agegrp, "age")) %>%
  mutate(agegrp = case_when(agegrp %in% c("agele17", "age1824") ~ "agele24",
                            agegrp %in% c("age2534", "age3544") ~ "age2544",
                            agegrp %in% c("age6584", "age85p") ~ "age65p",
                            TRUE ~ agegrp)) %>%
  group_by(year, agegrp) %>%
  summarise(value=sum(value), .groups="drop")

p <- pdata %>%
  mutate(agegrp=factor(agegrp, 
                       levels=c("agele24", "age2544", "age4564", "age65p"),
                       labels=c("<= 24", "25-44", "45-64", "65+"))) %>%
  # arrange(year, agegrp) %>%
  ggplot(aes(year, value, colour=agegrp)) +
  geom_line(size=1) +
  geom_point(size=1) +
  scale_x_continuous(name=NULL) +
  scale_y_continuous(name="# of people", 
                     breaks=seq(0, 60e3, 2e3), 
                     labels=label_comma(accuracy=1),
                     limits=c(NA, NA)) +
  scale_colour_discrete(name="age group") +
  ggtitle("Cornell population projections for Washington County") +
  labs(caption = capt) +
  theme_bw() +
  caption_left
p

ggsave(here::here("results", "fig_washco_popproj.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_washco_popproj_data.csv"))

```


## Educational attainment

## Geographic mobility

## Population growth





# Housing in and around the Village of Cambridge

## Property tax data
```{r}
# https://data.ny.gov/Government-Finance/Parcel-Counts-By-Type-By-Municipality-Beginning-Ro/tnwc-mx3q
# levies
# https://data.ny.gov/Government-Finance/Real-Property-Tax-Rates-Levy-Data-By-Municipality-/iq85-sdzs
# http://data.ny.gov/d/e6pv-77bh
# rars http://data.ny.gov/d/bsmp-6um6


# other
# NYSERDA
# https://data.ny.gov/Energy-Environment/RSBS-MOM-Part-2-of-2-New-York-State-Residential-St/hc4z-b2p5

# search
# https://data.ny.gov/Government-Finance/Local-Data-Index/vgx8-sf6x

parcels1 <- read_csv("https://data.ny.gov/api/views/tnwc-mx3q/rows.csv?accessType=DOWNLOAD&sorting=true")
glimpse(parcels1)
vnames <- c("rollyear", "swis", "muniname", "county",
            "agricultural_100", "residential_200", "vacant_300", "commercial_400",
            "recreation_500", "communityservice_600", "industrial_700",
            "publicservice_800", "forest_900", "total")
parcels2 <- parcels1 %>%
  setNames(vnames) %>%
  pivot_longer(-c(rollyear, swis, muniname, county)) %>%
  separate(name, c("type", "code"), remove=FALSE) %>%
  mutate(code=as.integer(code))

parcels2 %>%
  filter(rollyear==2020, str_detect(muniname, coll("Cambridge", ignore_case=TRUE)))

parcels2 %>%
  filter(str_detect(muniname, coll("Cambridge", ignore_case=TRUE))) %>%
  filter(code %in% c(100, 200, 300, 400)) %>%
  ggplot(aes(rollyear, value, colour=type)) +
  geom_line() +
  geom_point()



```


## TO DO

```{r gt_example}
gt() %>%
  cols_hide(stabbr) %>%
  tab_header(
    title = "State correctional officer wages, selected years"
      ) %>%
  cols_label(stname="",
             wage_2012="2012",
             wage_2016="2016",
             wage_2020="2020",
             pdiff_2012="2012",
             pdiff_2016="2016",
             pdiff_2020="2020") %>%
  cols_align(align="left", columns = stname) %>%
  tab_spanner(
    label = html("Average wage"),
    columns = contains("wage")
    ) %>%
  tab_spanner(
    label = "California wage % above other area",
    columns = contains("pdiff")
    )  %>%
  fmt_number(
    columns=c(contains("wage")),
    pattern = "${x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pdiff"),
    decimals = 1) %>%
  fmt_missing(columns=everything(), missing_text="") %>%
  fmt_missing(contains("pdiff"), rows=2) %>%
  tab_source_note(paste0("Sources: ", source_oesres, ".")) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_body(
      rows = c(1, 4, 7)
    )
  ) %>%
  cols_width(
    stname ~ px(200),
    everything() ~ px(100)
    )

tab
gtsave(tab, filename="tab_wages_states_oes.png", path=here::here("results"))
```


```{r define_poi}
# places of interest
# ONETIME
# dhtabs <- r"(E:\data\acs\hud_chas\tables\)"
# poi1 <- readRDS(paste0(dhtabs, "table1.rds")) %>%
#   filter(st=="36")
#   
# poi2 <- poi1 %>%
#   select(geoid, geoname, type) %>%
#   distinct()
# saveRDS(poi2, here::here("data", "hud_nyareas.rds"))
# count(poi2, type)

nyareas <- readRDS(here::here("data", "hud_nyareas.rds"))

counties <- c("Albany", "Saratoga", "Warren", "Washington")
places <- c("Cambridge", "Greenwich", "Argyle", "Salem", "White Creek")
nypoi <- nyareas %>%
  filter(type=="state" |
           type=="county" & str_detect_any(geoname, counties) |
           type=="place" & str_detect_any(geoname, places) |
           type=="mcd" & 
           str_detect(geoname, "Washington County") & 
           str_detect_any(geoname, places))
nypoi

```


```{r hudny_prep}
dhtabs <- r"(E:\data\acs\hud_chas\tables\)"
  
# df2 <- df %>%
  #   separate(vname, into=c("table", "est")) %>%
  #   mutate(etype=str_sub(est, 1, 3),
  #          estnum=str_sub(est, 4, nchar(est)) %>% as.integer()) %>%
  #   pivot_wider(names_from = etype)

df1 <- readRDS(paste0(dhtabs, "table1.rds"))
glimpse(df1)

df14a <- readRDS(paste0(dhtabs, "table14a.rds"))
glimpse(df14a)

df14b <- readRDS(paste0(dhtabs, "table14b.rds"))
glimpse(df14b)

nyhud1 <- bind_rows(df1 %>% filter(st=="36"),
                   df14a %>% filter(st=="36"),
                   df14b %>% filter(st=="36")) %>%
  select(-st)


nyhud2 <- nyhud1 %>%
  filter(geoid %in% nypoi$geoid) %>%
  separate(vname, c("table", "estmoe")) %>%
  mutate(vtype=str_sub(estmoe, 1, 3),
         vnum=str_sub(estmoe, 4, nchar(estmoe)) %>% as.integer)
glimpse(nyhud2)
summary(nyhud2)
count(nyhud2, table)


# .. key variables ----
# T14A_est1	Total	Total: Vacant-for-sale housing units	All
# T14A_est2	Detail	Vacant-for-sale	housing unit lacks complete kitchen or plumbing facilities
# T14B_est1	Total	Total: Vacant-for-rent housing units	All
# T14B_est2	Detail	Vacant-for-rent	housing unit lacks complete kitchen or plumbing facilities

# T1_est1	 Total	Total: Occupied housing units

# owner occupied
# T1_est2	 .	Owner occupied
# T1_est3	 .. has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)
# T1_est4  ... less than or equal to 30% of HAMFI
# T1_est11 ... greater than 30% but less than or equal to 50% of HAMFI
# T1_est18 ... greater than 50% but less than or equal to 80% of HAMFI
# T1_est25 ... greater than 80% but less than or equal to 100% of HAMFI

# T1_est75 .  Renter occupied
# T1_est76 .. has 1 or more of the 4 housing unit problems (lacks kitchen or plumbing, more than 1 person per room, or cost burden greater than 30%)
# T1_est77 ... less than or equal to 30% of HAMFI
# T1_est84 ... greater than 30% but less than or equal to 50% of HAMFI
# T1_est91 ... greater than 50% but less than or equal to 80% of HAMFI
# T1_est98 ... greater than 80% but less than or equal to 100% of HAMFI
# T1_est105 ... greater than 100% of HAMFI

t1enums <- c(1:4, 11, 18, 25, 75:77, 84, 91, 98, 105)

nyhud3 <- nyhud2 %>%
  filter((table=="T1" & vnum %in% t1enums) |
           (table %in% c("T14A", "T14B") & vnum %in% 1:2))
count(nyhud3, table, vnum)

# check on moe
nyhud4 <- nyhud3 %>%
  select(-estmoe) %>%
  pivot_wider(names_from = vtype) %>%
  mutate(moepct=moe / est)

```


```{r stock}
tabdata <- nyhud4 %>%
  filter(vnum==1) %>%
  select(type, geoname, table, est) %>%
  mutate(table=factor(table,
                    levels=c("T1", "T14A", "T14B"),
                    labels=c("occ", "vfs", "vfr"))) %>%
  pivot_wider(names_from = table, values_from = est) %>%
  mutate(vacant=vfs + vfr,
         avail=occ + vacant,
         vacpct=vacant / avail,
         geoname=ifelse(type=="state", paste0(geoname, " State"), geoname),
         geoname=str_extract(geoname, '^[^,]+')
         ) %>%
  select(type, geoname, avail, occ, vacant, vacpct)

tab <- tabdata %>%
  #  select(-type) %>%
  group_by(type) %>%
  gt() %>%
  tab_header(
    title = "Occupied or vacant & available housing"
      ) %>%
  cols_label(type="",
             geoname="",
             avail="Total # units",
             occ="# occupied",
             vacant="# vacant & available",
             vacpct="vacant as % of total") %>%
  cols_align(align="left", columns = geoname) %>%
  fmt_number(
    columns=c(avail, occ,  vacant),
    decimals=0
  ) %>%
  fmt_percent(
    columns = vacpct,
    decimals = 1) %>%
  tab_source_note(paste0("Source: ", source_hud, ".")) %>%
  tab_footnote(
    footnote = "CAUTION: small areas have high margins of error.",
    locations = cells_column_labels(columns = c(vacant, vacpct))
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_body(
      rows=str_detect(geoname, "Cambridge")
      )
  ) 

gtsave(tab, filename="tab_stock_hud.png", path=here::here("results"))
write_csv(tabdata, file=here::here("results", "tab_stock_hud_data.csv"))

```


```{r tenure}

# tenure
tabdata <- hudnuy_base %>%
  filter(estnum %in% c(1, 2, 75)) %>%
  select(-moe) %>%
  mutate(estnum=factor(estnum,
                       levels=c(1, 2, 75),
                       c("total", "own", "rent"))) %>%
  pivot_wider(names_from = estnum, values_from = c(est, moepct)) %>%
  mutate(est_ownpct=est_own / est_total) %>%
  select(type, geoid, geoname, est_total, est_own, est_rent, est_ownpct, everything())

tab <- tabdata %>%
  select(geoname, starts_with("est")) %>%
  gt() %>%
  tab_header(
    title = "Housing tenure in our area"
      ) %>%
  cols_label(geoname="",
             est_total="Total # units",
             est_own="# owner occupied"
             est_rent="# renter occupied"
             wage_2016="2016",
             wage_2020="2020",
             pdiff_2012="2012",
             pdiff_2016="2016",
             pdiff_2020="2020") %>%
  cols_align(align="left", columns = stname) %>%
  tab_spanner(
    label = html("Average wage"),
    columns = contains("wage")
    ) %>%
  tab_spanner(
    label = "California wage % above other area",
    columns = contains("pdiff")
    )  %>%
  fmt_number(
    columns=c(contains("wage")),
    pattern = "${x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pdiff"),
    decimals = 1) 
  
```



## Housing affordability
```{r plot_median_rent_income}
excludes <- c("Argyle", "Fort", "Dresden", "Hampton", "Hebron", "Whitehall", "Putnam", "Granville", "Kingsb", "Hartf")

pdata <- acsdata %>%
  filter(tableid=="B25071", year==2019, !str_detect_any(sname, excludes)) %>%
  mutate(cambvillage=geoid==cambridge_village)

capt1 <- paste0("Note: Costs above 30 percent are generally often defined as burdensome. Smaller geographic areas generally have a larger margin of error.")
capt2 <- paste0("Source: ", source_acs, ", 2015-2019.")
capt <- paste0(capt1, "\n", capt2)
# xlab <- "% of household income\n<--- more affordable : less affordable --->"
xlab <- "% of household income"

xlims <- c(22.25, 31.5)
p <- pdata %>%
  ggplot(aes(x=estimate, y=reorder(sname, estimate))) +
  # geom_errorbar(aes(xmin=pmax(estimate - moe, xlims[1]),
  #                   xmax=pmin(estimate + moe, xlims[2])),
  #               width=.05, colour="grey") +
  geom_point(aes(colour=cambvillage), size=3) +
  scale_colour_manual(values=c("blue", "red")) +
  # geom_col(fill="blue", size=2.5, width=0.3) +
  geom_vline(xintercept = 30, linetype="solid", colour="darkgrey", size=.5) +
  theme_bw() +
  labs(x=xlab,
       y=NULL,
       caption=capt) +
  ggtitle(label=str_to_sentence("MEDIAN GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME, 2015-2019 average"),
          subtitle = NULL) +
  # theme(axis.text.y = element_text(hjust = 0)) +
  scale_x_continuous(breaks=seq(0, 100, 1), labels=label_comma(accuracy=.1), limits=xlims) +
  legend_none +
  caption_left
p

ggsave(here::here("results", "fig_rent_affordability_2019.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "fig_rent_affordability_2019_data.csv"))

```


# Older

```{r census_geo}
gdir <- r"(E:\data\acs\sf\2019_5year\)"
fn <- "5_year_Mini_Geo.xlsx"

rgeo1 <- read_excel(paste0(gdir, fn), sheet="ny")

rgeo2 <- rgeo1 %>%
  setNames(c("stabbr", "logrecno", "geoid", "geoname")) %>%
  mutate(geoleft=str_sub(geoid, 1, 5),
         geomid=str_sub(geoid, 6, 7),
         georight=str_sub(geoid, 8, nchar(geoid)))
count(rgeo2, geoleft) %>% ht
count(rgeo2, geomid) %>% ht
count(rgeo2, georight) %>% ht

rgeo3 <- rgeo2 %>%
  select(stabbr, logrecno, geoid, geoname, geotype=geoleft, geonums=georight)

# which are the uniques?
rgeo3 %>%
  group_by(geotype) %>%
  mutate(n=n()) %>%
  ungroup %>%
  filter(n==1)

# geonums that start with something other than 36 are...
rgeoxpart <- rgeo3 %>%
  filter(!str_detect(geoname, "part"),
         !str_detect(geoname, "Remainder"))
count(rgeoxpart, geotype)

tmp <- rgeo3 %>%
  group_by(geotype) %>%
  mutate(n=n()) %>%
  ungroup %>%
  arrange(geotype, geoid)

# logrecno geoid     geoname                                                               geoty
# <chr>    <chr>     <chr>                                                                 <chr>
# 0000001  04000US36 New York                                                              04000
# 0000002  04001US36 New York -- Urban                                                     04001
# 0000003  04043US36 New York -- Rural                                                     04043
# 0000004  040A0US36 New York -- In metropolitan or micropolitan statistical area          040A0
# 0000005  040C0US36 New York -- In metropolitan statistical area                          040C0
# 0000006  040C1US36 New York -- In metropolitan statistical area -- in principal city     040C1
# 0000007  040C2US36 New York -- In metropolitan statistical area -- not in principal city 040C2
# 0000008  040E0US36 New York -- In micropolitan statistical area                          040E0
# 0000009  040E1US36 New York -- In micropolitan statistical area -- in principal city     040E1
# 0000010  040E2US36 New York -- In micropolitan statistical area -- not in principal city 040E2
# 0000011  040G0US36 New York -- Not in metropolitan or micropolitan statistical area      040G0
# 0000012  040H0US36 New York -- Not in metropolitan statistical area                      040H0

# we'll want geotypes
# 04000, 04001, 04043
# 05000 counties (5 nyc)
# 06000 cities, towns, villages, CDPs


rgcounty <- rgeo3 %>%
  filter(geotype=="05000")


gdf <- read_csv(paste0(gdir, "ny/", "g20195ny.csv"),
                col_names = FALSE)


```

```{r census_txt}
dir <- r"(E:\data\acs\sf\2019_5year\ny\)"
fn <- "e20195ny.txt"

# FILEID File Identification 6 Characters
# FILETYPE File Type 6 Characters
# STUSAB State/U.S.-Abbreviation (USPS) 2 Characters
# CHARITER Character Iteration 3 Characters
# SEQUENCE Sequence Number 4 Characters
# LOGRECNO Logical Record Number 7 Characters
idvars <- c("fileid", "filetype", "stusab", "chariter", "sequence", "logrecno")

rdf <- vroom(paste0(dir, fn), col_names=FALSE, 
             col_types = cols("c", "c", "c", "c", "c", "c",
                              .default= col_double()))
# rdf <- read_csv(paste0(dir, fn))
glimpse(rdf[, 1:7])
names(rdf)

# xvars <- paste0("x", 1:(ncol(rdf) - length(idvars)))
# vnames <- c(idvars, xvars)
names(rdf)[1:length(idvars)] <- idvars
glimpse(rdf)
names(rdf) <- str_to_lower(names(rdf))

saveRDS(rdf, paste0(dir, "e20195ny.rds"))

rdf <- readRDS(paste0(dir, "e20195ny.rds"))
glimpse(rdf[, 1:10])

tmp <- rdf %>%
  filter(sequence=="0001") %>%
  select(1:x55)

```

```{r census_reporter}
# https://censusreporter.org/profiles/16000US3611825-cambridge-ny/

```

```{r cornell}
# https://pad.human.cornell.edu/profiles/Washington.pdf


```


## acs package
```{r}
library(acs)
showClass("acs")
# ONETIME
# api.key.install(key=census_apikey, file = "key.rda")
# acs.tables.install()

geo_us <- geo.make(us=TRUE)
geo_nys <- geo.make(state="NY")
geo_nyscounties <- geo.make(state="NY", county="*")
geo_nysusds <- geo.make(state="NY", school.district.unified="*")
geo_zips <- geo.make(zip.code=c(12816, 12834))
geo_all <- geo_us + geo_nys + geo_nyscounties + geo_nysusds

geo_zips <- geo.make(zip.code="12816")
geo_all <- geo_zips

obj <- acs.fetch(endyear=2014, 
                       span = 5, 
                       geography=geo_all, 
                       table.number="B01001",
                       key=census_apikey)


f <- function(obj){
  geog <- geography(obj)
  ests <- tibble(geog, 
                 endyear=endyear(obj), 
                 type="est",
                 as_tibble(estimate(obj)))
  se <- tibble(geog,
               endyear=endyear(obj), 
               type="se",
               as_tibble(standard.error(obj)))
  
  df <- bind_rows(ests, se) %>%
    pivot_longer(-all_of(c(names(geog), "endyear", "type")))
}

df <- f(obj)

```


# WHY DO YOUNG PEOPLE COME TO A RURAL AREA?

# HOW DO IMPORTANT CHARACTERISTICS OF THE CAMBRIDGE AREA COMPARE AND CHANGE OVER TIME?

# ZIP CODES
```{r}
library(tigris)
library(ggmap)
options(tigris_use_cache = TRUE)

Tooele       <- c('84074','84029')
NEUtahCo     <- c('84003', '84004', '84042', '84062')
NWUtahCounty <- c('84005','84013','84043','84045')
utah_zips <- bind_rows(
  tibble(area = "Tooele", zip = Tooele),
  tibble(area = "NEUtahCo", zip = NEUtahCo),
  tibble(area = "NWUtahCounty", zip = NWUtahCounty)
)

zips_sf <- zctas(cb = T, starts_with = "84", class = "sf") %>%
  select(zip = ZCTA5CE10, geometry)

head(zips_sf)
#> Simple feature collection with 6 features and 1 field
#> geometry type:  MULTIPOLYGON
#> dimension:      XY
#> bbox:           xmin: -114.0504 ymin: 37.60461 xmax: -109.0485 ymax: 41.79228
#> epsg (SRID):    4269
#> proj4string:    +proj=longlat +datum=NAD83 +no_defs
#>       zip                       geometry
#> 37  84023 MULTIPOLYGON (((-109.5799 4...
#> 270 84631 MULTIPOLYGON (((-112.5315 3...
#> 271 84334 MULTIPOLYGON (((-112.1608 4...
#> 272 84714 MULTIPOLYGON (((-113.93 37....
#> 705 84728 MULTIPOLYGON (((-114.0495 3...
#> 706 84083 MULTIPOLYGON (((-114.0437 4...
#> 
utah_sf <- zips_sf %>%
  inner_join(utah_zips, by = "zip")
head(utah_sf)

ggmap_show_api_key()
ggmap_hide_api_key()


#43.0278499,-73.3841795
basemap <- get_map(location = c(lon=-111.9, lat= 40.7), zoom = 9)

ggmap(basemap) +
  geom_sf(aes(fill = zip), data = utah_sf, inherit.aes = F, size = 0, alpha = 0.6) +
  coord_sf(ndiscr = F) +
  theme(legend.position = "none")

#43.0278499,-73.3841795
lat <- 43.0278499
lon <- -73.3841795

Tooele       <- c('84074','84029')
NEUtahCo     <- c('84003', '84004', '84042', '84062')
NWUtahCounty <- c('84005','84013','84043','84045')

camb_zips <- bind_rows(
  tibble(area = "12816", zip = "12816"),
  tibble(area = "12834", zip = "12834")
)

camb_zips_sf <- zctas(cb = TRUE, starts_with = "128", class = "sf") %>%
  select(zip = ZCTA5CE10, geometry)

camb_sf <- camb_zips_sf %>%
  inner_join(camb_zips, by = "zip")
head(camb_sf)

camb_basemap5 <- get_map(location = c(lon=lon, lat= lat), 
                        zoom = 5) # maptype = "hybrid", 

camb_basemap10 <- get_map(location = c(lon=lon, lat= lat), 
                          maptype = "hybrid",
                          zoom = 10) # maptype = "hybrid", 


camb_basemap11 <- get_map(location = c(lon=lon, lat= lat), 
                        zoom = 11) # maptype = "hybrid", 

camb_basemap12 <- get_map(location = c(lon=lon, lat= lat), 
                        zoom = 12)


camb_basemap10 <- get_map(location = c(lon=lon, lat= lat), 
                          terrain = "roadmap", # hybrid, terrain, roadmap
                          zoom = 10) # maptype = "hybrid", 

camb_basemap10 <- get_map(location = c(lon=lon, lat= lat), 
                          terrain = "terrain", # hybrid, terrain, roadmap
                          zoom="auto", scale=2)

camb_basemap <- camb_basemap10 
ggmap(camb_basemap) +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.6) +
  coord_sf(ndiscr = 100,
           xlim=c(-73.65, -73.25),
           ylim=c(42.9, 43.25)) +
  # scale_x_continuous(name=NULL, breaks=NULL, labels=NULL) +
  # scale_y_continuous(name=NULL, breaks=NULL, labels=NULL) +
  legend_notitle +
  ggtitle("Zip code boundaries in Cambridge area") + 
  theme(axis.line = element_line(color = NA)) + 
  xlab("") + ylab("")

get_map("houston, texas")
get_map("cambridge, new york") %>%
  ggmap()

lat <- 43.0278499
lon <- -73.3841795
get_map(location = c(lon=lon, lat= lat), 
        terrain = "roadmap", # hybrid, terrain, roadmap
        maprange=TRUE,
        zoom="auto", scale=2) %>%
  ggmap() +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.2) +
  coord_sf(ndiscr = 100,
           xlim=c(-73.65, -73.25),
           ylim=c(42.9, 43.25)) +
  theme_void() + 
  ggtitle("Zip code boundaries in Cambridge area") +
  theme(
    plot.title = element_text(colour = "blue"), 
    panel.border = element_rect(colour = "grey", fill=NA, size=2)
    ) +
  legend_notitle

chi_bb <- c(
  left = -87.936287,
  bottom = 41.679835,
  right = -87.447052,
  top = 42.000835
)

chicago_stamen <- get_stamenmap(
  bbox = chi_bb,
  zoom = 11
)

ggmap(chicago_stamen)

# camb bounding box
camb_bb <- c(
  left = -73.65,
  bottom = 42.9,
  right = -73.25,
  top = 43.25
)
camb_stamen <- get_stamenmap(bbox = camb_bb, zoom = 13)
camb_stamen <- get_stamenmap(
  bbox = camb_bb
)
# get_stamenmap(bbox = camb_bb, zoom = 13, maptype="terrain-labels") %>%
get_map(location=camb_bb, source="osm", maptype = "hybrid") %>%  
  ggmap() +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.2) +
  # coord_sf(ndiscr = 100,
  #          xlim=c(-73.65, -73.25),
  #          ylim=c(42.9, 43.25)) +
  theme_void() + 
  ggtitle("Zip code boundaries in Cambridge area") +
  theme(
    plot.title = element_text(colour = "blue"), 
    panel.border = element_rect(colour = "grey", fill=NA, size=2)
    ) +
  legend_notitle

  # theme(axis.line = element_blank(),
  #       axis.text = element_blank(),
  #       axis.ticks = element_blank(),
  #       plot.margin = unit(c(0, 0, -1, -1), 'lines')) +
  # xlab('') +
  # ylab('')


# bounding box
left_bottom <- c(43.005063, -73.440002)
right_top <- c(43.060715, -73.336668)
(map <- get_map(c(left = left_bottom[1], bottom = left_bottom[2],
                  right = right_top[1], top = right_top[2])))

(map <- get_map(c(left = left_bottom[2], bottom = left_bottom[1],
                  right = right_top[2], top = right_top[1]),
                maptype="watercolor"))
ggmap(map)


map <- get_googlemap("Montpellier, France", zoom = 8, maptype = "terrain")
 # Plot it
ggmap(map) + 
  theme_void() + 
  ggtitle("terrain") + 
  theme(
    plot.title = element_text(colour = "orange"), 
    panel.border = element_rect(colour = "grey", fill=NA, size=2)
  )


big_streets <- getbb("Asheville United States")%>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("motorway", "primary", "motorway_link", "primary_link")) %>%
  osmdata_sf()

big_streets

med_streets <- getbb("Asheville United States")%>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("secondary", "tertiary", "secondary_link", "tertiary_link")) %>%
  osmdata_sf()


small_streets <- getbb("Asheville United States") %>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("residential", "living_street",
                            "unclassified",
                            "service", "footway"
                  )) %>%
  osmdata_sf()

river <- getbb("Asheville United States")%>%
  opq()%>%
  add_osm_feature(key = "waterway", value = "river") %>%
  osmdata_sf()

railway <- getbb("Asheville United States") %>%
  opq()%>%
  add_osm_feature(key = "railway", value="rail") %>%
  osmdata_sf()

# http://joshuamccrain.com/tutorials/maps/streets_tutorial.html
cbb <- getbb("Cambridge New York")
# camb bounding box
camb_bb <- c(
  left = -73.65,
  bottom = 42.9,
  right = -73.25,
  top = 43.25
)

big_streets <- camb_bb %>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("motorway", "primary", "motorway_link", "primary_link")) %>%
  osmdata_sf()

big_streets

med_streets <- camb_bb %>%
  opq()%>%
  add_osm_feature(key = "highway", 
                  value = c("secondary", "tertiary", "secondary_link", "tertiary_link")) %>%
  osmdata_sf()

ggplot() +
  geom_sf(data = big_streets$osm_lines,
          inherit.aes = FALSE,
          color = "black") +
  geom_sf(data = med_streets$osm_lines,
          inherit.aes = FALSE,
          color = "black")

# http://gis.ny.gov/civil-boundaries/
# http://gis.ny.gov/gisdata/inventories/details.cfm?DSID=927
map('county', 'new jersey')
map_data("county", "iowa")
map_data("village", "new york")

require(rgdal)
require(ggplot2)
fn <- file.path(tempdir(), "GBR_adm_gdb.zip", fsep = "\\")
download.file("http://biogeo.ucdavis.edu/data/gadm2.8/shp/GBR_adm_shp.zip", fn)
utils::unzip(fn, exdir = tempdir())
shp <- readOGR(dsn = file.path(tempdir(), "GBR_adm1.shp"), stringsAsFactors = F)
shp <- readOGR(here::here("map_data", "NYS_Civil_Boundaries.shp", "Villages.shp"), stringsAsFactors = FALSE)
head(shp)
count(shp, NAME)
shp@data$NAME
shp2 <- subset(shp, NAME=="Cambridge")

camb_bb <- c(
  left = -73.65,
  bottom = 42.9,
  right = -73.25,
  top = 43.25
)

get_map(location=camb_bb, source="osm", maptype = "hybrid") %>%  
  ggmap() +
  geom_sf(aes(fill = zip), data = camb_sf, 
          inherit.aes = FALSE, size = 0, alpha = 0.2)  +
  geom_polygon(data = shp2, aes(x = long, y = lat, group = group), colour = "black", fill = NA)

ggplot() + 
  geom_polygon(data = shp2, aes(x = long, y = lat, group = group), colour = "black", fill = NA)


scale_x_continuous( limits = c( -95.5 , -95.3 ) , expand = c( 0 , 0 ) )+
scale_y_continuous( limits = c( 29.6 , 29.8 ) , expand = c( 0 , 0 ) )


library(sf)
vlg_path <- here::here("map_data", "NYS_Civil_Boundaries.shp", "Villages.shp")
vlg_sf <- st_read(vlg_path)
vlg_sf
subset(vlg_sf, NAME=="Cambridge")
camb_bb
xmin <- -73.65; xmax <- -73.25
ymin <- 42.90; ymax <- 43.25
# the bound box
tibble(long=c(xmin, xmin, xmax, xmax),
       lat=c(ymin, ymax, ymin, ymax)) %>%
  ggplot(aes(x = long, y = lat)) +
  geom_sf(data=vlg_sf)
  geom_polygon()
  
vlg_sf %>%
  filter(NAME == "Cambbridge") %>%
  ggplot() +
  geom_sf(fill="blue") + 
  coord_sf() +
  scale_x_continuous(limits=c(xmin, xmax)) +
  scale_y_continuous(limits=c(ymin, ymax))
  scale_fill_manual(values=clrs) +
  theme_map()
  
basemap <- get_map(location = c(lon=-111.9, lat= 40.7), zoom = 9)
basemap <- get_map(location = camb_bb)
ggmap(basemap) +
  layer_spatial(vlg_sf) 
  geom_sf(data=vlg_sf)
  
  

us_counties(states = "NY") %>%
  dplyr::select(-13) %>%
  ggplot() + 
  geom_sf(aes(fill="blue"))  + 
  coord_sf()

library(ggspatial)
library(sf)
ggplot() +
  layer_spatial(sf::st_bbox(camb_bb))

st_bbox(c(xmin = camb_bb["left"], xmax = camb_bb["right"],
          ymax = camb_bb["top"], ymin = camb_bb["bottom"]),
        crs = st_crs(4326))

a <- st_bbox(c(xmin = 16.1, xmax = 16.6, ymax = 48.6, ymin = 47.9), crs = st_crs(4326))
str(a)

load_longlake_data()
longlake_waterdf # is a simple features object
a <- st_bbox(longlake_waterdf)
a
 #    xmin      ymin      xmax      ymax 
 # 409949.5 5083315.6  412606.5 5087084.0 
ggplot() +
  layer_spatial(sf::st_bbox(longlake_waterdf)) +
  layer_spatial(longlake_depthdf) 

library(OpenStreetMap)
# define upleft lowright as lat, lon
# camb_bb
upleft <- c(43.25, -73.65)
lowright <- c(42.90, -73.25)
ggplot() +
  openmap(c(LAT2,LON1), c(LAT1,LON2), zoom = NULL,
               type = c("osm", "stamen-toner", "stamen-terrain","stamen-watercolor", "esri","esri-topo")[6],
               mergeTiles = TRUE)
  

```

```{r}
# https://cran.r-project.org/web/packages/osmdata/vignettes/osmdata.html
# https://wiki.openstreetmap.org/wiki/Category:Keys
# All overpass queries begin with a bounding box, defined in osmdata with the function opq():

# The overpass API only accepts simple rectangular bounding boxes, and so data requested with a bounding polygon will actually be all data within the corresponding rectangular bounding box, but such data may be subsequently trimmed to within the polygon with the trim_osmdata() function, demonstrated in the code immediately below.

# usual format: 
# bbox = left,bottom,right,top
# bbox = min Longitude , min Latitude , max Longitude , max Latitude 
# ie xmin, ymin, xmax, ymax

q <- opq(bbox = c(51.1, 0.1, 51.2, 0.2))
# The following sub-section provides more detail on bounding boxes. Following the initial opq() call, osmdata queries are built by adding one or more ‘features,’ which are specified in terms of key-value pairs. For example, all paths, ways, and roads are designated in OSM with key=highway, so that a query all motorways in greater London (UK) can be constructed as follows:
q <- opq(bbox = 'greater london uk') %>%
    add_osm_feature(key = 'highway', value = 'motorway')

bb <- getbb ('london uk', format_out = 'polygon')
x <- opq(bbox = bb) %>%
    add_osm_feature(key = 'highway', value = 'motorway') %>%
    osmdata_sf () %>%
    trim_osmdata (bb)

# osmdata_sf() returns OSM data in Simple Features (SF) format, defined by the
# Open Geospatial Consortium, and implemented in the R package sf. This package
# provides a direct interface to the C++ Graphical Data Abstraction Library
# (GDAL) which also includes a so-called ‘driver’ for OSM data. This means that
# OSM data may also be read directly with sf, rather than using osmdata. In this
# case, data must first be saved to disk, which can be readily achieved using
# osmdata_xml() described above, or through downloading directly from the
# overpass interactive query builder.

opq(bbox = 'Trentham, Australia') %>%
    add_osm_feature(key = 'name') %>%
    # osmdata_xml(filename = 'trentham.osm')
    osmdata_xml(filename = here::here("map_data", 'trentham.osm'))

# The GDAL drivers used by sf can only load single ‘layers’ of features, for
# example, points, lines, or polygons. In contrast, osmdata loads all features
# simultaneously:
sf::st_read(here::here("map_data", 'trentham.osm'), layer = 'points')
sf::st_read(here::here("map_data", 'trentham.osm'), layer = 'lines')
sf::st_read(here::here("map_data", 'trentham.osm'), layer = 'polygons')

# The GDAL drivers used by sf can only load single ‘layers’ of features, for
# example, points, lines, or polygons. In contrast, osmdata loads all features
# simultaneously:
(a <- osmdata_sf(q, here::here("map_data", 'trentham.osm')))
names(a$osm_points)
names(osmdata_sf(q, 'trentham.osm')$osm_points)
# IMPORTANT!!
# https://www.liamdbailey.com/post/building-maps-using-openstreetmap-content/
# The first step is to specify the area within which we want to search for
# OpenStreetMap features. We can specify the latitude and longitude limits
# manually, but you can also use the getbb() function to return the limits of a
# particular place (e.g. a city).
getbb(place_name = "Greater Melbourne, Australia")
melb_bb <- getbb(place_name = "Greater Melbourne, Australia")
melb_bb

##     min   max
## x 144.4 146.2
## y -38.5 -37.4

# didn't work; altneratively
# ie xmin, ymin, xmax, ymax
melb_bb2 <- matrix(data=c(144.6, 146.2,
                          -38.5, -37.4), 
                   ncol=2, byrow=TRUE,
                   dimnames=list(c("x", "y"), c("min", "max")))
melb_bb2
melb_bb <- melb_bb2

make_bb <- function(xmin, ymin, xmax, ymax){
  matrix(data=c(xmin, xmax, ymin, ymax), 
         ncol=2, byrow=TRUE,
         dimnames=list(c("x", "y"), c("min", "max")))
}
make_bb(144.6, -38.5, 146.2, -37.4)

# define queries
# query railway lines
melb_query_line <- opq(bbox = melb_bb2, timeout = 120) %>% 
  add_osm_feature(key = 'route', value = 'train')

melb_query_station <- opq(bbox = melb_bb2, timeout = 120) %>% 
  add_osm_feature(key = 'railway', value = 'station')

melbourne_trainline <- melb_query_line %>% 
  osmdata_sf()

melbourne_station <- melb_query_station %>% 
  osmdata_sf()

melbourne_trainline

melbourne_trainline_lines <- melbourne_trainline$osm_lines
melbourne_station_points  <- melbourne_station$osm_points

ggplot() +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "black") +
  geom_sf(data = melbourne_station_points, size = 1, shape = 21, colour = "black", fill = "dark grey") +
  theme_void()

# Although we queried within the greater Melbourne area, the lines and polygons
# can extend outside this bounding box. We can deal with this a number of ways.
# Here we’ll use a combination of trim_osmdata() from within osmdata to clip our
# lines and the coord_sf() function to adjust the limits of plot to match the
# bounding box of Melbourne we’ve been using.

# melb_bb_poly <- getbb(place_name = "Melbourne, Australia",
#                       format_out = "sf_polygon")

# create the polygon (my workaround)
xmin <- 144.6; ymin <- -38.5; xmax <- 146.3; ymax <- -37.4
Poly_Coord_df = data.frame(lon=c(xmin, xmax), lat=c(ymin, ymax))
melb_bb_poly = Poly_Coord_df %>% 
  st_as_sf(coords = c("lon", "lat"), crs = 4326) 

melbourne_trainline_trim <- melbourne_trainline %>% 
  #Use exclude = FALSE to include lines that partially overlap our boundaries
  trim_osmdata(bb_poly = melb_bb_poly, exclude = FALSE)

melbourne_station_trim <- melbourne_station %>% 
  trim_osmdata(bb_poly = melb_bb_poly, exclude = FALSE)

melbourne_trainline_lines <- melbourne_trainline_trim$osm_lines
melbourne_station_points  <- melbourne_station_trim$osm_points

ggplot() +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "black") +
  geom_sf(data = melbourne_station_points, size = 1, shape = 21, colour = "black", fill = "dark grey") +
  theme_void() +
  coord_sf(xlim = melb_bb[1, ], ylim = melb_bb[2, ])

#For each station, determine the distance to all train lines
min_dist <- sf::st_distance(melbourne_station_points,
                            melbourne_trainline_lines) %>% 
  #Determine the minimum distance for each station
  apply(MARGIN = 1, FUN = min)

melbourne_station_points_subset <- melbourne_station_points %>% 
  dplyr::mutate(dist = min_dist) %>% 
  dplyr::filter(dist <= 1000)
  
ggplot() +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "black") +
  geom_sf(data = melbourne_station_points_subset, size = 1, shape = 21,
          colour = "black", fill = "dark grey") +
  theme_void() +
  coord_sf(xlim = melb_bb[1, ], ylim = melb_bb[2, ])

bass_strait <- opq(bbox = melb_bb, timeout = 120) %>% 
  add_osm_feature(key = 'natural', value = 'strait') %>% 
  add_osm_feature(key = "name", value = "Bass Strait", value_exact = FALSE) %>%
  osmdata_sf()

bass_strait_polygon <- bass_strait$osm_multipolygons

yarra <- opq(bbox = melb_bb, timeout = 120) %>% 
  add_osm_feature(key = 'waterway', value = 'river') %>% 
  add_osm_feature(key = "name", value = "Yarra River", value_exact = FALSE) %>%
  osmdata_sf()

yarra_line <- yarra$osm_multilines

ggplot() +
  geom_sf(data = bass_strait_polygon, fill = "blue", colour = NA) +
  geom_sf(data = yarra_line, colour = "blue", size = 1.5) +
  geom_sf(data = melbourne_trainline_lines, size = 1, colour = "gray") +
  geom_sf(data = melbourne_station_points_subset, size = 2, shape = 21,
          colour = "black", fill = "dark grey") +
  theme_void() +
  coord_sf(xlim = melb_bb[1, ], ylim = melb_bb[2, ])


```



```{r}
library(USAboundaries)
data(package="USAboundaries")
us_zipcodes() %>% filter(zipcode==12816)
us_zipcodes() %>% filter(zipcode %in% c(12816, 12834))
us_cities() %>% filter(state_abbr=="NY", county_name=="Washington")

# ny data
ny1 <- nytroll %>%
  filter(stabbr=="NY", date==max(date))
# create nyc records
# 36000 New York
# 36005 Bronx
# 36047 Kings
# 36061 New York
# 36081 Queens
# 36085 Richmond
nyc <- tribble(
  ~fips, ~county,
  "36000", "New York",
  "36005", "Bronx",
  "36047", "Kings",
  "36061", "New York",
  "36081", "Queens",
  "36085", "Richmond") %>%
  mutate(cap100k=ny1$cap100k[ny1$fips=="36998"])
nybase <- bind_rows(ny1, nyc)

nydata <- us_counties(states = "NY") %>%
  dplyr::select(-13) %>%  # state_name is 9 and 13, so delete second as duplicated and unnecessary
  left_join(nybase %>%
              dplyr::select(geoid=fips, cap100k),
            by="geoid")

# ggplot(nydata) + 
#   geom_sf() + 
#   coord_sf()

nydata %>%
  mutate(f=cut(cap100k, seq(0, 100, 10))) %>%
  count(f)
# good cuts look like 40-80 bt 10, 80-100, > 200
nydata %>% mutate(f=cut(cap100k, seq(0, 100, 10))) %>% filter(is.na(f))

# brewer.pal.info
# clrs <- c(brewer.pal(5, "Paired"), "black")
clrs <- brewer.pal(7, "RdBu") %>% rev()

p <- nydata %>%
  mutate(f=cut(cap100k, c(seq(30, 80, 10), 100, Inf))) %>%
  ggplot() + 
  geom_sf(aes(fill=f)) + 
  coord_sf() +
  scale_fill_manual(values=clrs) +
  theme_map() +
  geom_sf_text(aes(label = name), colour="black", size=2) +
  guides(fill = guide_legend(reverse = TRUE)) +
  theme(legend.position = "right") +
  ggtitle("Covid-9 cases per 100,000 population",
          subtitle=paste0("Most recent 7-day average as reported on ", format(today(), "%B %d, %Y"))) +
  theme(legend.position = c(.85, .4)) +
  legend_notitle
p

ggsave(plot=p, filename=here::here("results", "nyco_map.png"), width=10, height=6.5, units="in")
```

